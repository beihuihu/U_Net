{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Author: Ankit Kariryaa, University of Bremen\n",
    "  \n",
    "  Modified by Xuehui Pi and Qiuqi Luo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started\n",
    "Define the paths for the dataset and trained models in the `notebooks/config/UNetTraining.py` file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = '16'\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = '16'\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '16'\n",
    "print(os.environ.get('OMP_NUM_THREADS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090, compute capability 8.6\n",
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision \n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "import time\n",
    "import rasterio.warp             # Reproject raster samples\n",
    "from functools import reduce\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from core.UNet_572 import UNet  #\n",
    "from core.losses import tversky, focalTversky, bce_dice_loss, accuracy, dice_loss, IoU, recall, precision,F1_score\n",
    "from tensorflow.keras.losses import BinaryCrossentropy as bce\n",
    "from core.optimizers import adaDelta, adagrad, adam, nadam\n",
    "from core.frame_info_572 import FrameInfo\n",
    "from core.dataset_generator_572 import DataGenerator\n",
    "from core.visualize import display_images,plot\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # plotting tools\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Polygon\n",
    "#matplotlib.use(\"Agg\")\n",
    "\n",
    "import warnings                  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "#Mixed precision is the use of both 16-bit and 32-bit floating-point types in a model during training to make it run faster and use less memory.\n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "# tf.device('/gpu:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto(\n",
    "    #device_count={\"CPU\": 64},\n",
    "    allow_soft_placement=True, \n",
    "    log_device_placement=False)\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required configurations (including the input and output paths) are stored in a separate file (such as config/UNetTraining.py)\n",
    "# Please provide required info in the file before continuing with this notebook. \n",
    "# hbh: in this scene,a new config named UNetTraining_sequential is created to distinguish from the original\n",
    "from config import UNetTraining_572\n",
    "# In case you are using a different folder name such as configLargeCluster, then you should import from the respective folder \n",
    "# Eg. from configLargeCluster import UNetTraining\n",
    "config = UNetTraining_572.Configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OPTIMIZER = adaDelta\n",
    "OPTIMIZER =  mixed_precision.LossScaleOptimizer(OPTIMIZER)\n",
    "OPTIMIZER_NAME = 'AdaDelta'\n",
    "\n",
    "# OPTIMIZER = adam\n",
    "# OPTIMIZER = mixed_precision.LossScaleOptimizer(OPTIMIZER)\n",
    "# OPTIMIZER_NAME = 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSS = tversky \n",
    "# LOSS_NAME = 'tversky'\n",
    "\n",
    "# LOSS=focalTversky\n",
    "# LOSS_NAME = 'focalTversky'\n",
    "\n",
    "#LOSS=tf.keras.losses.BinaryCrossentropy()\n",
    "#LOSS_NAME = 'bce'\n",
    "\n",
    "# LOSS=bce_dice_loss\n",
    "# LOSS_NAME = 'bce_dice_loss'\n",
    "\n",
    "LOSS=dice_loss\n",
    "LOSS_NAME = 'dice_loss'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImgs(path_to_write, fn):\n",
    "    image = rasterio.open(os.path.join(path_to_write, fn))\n",
    "#     print(fn)\n",
    "    read_image = image.read()/1000\n",
    "#     print(read_image[1].max())\n",
    "    \n",
    "    comb_img = np.transpose(read_image, axes=(1,2,0))\n",
    "    annotation_im = Image.open(os.path.join(path_to_write, fn.replace(config.image_fn,config.annotation_fn).replace(config.image_type,config.ann_type)))\n",
    "    annotation = np.array(annotation_im)\n",
    "    rowNum=annotation.shape[0]/config.output_size[0]#config.patch_size[0]\n",
    "    colNum=annotation.shape[1]/config.output_size[1]#config.patch_size[1]\n",
    "#     if(read_image.shape[1]- annotation.shape[0]!=184) or(read_image.shape[2]- annotation.shape[1]!=184):\n",
    "#                 print(fn)\n",
    "    f = FrameInfo(comb_img, annotation)\n",
    "    return f,rowNum*colNum\n",
    "    \n",
    "def readFrames(dataType):\n",
    "    frames=[]\n",
    "    numList=[]\n",
    "    print(dataType)\n",
    "#     for i in range(3,4):\n",
    "    for i in range(0,config.type_num):#config.type_num\n",
    "        path_to_write=os.path.join(config.dataset_dir,'{}/type{}'.format(dataType,i))\n",
    "        all_files = os.listdir(path_to_write)\n",
    "        all_files_image = [fn for fn in all_files if fn.startswith(config.image_fn) and fn.endswith(config.image_type)]#image.png\n",
    "        print('type{} image number:{}'.format(i,len(all_files_image)))\n",
    "        for j, fn in enumerate(all_files_image):\n",
    "            f,num = readImgs(path_to_write,fn)\n",
    "            frames.append(f)\n",
    "            numList.append(num)\n",
    "    return frames,numList\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "type0 image number:156\n",
      "type1 image number:141\n",
      "type2 image number:68\n",
      "type3 image number:53\n",
      "type4 image number:9\n",
      "type5 image number:17\n",
      "total training img count:444\n",
      "total training patches count:17414.319155861413\n"
     ]
    }
   ],
   "source": [
    "frames,numList=readFrames('train')\n",
    "percentages=np.array(numList)\n",
    "train_sum=percentages.sum()\n",
    "percentages=percentages/percentages.sum()\n",
    "print('total training img count:'+str(len(frames)))\n",
    "print('total training patches count:{}'.format(train_sum))\n",
    "train_generator = DataGenerator(config.input_size, config.output_size,frames, augmenter = 'iaa').random_generator(config.BATCH_SIZE,percentages)#,normalize ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numList=readNum('train')\n",
    "# percentages=np.array(numList)\n",
    "# print(percentages.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "type0 image number:53\n",
      "type1 image number:48\n",
      "type2 image number:24\n",
      "type3 image number:18\n",
      "type4 image number:3\n",
      "type5 image number:5\n",
      "total validation img count:151\n",
      "total validation patches count:5719.94284063131\n"
     ]
    }
   ],
   "source": [
    "frames,numList=readFrames('val')\n",
    "percentages=np.array(numList)\n",
    "val_sum=percentages.sum()\n",
    "percentages=percentages/percentages.sum()\n",
    "print('total validation img count:'+str(len(frames)))\n",
    "print('total validation patches count:{}'.format(val_sum))\n",
    "val_generator = DataGenerator(config.input_size, config.output_size, frames, augmenter = None).random_generator(config.BATCH_SIZE,percentages)#, normalize = config.normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(1):\n",
    "    train_images, real_label = next(train_generator) \n",
    "    print(train_images.shape)\n",
    "    print(real_label.shape)\n",
    "    display_images(train_images,real_label,pad=92,output_size=config.output_size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(1):\n",
    "    val_images, val_label = next(val_generator) \n",
    "    print(val_images.shape)\n",
    "    display_images(val_images,val_label,pad=92,output_size=config.output_size[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\lakemapping\\5_saved_models\\lakes_20240112-1629_AdaDelta_dice_loss_012345_572.h5\n"
     ]
    }
   ],
   "source": [
    "timestr = time.strftime(\"%Y%m%d-%H%M\")\n",
    "chf = config.input_image_channel + config.input_label_channel\n",
    "chs = reduce(lambda a,b: a+str(b), chf, '') \n",
    "\n",
    "if not os.path.exists(config.model_path):\n",
    "    os.makedirs(config.model_path)\n",
    "model_name='_{}_{}_{}_{}_{}.h5'.format(timestr,OPTIMIZER_NAME,LOSS_NAME,chs,config.input_shape[0])\n",
    "model_path = os.path.join(config.model_path,'lakes'+model_name)\n",
    "chf = config.input_image_channel + config.input_label_channel\n",
    "chs = reduce(lambda a,b: a+str(b), chf, '') \n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(572, 572, 5)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, 572, 572, 5  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 570, 570, 64  2944        ['Input[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 568, 568, 64  36928       ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 568, 568, 64  256        ['conv2d_1[0][0]']               \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 284, 284, 64  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 282, 282, 12  73856       ['max_pooling2d[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 280, 280, 12  147584      ['conv2d_2[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 280, 280, 12  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 140, 140, 12  0          ['batch_normalization_1[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 138, 138, 25  295168      ['max_pooling2d_1[0][0]']        \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 136, 136, 25  590080      ['conv2d_4[0][0]']               \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 136, 136, 25  1024       ['conv2d_5[0][0]']               \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 68, 68, 256)  0          ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 66, 66, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 64, 64, 512)  2359808     ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 64, 64, 512)  2048       ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 512)  0          ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 30, 30, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 28, 28, 1024  9438208     ['conv2d_8[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 56, 56, 1024  0           ['conv2d_9[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 56, 1024  4096       ['up_sampling2d[0][0]']          \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " cropping2d (Cropping2D)        (None, 56, 56, 512)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 56, 56, 1536  0           ['batch_normalization_4[0][0]',  \n",
      "                                )                                 'cropping2d[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 54, 54, 512)  7078400     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 52, 52, 512)  2359808     ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 104, 104, 51  0          ['conv2d_11[0][0]']              \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 104, 104, 51  2048       ['up_sampling2d_1[0][0]']        \n",
      " rmalization)                   2)                                                                \n",
      "                                                                                                  \n",
      " cropping2d_1 (Cropping2D)      (None, 104, 104, 25  0           ['batch_normalization_2[0][0]']  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 104, 104, 76  0           ['batch_normalization_5[0][0]',  \n",
      "                                8)                                'cropping2d_1[0][0]']           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_12 (Conv2D)             (None, 102, 102, 25  1769728     ['concatenate_1[0][0]']          \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 100, 100, 25  590080      ['conv2d_12[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 200, 200, 25  0          ['conv2d_13[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 200, 200, 25  1024       ['up_sampling2d_2[0][0]']        \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " cropping2d_2 (Cropping2D)      (None, 200, 200, 12  0           ['batch_normalization_1[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 200, 200, 38  0           ['batch_normalization_6[0][0]',  \n",
      "                                4)                                'cropping2d_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 198, 198, 12  442496      ['concatenate_2[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 196, 196, 12  147584      ['conv2d_14[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 392, 392, 12  0          ['conv2d_15[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 392, 392, 12  512        ['up_sampling2d_3[0][0]']        \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " cropping2d_3 (Cropping2D)      (None, 392, 392, 64  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 392, 392, 19  0           ['batch_normalization_7[0][0]',  \n",
      "                                2)                                'cropping2d_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 390, 390, 64  110656      ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 388, 388, 64  36928       ['conv2d_16[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 388, 388, 1)  65          ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 388, 388, 1)  0           ['conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,391,617\n",
      "Trainable params: 31,385,857\n",
      "Non-trainable params: 5,760\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model and compile it  \n",
    "print(config.input_shape)\n",
    "shape=[config.BATCH_SIZE, *config.input_shape]\n",
    "model = UNet([config.BATCH_SIZE, *config.input_shape],config.input_label_channel)\n",
    "model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=[dice_loss, accuracy, recall, precision,F1_score, IoU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks      for the early stopping of training, LearningRateScheduler and model checkpointing \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = False)\n",
    "\n",
    "#reduceonplatea： It can be useful when using adam as optimizer\n",
    "#Reduce learning rate when a metric has stopped improving (after some patience 个epoch, reduce by a factor of 0.33, new_lr = lr * factor). \n",
    "#cooldown: number of epochs to wait before resuming normal operation after lr has been reduced. \n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.33,\n",
    "                                   patience=4, verbose=1, mode='min',\n",
    "                                   min_delta=0.0001, cooldown=4, min_lr=1e-16) \n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=2, patience=40)\n",
    "\n",
    "\n",
    "log_dir = os.path.join('./logs','UNet'+model_name)\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=0, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')\n",
    "\n",
    "callbacks_list = [checkpoint, tensorboard] #reduceLROnPlat is not required with adaDelta, early"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型\n",
    "保存history文件并绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.2519 - dice_loss: 0.2517 - accuracy: 0.9843 - recall: 0.8386 - precision: 0.7102 - F1_score: 0.7490 - IoU: 0.6229\n",
      "Epoch 1: val_loss improved from inf to 0.29936, saving model to G:\\lakemapping\\5_saved_models\\lakes_20240112-1629_AdaDelta_dice_loss_012345_572.h5\n",
      "1088/1088 [==============================] - 707s 599ms/step - loss: 0.2519 - dice_loss: 0.2517 - accuracy: 0.9843 - recall: 0.8386 - precision: 0.7102 - F1_score: 0.7490 - IoU: 0.6229 - val_loss: 0.2994 - val_dice_loss: 0.2992 - val_accuracy: 0.9846 - val_recall: 0.6672 - val_precision: 0.7755 - val_F1_score: 0.7009 - val_IoU: 0.5614\n",
      "Epoch 2/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.2115 - dice_loss: 0.2113 - accuracy: 0.9878 - recall: 0.8650 - precision: 0.7511 - F1_score: 0.7889 - IoU: 0.6713\n",
      "Epoch 2: val_loss improved from 0.29936 to 0.18207, saving model to G:\\lakemapping\\5_saved_models\\lakes_20240112-1629_AdaDelta_dice_loss_012345_572.h5\n",
      "1088/1088 [==============================] - 654s 601ms/step - loss: 0.2115 - dice_loss: 0.2113 - accuracy: 0.9878 - recall: 0.8650 - precision: 0.7511 - F1_score: 0.7889 - IoU: 0.6713 - val_loss: 0.1821 - val_dice_loss: 0.1819 - val_accuracy: 0.9893 - val_recall: 0.8754 - val_precision: 0.7879 - val_F1_score: 0.8182 - val_IoU: 0.7139\n",
      "Epoch 3/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.2005 - dice_loss: 0.2003 - accuracy: 0.9888 - recall: 0.8666 - precision: 0.7653 - F1_score: 0.7998 - IoU: 0.6851\n",
      "Epoch 3: val_loss did not improve from 0.18207\n",
      "1088/1088 [==============================] - 649s 596ms/step - loss: 0.2005 - dice_loss: 0.2003 - accuracy: 0.9888 - recall: 0.8666 - precision: 0.7653 - F1_score: 0.7998 - IoU: 0.6851 - val_loss: 0.2460 - val_dice_loss: 0.2458 - val_accuracy: 0.9821 - val_recall: 0.9218 - val_precision: 0.6639 - val_F1_score: 0.7543 - val_IoU: 0.6291\n",
      "Epoch 4/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.1903 - dice_loss: 0.1901 - accuracy: 0.9892 - recall: 0.8666 - precision: 0.7821 - F1_score: 0.8100 - IoU: 0.6969\n",
      "Epoch 4: val_loss did not improve from 0.18207\n",
      "1088/1088 [==============================] - 651s 598ms/step - loss: 0.1903 - dice_loss: 0.1901 - accuracy: 0.9892 - recall: 0.8666 - precision: 0.7821 - F1_score: 0.8100 - IoU: 0.6969 - val_loss: 0.1858 - val_dice_loss: 0.1857 - val_accuracy: 0.9886 - val_recall: 0.8583 - val_precision: 0.7975 - val_F1_score: 0.8144 - val_IoU: 0.7054\n",
      "Epoch 5/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.1638 - dice_loss: 0.1637 - accuracy: 0.9907 - recall: 0.8780 - precision: 0.8167 - F1_score: 0.8364 - IoU: 0.7328\n",
      "Epoch 5: val_loss improved from 0.18207 to 0.17197, saving model to G:\\lakemapping\\5_saved_models\\lakes_20240112-1629_AdaDelta_dice_loss_012345_572.h5\n",
      "1088/1088 [==============================] - 682s 627ms/step - loss: 0.1638 - dice_loss: 0.1637 - accuracy: 0.9907 - recall: 0.8780 - precision: 0.8167 - F1_score: 0.8364 - IoU: 0.7328 - val_loss: 0.1720 - val_dice_loss: 0.1718 - val_accuracy: 0.9897 - val_recall: 0.8676 - val_precision: 0.8099 - val_F1_score: 0.8283 - val_IoU: 0.7234\n",
      "Epoch 6/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.1598 - dice_loss: 0.1597 - accuracy: 0.9913 - recall: 0.8753 - precision: 0.8297 - F1_score: 0.8404 - IoU: 0.7389\n",
      "Epoch 6: val_loss improved from 0.17197 to 0.16737, saving model to G:\\lakemapping\\5_saved_models\\lakes_20240112-1629_AdaDelta_dice_loss_012345_572.h5\n",
      "1088/1088 [==============================] - 672s 617ms/step - loss: 0.1598 - dice_loss: 0.1597 - accuracy: 0.9913 - recall: 0.8753 - precision: 0.8297 - F1_score: 0.8404 - IoU: 0.7389 - val_loss: 0.1674 - val_dice_loss: 0.1672 - val_accuracy: 0.9907 - val_recall: 0.8239 - val_precision: 0.8652 - val_F1_score: 0.8328 - val_IoU: 0.7307\n",
      "Epoch 7/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.1307 - dice_loss: 0.1305 - accuracy: 0.9930 - recall: 0.8874 - precision: 0.8683 - F1_score: 0.8696 - IoU: 0.7812\n",
      "Epoch 7: val_loss did not improve from 0.16737\n",
      "1088/1088 [==============================] - 672s 618ms/step - loss: 0.1307 - dice_loss: 0.1305 - accuracy: 0.9930 - recall: 0.8874 - precision: 0.8683 - F1_score: 0.8696 - IoU: 0.7812 - val_loss: 0.1869 - val_dice_loss: 0.1868 - val_accuracy: 0.9883 - val_recall: 0.8865 - val_precision: 0.7836 - val_F1_score: 0.8133 - val_IoU: 0.7127\n",
      "Epoch 8/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.1294 - dice_loss: 0.1292 - accuracy: 0.9932 - recall: 0.8835 - precision: 0.8745 - F1_score: 0.8708 - IoU: 0.7819\n",
      "Epoch 8: val_loss did not improve from 0.16737\n",
      "1088/1088 [==============================] - 668s 613ms/step - loss: 0.1294 - dice_loss: 0.1292 - accuracy: 0.9932 - recall: 0.8835 - precision: 0.8745 - F1_score: 0.8708 - IoU: 0.7819 - val_loss: 0.1802 - val_dice_loss: 0.1801 - val_accuracy: 0.9878 - val_recall: 0.9141 - val_precision: 0.7758 - val_F1_score: 0.8200 - val_IoU: 0.7211\n",
      "Epoch 9/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.1110 - dice_loss: 0.1109 - accuracy: 0.9942 - recall: 0.8981 - precision: 0.8931 - F1_score: 0.8892 - IoU: 0.8096\n",
      "Epoch 9: val_loss improved from 0.16737 to 0.11434, saving model to G:\\lakemapping\\5_saved_models\\lakes_20240112-1629_AdaDelta_dice_loss_012345_572.h5\n",
      "1088/1088 [==============================] - 666s 612ms/step - loss: 0.1110 - dice_loss: 0.1109 - accuracy: 0.9942 - recall: 0.8981 - precision: 0.8931 - F1_score: 0.8892 - IoU: 0.8096 - val_loss: 0.1143 - val_dice_loss: 0.1142 - val_accuracy: 0.9938 - val_recall: 0.8621 - val_precision: 0.9251 - val_F1_score: 0.8858 - val_IoU: 0.8070\n",
      "Epoch 10/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.1068 - dice_loss: 0.1067 - accuracy: 0.9944 - recall: 0.8981 - precision: 0.9001 - F1_score: 0.8934 - IoU: 0.8156\n",
      "Epoch 10: val_loss did not improve from 0.11434\n",
      "1088/1088 [==============================] - 662s 608ms/step - loss: 0.1068 - dice_loss: 0.1067 - accuracy: 0.9944 - recall: 0.8981 - precision: 0.9001 - F1_score: 0.8934 - IoU: 0.8156 - val_loss: 0.1179 - val_dice_loss: 0.1177 - val_accuracy: 0.9933 - val_recall: 0.8850 - val_precision: 0.8935 - val_F1_score: 0.8823 - val_IoU: 0.8008\n",
      "Epoch 11/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0989 - dice_loss: 0.0988 - accuracy: 0.9949 - recall: 0.9082 - precision: 0.9044 - F1_score: 0.9013 - IoU: 0.8284\n",
      "Epoch 11: val_loss improved from 0.11434 to 0.09890, saving model to G:\\lakemapping\\5_saved_models\\lakes_20240112-1629_AdaDelta_dice_loss_012345_572.h5\n",
      "1088/1088 [==============================] - 671s 616ms/step - loss: 0.0989 - dice_loss: 0.0988 - accuracy: 0.9949 - recall: 0.9082 - precision: 0.9044 - F1_score: 0.9013 - IoU: 0.8284 - val_loss: 0.0989 - val_dice_loss: 0.0988 - val_accuracy: 0.9945 - val_recall: 0.8797 - val_precision: 0.9346 - val_F1_score: 0.9013 - val_IoU: 0.8289\n",
      "Epoch 12/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0971 - dice_loss: 0.0970 - accuracy: 0.9949 - recall: 0.9087 - precision: 0.9087 - F1_score: 0.9031 - IoU: 0.8316\n",
      "Epoch 12: val_loss did not improve from 0.09890\n",
      "1088/1088 [==============================] - 666s 612ms/step - loss: 0.0971 - dice_loss: 0.0970 - accuracy: 0.9949 - recall: 0.9087 - precision: 0.9087 - F1_score: 0.9031 - IoU: 0.8316 - val_loss: 0.1075 - val_dice_loss: 0.1073 - val_accuracy: 0.9937 - val_recall: 0.8946 - val_precision: 0.9030 - val_F1_score: 0.8927 - val_IoU: 0.8159\n",
      "Epoch 13/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0903 - dice_loss: 0.0902 - accuracy: 0.9951 - recall: 0.9172 - precision: 0.9120 - F1_score: 0.9099 - IoU: 0.8411\n",
      "Epoch 13: val_loss did not improve from 0.09890\n",
      "1088/1088 [==============================] - 670s 615ms/step - loss: 0.0903 - dice_loss: 0.0902 - accuracy: 0.9951 - recall: 0.9172 - precision: 0.9120 - F1_score: 0.9099 - IoU: 0.8411 - val_loss: 0.1263 - val_dice_loss: 0.1262 - val_accuracy: 0.9921 - val_recall: 0.9170 - val_precision: 0.8510 - val_F1_score: 0.8738 - val_IoU: 0.7877\n",
      "Epoch 14/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0875 - dice_loss: 0.0874 - accuracy: 0.9955 - recall: 0.9152 - precision: 0.9178 - F1_score: 0.9127 - IoU: 0.8452\n",
      "Epoch 14: val_loss did not improve from 0.09890\n",
      "1088/1088 [==============================] - 669s 614ms/step - loss: 0.0875 - dice_loss: 0.0874 - accuracy: 0.9955 - recall: 0.9152 - precision: 0.9178 - F1_score: 0.9127 - IoU: 0.8452 - val_loss: 0.0998 - val_dice_loss: 0.0997 - val_accuracy: 0.9942 - val_recall: 0.8994 - val_precision: 0.9123 - val_F1_score: 0.9003 - val_IoU: 0.8291\n",
      "Epoch 15/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0856 - dice_loss: 0.0855 - accuracy: 0.9956 - recall: 0.9167 - precision: 0.9195 - F1_score: 0.9146 - IoU: 0.8483\n",
      "Epoch 15: val_loss did not improve from 0.09890\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0856 - dice_loss: 0.0855 - accuracy: 0.9956 - recall: 0.9167 - precision: 0.9195 - F1_score: 0.9146 - IoU: 0.8483 - val_loss: 0.1479 - val_dice_loss: 0.1478 - val_accuracy: 0.9926 - val_recall: 0.7753 - val_precision: 0.9695 - val_F1_score: 0.8523 - val_IoU: 0.7574\n",
      "Epoch 16/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0864 - dice_loss: 0.0863 - accuracy: 0.9956 - recall: 0.9192 - precision: 0.9161 - F1_score: 0.9137 - IoU: 0.8479\n",
      "Epoch 16: val_loss did not improve from 0.09890\n",
      "1088/1088 [==============================] - 671s 617ms/step - loss: 0.0864 - dice_loss: 0.0863 - accuracy: 0.9956 - recall: 0.9192 - precision: 0.9161 - F1_score: 0.9137 - IoU: 0.8479 - val_loss: 0.1100 - val_dice_loss: 0.1099 - val_accuracy: 0.9939 - val_recall: 0.8857 - val_precision: 0.9067 - val_F1_score: 0.8901 - val_IoU: 0.8121\n",
      "Epoch 17/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0799 - dice_loss: 0.0799 - accuracy: 0.9957 - recall: 0.9224 - precision: 0.9249 - F1_score: 0.9202 - IoU: 0.8577\n",
      "Epoch 17: val_loss did not improve from 0.09890\n",
      "1088/1088 [==============================] - 666s 612ms/step - loss: 0.0799 - dice_loss: 0.0799 - accuracy: 0.9957 - recall: 0.9224 - precision: 0.9249 - F1_score: 0.9202 - IoU: 0.8577 - val_loss: 0.1120 - val_dice_loss: 0.1119 - val_accuracy: 0.9940 - val_recall: 0.8510 - val_precision: 0.9451 - val_F1_score: 0.8881 - val_IoU: 0.8112\n",
      "Epoch 18/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0779 - dice_loss: 0.0778 - accuracy: 0.9959 - recall: 0.9235 - precision: 0.9268 - F1_score: 0.9223 - IoU: 0.8607\n",
      "Epoch 18: val_loss did not improve from 0.09890\n",
      "1088/1088 [==============================] - 666s 611ms/step - loss: 0.0779 - dice_loss: 0.0778 - accuracy: 0.9959 - recall: 0.9235 - precision: 0.9268 - F1_score: 0.9223 - IoU: 0.8607 - val_loss: 0.1024 - val_dice_loss: 0.1024 - val_accuracy: 0.9943 - val_recall: 0.8645 - val_precision: 0.9454 - val_F1_score: 0.8977 - val_IoU: 0.8240\n",
      "Epoch 19/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0784 - dice_loss: 0.0784 - accuracy: 0.9959 - recall: 0.9244 - precision: 0.9251 - F1_score: 0.9217 - IoU: 0.8600\n",
      "Epoch 19: val_loss did not improve from 0.09890\n",
      "1088/1088 [==============================] - 667s 613ms/step - loss: 0.0784 - dice_loss: 0.0784 - accuracy: 0.9959 - recall: 0.9244 - precision: 0.9251 - F1_score: 0.9217 - IoU: 0.8600 - val_loss: 0.1071 - val_dice_loss: 0.1070 - val_accuracy: 0.9941 - val_recall: 0.8951 - val_precision: 0.9033 - val_F1_score: 0.8930 - val_IoU: 0.8183\n",
      "Epoch 20/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0753 - dice_loss: 0.0752 - accuracy: 0.9962 - recall: 0.9257 - precision: 0.9302 - F1_score: 0.9249 - IoU: 0.8654\n",
      "Epoch 20: val_loss did not improve from 0.09890\n",
      "1088/1088 [==============================] - 666s 612ms/step - loss: 0.0753 - dice_loss: 0.0752 - accuracy: 0.9962 - recall: 0.9257 - precision: 0.9302 - F1_score: 0.9249 - IoU: 0.8654 - val_loss: 0.1203 - val_dice_loss: 0.1202 - val_accuracy: 0.9937 - val_recall: 0.8596 - val_precision: 0.9205 - val_F1_score: 0.8798 - val_IoU: 0.8000\n",
      "Epoch 21/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0758 - dice_loss: 0.0757 - accuracy: 0.9959 - recall: 0.9257 - precision: 0.9290 - F1_score: 0.9244 - IoU: 0.8643\n",
      "Epoch 21: val_loss improved from 0.09890 to 0.09612, saving model to G:\\lakemapping\\5_saved_models\\lakes_20240112-1629_AdaDelta_dice_loss_012345_572.h5\n",
      "1088/1088 [==============================] - 669s 614ms/step - loss: 0.0758 - dice_loss: 0.0757 - accuracy: 0.9959 - recall: 0.9257 - precision: 0.9290 - F1_score: 0.9244 - IoU: 0.8643 - val_loss: 0.0961 - val_dice_loss: 0.0960 - val_accuracy: 0.9946 - val_recall: 0.9081 - val_precision: 0.9099 - val_F1_score: 0.9040 - val_IoU: 0.8344\n",
      "Epoch 22/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0750 - dice_loss: 0.0749 - accuracy: 0.9962 - recall: 0.9275 - precision: 0.9288 - F1_score: 0.9251 - IoU: 0.8656\n",
      "Epoch 22: val_loss did not improve from 0.09612\n",
      "1088/1088 [==============================] - 665s 610ms/step - loss: 0.0750 - dice_loss: 0.0749 - accuracy: 0.9962 - recall: 0.9275 - precision: 0.9288 - F1_score: 0.9251 - IoU: 0.8656 - val_loss: 0.1292 - val_dice_loss: 0.1291 - val_accuracy: 0.9922 - val_recall: 0.8931 - val_precision: 0.8714 - val_F1_score: 0.8710 - val_IoU: 0.7885\n",
      "Epoch 23/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0745 - dice_loss: 0.0744 - accuracy: 0.9962 - recall: 0.9284 - precision: 0.9291 - F1_score: 0.9257 - IoU: 0.8666\n",
      "Epoch 23: val_loss did not improve from 0.09612\n",
      "1088/1088 [==============================] - 663s 609ms/step - loss: 0.0745 - dice_loss: 0.0744 - accuracy: 0.9962 - recall: 0.9284 - precision: 0.9291 - F1_score: 0.9257 - IoU: 0.8666 - val_loss: 0.1138 - val_dice_loss: 0.1138 - val_accuracy: 0.9938 - val_recall: 0.8671 - val_precision: 0.9226 - val_F1_score: 0.8863 - val_IoU: 0.8085\n",
      "Epoch 24/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0692 - dice_loss: 0.0691 - accuracy: 0.9964 - recall: 0.9309 - precision: 0.9352 - F1_score: 0.9309 - IoU: 0.8741\n",
      "Epoch 24: val_loss did not improve from 0.09612\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0692 - dice_loss: 0.0691 - accuracy: 0.9964 - recall: 0.9309 - precision: 0.9352 - F1_score: 0.9309 - IoU: 0.8741 - val_loss: 0.1079 - val_dice_loss: 0.1078 - val_accuracy: 0.9942 - val_recall: 0.8927 - val_precision: 0.9037 - val_F1_score: 0.8922 - val_IoU: 0.8158\n",
      "Epoch 25/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0718 - dice_loss: 0.0718 - accuracy: 0.9963 - recall: 0.9299 - precision: 0.9321 - F1_score: 0.9283 - IoU: 0.8705\n",
      "Epoch 25: val_loss improved from 0.09612 to 0.09532, saving model to G:\\lakemapping\\5_saved_models\\lakes_20240112-1629_AdaDelta_dice_loss_012345_572.h5\n",
      "1088/1088 [==============================] - 669s 615ms/step - loss: 0.0718 - dice_loss: 0.0718 - accuracy: 0.9963 - recall: 0.9299 - precision: 0.9321 - F1_score: 0.9283 - IoU: 0.8705 - val_loss: 0.0953 - val_dice_loss: 0.0952 - val_accuracy: 0.9950 - val_recall: 0.8733 - val_precision: 0.9482 - val_F1_score: 0.9048 - val_IoU: 0.8352\n",
      "Epoch 26/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0679 - dice_loss: 0.0678 - accuracy: 0.9965 - recall: 0.9338 - precision: 0.9347 - F1_score: 0.9322 - IoU: 0.8767\n",
      "Epoch 26: val_loss did not improve from 0.09532\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0679 - dice_loss: 0.0678 - accuracy: 0.9965 - recall: 0.9338 - precision: 0.9347 - F1_score: 0.9322 - IoU: 0.8767 - val_loss: 0.0994 - val_dice_loss: 0.0993 - val_accuracy: 0.9946 - val_recall: 0.9053 - val_precision: 0.9090 - val_F1_score: 0.9007 - val_IoU: 0.8293\n",
      "Epoch 27/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0731 - dice_loss: 0.0730 - accuracy: 0.9963 - recall: 0.9280 - precision: 0.9313 - F1_score: 0.9270 - IoU: 0.8688\n",
      "Epoch 27: val_loss did not improve from 0.09532\n",
      "1088/1088 [==============================] - 666s 612ms/step - loss: 0.0731 - dice_loss: 0.0730 - accuracy: 0.9963 - recall: 0.9280 - precision: 0.9313 - F1_score: 0.9270 - IoU: 0.8688 - val_loss: 0.1137 - val_dice_loss: 0.1136 - val_accuracy: 0.9941 - val_recall: 0.8804 - val_precision: 0.9057 - val_F1_score: 0.8865 - val_IoU: 0.8070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0708 - dice_loss: 0.0708 - accuracy: 0.9963 - recall: 0.9312 - precision: 0.9322 - F1_score: 0.9293 - IoU: 0.8720\n",
      "Epoch 28: val_loss did not improve from 0.09532\n",
      "1088/1088 [==============================] - 666s 612ms/step - loss: 0.0708 - dice_loss: 0.0708 - accuracy: 0.9963 - recall: 0.9312 - precision: 0.9322 - F1_score: 0.9293 - IoU: 0.8720 - val_loss: 0.1253 - val_dice_loss: 0.1252 - val_accuracy: 0.9925 - val_recall: 0.8572 - val_precision: 0.9109 - val_F1_score: 0.8748 - val_IoU: 0.7911\n",
      "Epoch 29/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0645 - dice_loss: 0.0645 - accuracy: 0.9966 - recall: 0.9350 - precision: 0.9400 - F1_score: 0.9356 - IoU: 0.8823\n",
      "Epoch 29: val_loss did not improve from 0.09532\n",
      "1088/1088 [==============================] - 665s 611ms/step - loss: 0.0645 - dice_loss: 0.0645 - accuracy: 0.9966 - recall: 0.9350 - precision: 0.9400 - F1_score: 0.9356 - IoU: 0.8823 - val_loss: 0.1042 - val_dice_loss: 0.1041 - val_accuracy: 0.9943 - val_recall: 0.8796 - val_precision: 0.9262 - val_F1_score: 0.8959 - val_IoU: 0.8221\n",
      "Epoch 30/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0645 - dice_loss: 0.0644 - accuracy: 0.9966 - recall: 0.9356 - precision: 0.9395 - F1_score: 0.9356 - IoU: 0.8823\n",
      "Epoch 30: val_loss did not improve from 0.09532\n",
      "1088/1088 [==============================] - 667s 613ms/step - loss: 0.0645 - dice_loss: 0.0644 - accuracy: 0.9966 - recall: 0.9356 - precision: 0.9395 - F1_score: 0.9356 - IoU: 0.8823 - val_loss: 0.0986 - val_dice_loss: 0.0985 - val_accuracy: 0.9946 - val_recall: 0.8954 - val_precision: 0.9196 - val_F1_score: 0.9015 - val_IoU: 0.8298\n",
      "Epoch 31/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0628 - dice_loss: 0.0627 - accuracy: 0.9968 - recall: 0.9373 - precision: 0.9407 - F1_score: 0.9373 - IoU: 0.8853\n",
      "Epoch 31: val_loss did not improve from 0.09532\n",
      "1088/1088 [==============================] - 666s 612ms/step - loss: 0.0628 - dice_loss: 0.0627 - accuracy: 0.9968 - recall: 0.9373 - precision: 0.9407 - F1_score: 0.9373 - IoU: 0.8853 - val_loss: 0.0986 - val_dice_loss: 0.0985 - val_accuracy: 0.9946 - val_recall: 0.8903 - val_precision: 0.9278 - val_F1_score: 0.9015 - val_IoU: 0.8332\n",
      "Epoch 32/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0616 - dice_loss: 0.0615 - accuracy: 0.9967 - recall: 0.9376 - precision: 0.9427 - F1_score: 0.9385 - IoU: 0.8867\n",
      "Epoch 32: val_loss improved from 0.09532 to 0.08891, saving model to G:\\lakemapping\\5_saved_models\\lakes_20240112-1629_AdaDelta_dice_loss_012345_572.h5\n",
      "1088/1088 [==============================] - 669s 615ms/step - loss: 0.0616 - dice_loss: 0.0615 - accuracy: 0.9967 - recall: 0.9376 - precision: 0.9427 - F1_score: 0.9385 - IoU: 0.8867 - val_loss: 0.0889 - val_dice_loss: 0.0889 - val_accuracy: 0.9952 - val_recall: 0.8871 - val_precision: 0.9448 - val_F1_score: 0.9112 - val_IoU: 0.8441\n",
      "Epoch 33/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0624 - dice_loss: 0.0623 - accuracy: 0.9968 - recall: 0.9386 - precision: 0.9403 - F1_score: 0.9377 - IoU: 0.8862\n",
      "Epoch 33: val_loss did not improve from 0.08891\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0624 - dice_loss: 0.0623 - accuracy: 0.9968 - recall: 0.9386 - precision: 0.9403 - F1_score: 0.9377 - IoU: 0.8862 - val_loss: 0.0981 - val_dice_loss: 0.0980 - val_accuracy: 0.9948 - val_recall: 0.8803 - val_precision: 0.9382 - val_F1_score: 0.9020 - val_IoU: 0.8322\n",
      "Epoch 34/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0598 - dice_loss: 0.0598 - accuracy: 0.9968 - recall: 0.9401 - precision: 0.9432 - F1_score: 0.9403 - IoU: 0.8898\n",
      "Epoch 34: val_loss did not improve from 0.08891\n",
      "1088/1088 [==============================] - 666s 611ms/step - loss: 0.0598 - dice_loss: 0.0598 - accuracy: 0.9968 - recall: 0.9401 - precision: 0.9432 - F1_score: 0.9403 - IoU: 0.8898 - val_loss: 0.1023 - val_dice_loss: 0.1022 - val_accuracy: 0.9949 - val_recall: 0.8767 - val_precision: 0.9337 - val_F1_score: 0.8978 - val_IoU: 0.8258\n",
      "Epoch 35/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0650 - dice_loss: 0.0649 - accuracy: 0.9968 - recall: 0.9370 - precision: 0.9370 - F1_score: 0.9351 - IoU: 0.8818\n",
      "Epoch 35: val_loss did not improve from 0.08891\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0650 - dice_loss: 0.0649 - accuracy: 0.9968 - recall: 0.9370 - precision: 0.9370 - F1_score: 0.9351 - IoU: 0.8818 - val_loss: 0.0945 - val_dice_loss: 0.0944 - val_accuracy: 0.9945 - val_recall: 0.8962 - val_precision: 0.9274 - val_F1_score: 0.9056 - val_IoU: 0.8380\n",
      "Epoch 36/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0615 - dice_loss: 0.0614 - accuracy: 0.9968 - recall: 0.9390 - precision: 0.9414 - F1_score: 0.9386 - IoU: 0.8874\n",
      "Epoch 36: val_loss did not improve from 0.08891\n",
      "1088/1088 [==============================] - 663s 609ms/step - loss: 0.0615 - dice_loss: 0.0614 - accuracy: 0.9968 - recall: 0.9390 - precision: 0.9414 - F1_score: 0.9386 - IoU: 0.8874 - val_loss: 0.0936 - val_dice_loss: 0.0936 - val_accuracy: 0.9949 - val_recall: 0.9082 - val_precision: 0.9179 - val_F1_score: 0.9065 - val_IoU: 0.8396\n",
      "Epoch 37/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0591 - dice_loss: 0.0590 - accuracy: 0.9969 - recall: 0.9410 - precision: 0.9438 - F1_score: 0.9410 - IoU: 0.8910\n",
      "Epoch 37: val_loss did not improve from 0.08891\n",
      "1088/1088 [==============================] - 663s 609ms/step - loss: 0.0591 - dice_loss: 0.0590 - accuracy: 0.9969 - recall: 0.9410 - precision: 0.9438 - F1_score: 0.9410 - IoU: 0.8910 - val_loss: 0.1031 - val_dice_loss: 0.1031 - val_accuracy: 0.9947 - val_recall: 0.8863 - val_precision: 0.9184 - val_F1_score: 0.8970 - val_IoU: 0.8242\n",
      "Epoch 38/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0612 - dice_loss: 0.0611 - accuracy: 0.9969 - recall: 0.9391 - precision: 0.9427 - F1_score: 0.9389 - IoU: 0.8884\n",
      "Epoch 38: val_loss did not improve from 0.08891\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0612 - dice_loss: 0.0611 - accuracy: 0.9969 - recall: 0.9391 - precision: 0.9427 - F1_score: 0.9389 - IoU: 0.8884 - val_loss: 0.0945 - val_dice_loss: 0.0945 - val_accuracy: 0.9948 - val_recall: 0.8865 - val_precision: 0.9388 - val_F1_score: 0.9056 - val_IoU: 0.8382\n",
      "Epoch 39/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0585 - dice_loss: 0.0585 - accuracy: 0.9970 - recall: 0.9417 - precision: 0.9450 - F1_score: 0.9416 - IoU: 0.8928\n",
      "Epoch 39: val_loss did not improve from 0.08891\n",
      "1088/1088 [==============================] - 666s 612ms/step - loss: 0.0585 - dice_loss: 0.0585 - accuracy: 0.9970 - recall: 0.9417 - precision: 0.9450 - F1_score: 0.9416 - IoU: 0.8928 - val_loss: 0.0982 - val_dice_loss: 0.0981 - val_accuracy: 0.9945 - val_recall: 0.9082 - val_precision: 0.9069 - val_F1_score: 0.9019 - val_IoU: 0.8332\n",
      "Epoch 40/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0584 - dice_loss: 0.0584 - accuracy: 0.9970 - recall: 0.9411 - precision: 0.9448 - F1_score: 0.9417 - IoU: 0.8922\n",
      "Epoch 40: val_loss did not improve from 0.08891\n",
      "1088/1088 [==============================] - 672s 617ms/step - loss: 0.0584 - dice_loss: 0.0584 - accuracy: 0.9970 - recall: 0.9411 - precision: 0.9448 - F1_score: 0.9417 - IoU: 0.8922 - val_loss: 0.1015 - val_dice_loss: 0.1014 - val_accuracy: 0.9947 - val_recall: 0.8880 - val_precision: 0.9223 - val_F1_score: 0.8986 - val_IoU: 0.8262\n",
      "Epoch 41/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0582 - dice_loss: 0.0581 - accuracy: 0.9970 - recall: 0.9433 - precision: 0.9438 - F1_score: 0.9419 - IoU: 0.8931\n",
      "Epoch 41: val_loss improved from 0.08891 to 0.08783, saving model to G:\\lakemapping\\5_saved_models\\lakes_20240112-1629_AdaDelta_dice_loss_012345_572.h5\n",
      "1088/1088 [==============================] - 668s 614ms/step - loss: 0.0582 - dice_loss: 0.0581 - accuracy: 0.9970 - recall: 0.9433 - precision: 0.9438 - F1_score: 0.9419 - IoU: 0.8931 - val_loss: 0.0878 - val_dice_loss: 0.0878 - val_accuracy: 0.9950 - val_recall: 0.9001 - val_precision: 0.9360 - val_F1_score: 0.9123 - val_IoU: 0.8490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0574 - dice_loss: 0.0574 - accuracy: 0.9970 - recall: 0.9432 - precision: 0.9453 - F1_score: 0.9427 - IoU: 0.8947\n",
      "Epoch 42: val_loss did not improve from 0.08783\n",
      "1088/1088 [==============================] - 666s 611ms/step - loss: 0.0574 - dice_loss: 0.0574 - accuracy: 0.9970 - recall: 0.9432 - precision: 0.9453 - F1_score: 0.9427 - IoU: 0.8947 - val_loss: 0.1063 - val_dice_loss: 0.1063 - val_accuracy: 0.9942 - val_recall: 0.9005 - val_precision: 0.9021 - val_F1_score: 0.8938 - val_IoU: 0.8211\n",
      "Epoch 43/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0574 - dice_loss: 0.0574 - accuracy: 0.9970 - recall: 0.9420 - precision: 0.9460 - F1_score: 0.9426 - IoU: 0.8939\n",
      "Epoch 43: val_loss did not improve from 0.08783\n",
      "1088/1088 [==============================] - 663s 609ms/step - loss: 0.0574 - dice_loss: 0.0574 - accuracy: 0.9970 - recall: 0.9420 - precision: 0.9460 - F1_score: 0.9426 - IoU: 0.8939 - val_loss: 0.1059 - val_dice_loss: 0.1058 - val_accuracy: 0.9938 - val_recall: 0.8989 - val_precision: 0.9027 - val_F1_score: 0.8942 - val_IoU: 0.8199\n",
      "Epoch 44/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0566 - dice_loss: 0.0565 - accuracy: 0.9971 - recall: 0.9445 - precision: 0.9456 - F1_score: 0.9435 - IoU: 0.8960\n",
      "Epoch 44: val_loss did not improve from 0.08783\n",
      "1088/1088 [==============================] - 665s 611ms/step - loss: 0.0566 - dice_loss: 0.0565 - accuracy: 0.9971 - recall: 0.9445 - precision: 0.9456 - F1_score: 0.9435 - IoU: 0.8960 - val_loss: 0.0963 - val_dice_loss: 0.0962 - val_accuracy: 0.9947 - val_recall: 0.8966 - val_precision: 0.9258 - val_F1_score: 0.9038 - val_IoU: 0.8365\n",
      "Epoch 45/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0586 - dice_loss: 0.0586 - accuracy: 0.9971 - recall: 0.9418 - precision: 0.9441 - F1_score: 0.9415 - IoU: 0.8922\n",
      "Epoch 45: val_loss did not improve from 0.08783\n",
      "1088/1088 [==============================] - 665s 611ms/step - loss: 0.0586 - dice_loss: 0.0586 - accuracy: 0.9971 - recall: 0.9418 - precision: 0.9441 - F1_score: 0.9415 - IoU: 0.8922 - val_loss: 0.0953 - val_dice_loss: 0.0952 - val_accuracy: 0.9944 - val_recall: 0.9005 - val_precision: 0.9206 - val_F1_score: 0.9048 - val_IoU: 0.8366\n",
      "Epoch 46/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0569 - dice_loss: 0.0569 - accuracy: 0.9971 - recall: 0.9424 - precision: 0.9466 - F1_score: 0.9432 - IoU: 0.8949\n",
      "Epoch 46: val_loss did not improve from 0.08783\n",
      "1088/1088 [==============================] - 660s 606ms/step - loss: 0.0569 - dice_loss: 0.0569 - accuracy: 0.9971 - recall: 0.9424 - precision: 0.9466 - F1_score: 0.9432 - IoU: 0.8949 - val_loss: 0.0929 - val_dice_loss: 0.0928 - val_accuracy: 0.9946 - val_recall: 0.8954 - val_precision: 0.9307 - val_F1_score: 0.9072 - val_IoU: 0.8391\n",
      "Epoch 47/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0584 - dice_loss: 0.0583 - accuracy: 0.9971 - recall: 0.9422 - precision: 0.9441 - F1_score: 0.9417 - IoU: 0.8930\n",
      "Epoch 47: val_loss did not improve from 0.08783\n",
      "1088/1088 [==============================] - 662s 608ms/step - loss: 0.0584 - dice_loss: 0.0583 - accuracy: 0.9971 - recall: 0.9422 - precision: 0.9441 - F1_score: 0.9417 - IoU: 0.8930 - val_loss: 0.0887 - val_dice_loss: 0.0886 - val_accuracy: 0.9952 - val_recall: 0.9099 - val_precision: 0.9228 - val_F1_score: 0.9114 - val_IoU: 0.8453\n",
      "Epoch 48/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0555 - dice_loss: 0.0554 - accuracy: 0.9972 - recall: 0.9441 - precision: 0.9477 - F1_score: 0.9446 - IoU: 0.8978\n",
      "Epoch 48: val_loss improved from 0.08783 to 0.08277, saving model to G:\\lakemapping\\5_saved_models\\lakes_20240112-1629_AdaDelta_dice_loss_012345_572.h5\n",
      "1088/1088 [==============================] - 668s 614ms/step - loss: 0.0555 - dice_loss: 0.0554 - accuracy: 0.9972 - recall: 0.9441 - precision: 0.9477 - F1_score: 0.9446 - IoU: 0.8978 - val_loss: 0.0828 - val_dice_loss: 0.0827 - val_accuracy: 0.9952 - val_recall: 0.9208 - val_precision: 0.9244 - val_F1_score: 0.9173 - val_IoU: 0.8571\n",
      "Epoch 49/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0570 - dice_loss: 0.0569 - accuracy: 0.9971 - recall: 0.9432 - precision: 0.9458 - F1_score: 0.9431 - IoU: 0.8952\n",
      "Epoch 49: val_loss did not improve from 0.08277\n",
      "1088/1088 [==============================] - 661s 607ms/step - loss: 0.0570 - dice_loss: 0.0569 - accuracy: 0.9971 - recall: 0.9432 - precision: 0.9458 - F1_score: 0.9431 - IoU: 0.8952 - val_loss: 0.0986 - val_dice_loss: 0.0986 - val_accuracy: 0.9950 - val_recall: 0.8854 - val_precision: 0.9309 - val_F1_score: 0.9014 - val_IoU: 0.8327\n",
      "Epoch 50/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0537 - dice_loss: 0.0537 - accuracy: 0.9971 - recall: 0.9455 - precision: 0.9495 - F1_score: 0.9464 - IoU: 0.9002\n",
      "Epoch 50: val_loss did not improve from 0.08277\n",
      "1088/1088 [==============================] - 665s 611ms/step - loss: 0.0537 - dice_loss: 0.0537 - accuracy: 0.9971 - recall: 0.9455 - precision: 0.9495 - F1_score: 0.9464 - IoU: 0.9002 - val_loss: 0.0856 - val_dice_loss: 0.0855 - val_accuracy: 0.9952 - val_recall: 0.9124 - val_precision: 0.9250 - val_F1_score: 0.9145 - val_IoU: 0.8503\n",
      "Epoch 51/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0549 - dice_loss: 0.0549 - accuracy: 0.9972 - recall: 0.9457 - precision: 0.9471 - F1_score: 0.9452 - IoU: 0.8985\n",
      "Epoch 51: val_loss did not improve from 0.08277\n",
      "1088/1088 [==============================] - 666s 611ms/step - loss: 0.0549 - dice_loss: 0.0549 - accuracy: 0.9972 - recall: 0.9457 - precision: 0.9471 - F1_score: 0.9452 - IoU: 0.8985 - val_loss: 0.0988 - val_dice_loss: 0.0988 - val_accuracy: 0.9946 - val_recall: 0.8797 - val_precision: 0.9383 - val_F1_score: 0.9013 - val_IoU: 0.8322\n",
      "Epoch 52/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0545 - dice_loss: 0.0545 - accuracy: 0.9972 - recall: 0.9455 - precision: 0.9480 - F1_score: 0.9456 - IoU: 0.8991\n",
      "Epoch 52: val_loss did not improve from 0.08277\n",
      "1088/1088 [==============================] - 665s 611ms/step - loss: 0.0545 - dice_loss: 0.0545 - accuracy: 0.9972 - recall: 0.9455 - precision: 0.9480 - F1_score: 0.9456 - IoU: 0.8991 - val_loss: 0.0903 - val_dice_loss: 0.0903 - val_accuracy: 0.9948 - val_recall: 0.8892 - val_precision: 0.9416 - val_F1_score: 0.9097 - val_IoU: 0.8433\n",
      "Epoch 53/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0565 - dice_loss: 0.0564 - accuracy: 0.9972 - recall: 0.9444 - precision: 0.9466 - F1_score: 0.9436 - IoU: 0.8968\n",
      "Epoch 53: val_loss did not improve from 0.08277\n",
      "1088/1088 [==============================] - 665s 611ms/step - loss: 0.0565 - dice_loss: 0.0564 - accuracy: 0.9972 - recall: 0.9444 - precision: 0.9466 - F1_score: 0.9436 - IoU: 0.8968 - val_loss: 0.0929 - val_dice_loss: 0.0929 - val_accuracy: 0.9948 - val_recall: 0.8963 - val_precision: 0.9293 - val_F1_score: 0.9072 - val_IoU: 0.8398\n",
      "Epoch 54/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0521 - dice_loss: 0.0521 - accuracy: 0.9973 - recall: 0.9480 - precision: 0.9506 - F1_score: 0.9480 - IoU: 0.9037\n",
      "Epoch 54: val_loss did not improve from 0.08277\n",
      "1088/1088 [==============================] - 665s 611ms/step - loss: 0.0521 - dice_loss: 0.0521 - accuracy: 0.9973 - recall: 0.9480 - precision: 0.9506 - F1_score: 0.9480 - IoU: 0.9037 - val_loss: 0.0946 - val_dice_loss: 0.0946 - val_accuracy: 0.9950 - val_recall: 0.8844 - val_precision: 0.9398 - val_F1_score: 0.9055 - val_IoU: 0.8373\n",
      "Epoch 55/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0513 - dice_loss: 0.0512 - accuracy: 0.9973 - recall: 0.9493 - precision: 0.9505 - F1_score: 0.9488 - IoU: 0.9050\n",
      "Epoch 55: val_loss did not improve from 0.08277\n",
      "1088/1088 [==============================] - 666s 612ms/step - loss: 0.0513 - dice_loss: 0.0512 - accuracy: 0.9973 - recall: 0.9493 - precision: 0.9505 - F1_score: 0.9488 - IoU: 0.9050 - val_loss: 0.0905 - val_dice_loss: 0.0904 - val_accuracy: 0.9949 - val_recall: 0.9062 - val_precision: 0.9235 - val_F1_score: 0.9096 - val_IoU: 0.8440\n",
      "Epoch 56/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0521 - dice_loss: 0.0520 - accuracy: 0.9974 - recall: 0.9481 - precision: 0.9499 - F1_score: 0.9480 - IoU: 0.9033\n",
      "Epoch 56: val_loss did not improve from 0.08277\n",
      "1088/1088 [==============================] - 669s 615ms/step - loss: 0.0521 - dice_loss: 0.0520 - accuracy: 0.9974 - recall: 0.9481 - precision: 0.9499 - F1_score: 0.9480 - IoU: 0.9033 - val_loss: 0.0913 - val_dice_loss: 0.0913 - val_accuracy: 0.9947 - val_recall: 0.8920 - val_precision: 0.9371 - val_F1_score: 0.9088 - val_IoU: 0.8428\n",
      "Epoch 57/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0527 - dice_loss: 0.0527 - accuracy: 0.9973 - recall: 0.9469 - precision: 0.9500 - F1_score: 0.9473 - IoU: 0.9022\n",
      "Epoch 57: val_loss did not improve from 0.08277\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0527 - dice_loss: 0.0527 - accuracy: 0.9973 - recall: 0.9469 - precision: 0.9500 - F1_score: 0.9473 - IoU: 0.9022 - val_loss: 0.1065 - val_dice_loss: 0.1065 - val_accuracy: 0.9941 - val_recall: 0.8562 - val_precision: 0.9469 - val_F1_score: 0.8935 - val_IoU: 0.8176\n",
      "Epoch 58/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0512 - dice_loss: 0.0511 - accuracy: 0.9974 - recall: 0.9480 - precision: 0.9516 - F1_score: 0.9489 - IoU: 0.9048\n",
      "Epoch 58: val_loss did not improve from 0.08277\n",
      "1088/1088 [==============================] - 658s 605ms/step - loss: 0.0512 - dice_loss: 0.0511 - accuracy: 0.9974 - recall: 0.9480 - precision: 0.9516 - F1_score: 0.9489 - IoU: 0.9048 - val_loss: 0.0916 - val_dice_loss: 0.0915 - val_accuracy: 0.9949 - val_recall: 0.9181 - val_precision: 0.9097 - val_F1_score: 0.9085 - val_IoU: 0.8425\n",
      "Epoch 59/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0498 - dice_loss: 0.0497 - accuracy: 0.9974 - recall: 0.9496 - precision: 0.9531 - F1_score: 0.9503 - IoU: 0.9073\n",
      "Epoch 59: val_loss did not improve from 0.08277\n",
      "1088/1088 [==============================] - 656s 602ms/step - loss: 0.0498 - dice_loss: 0.0497 - accuracy: 0.9974 - recall: 0.9496 - precision: 0.9531 - F1_score: 0.9503 - IoU: 0.9073 - val_loss: 0.0848 - val_dice_loss: 0.0848 - val_accuracy: 0.9954 - val_recall: 0.9033 - val_precision: 0.9381 - val_F1_score: 0.9153 - val_IoU: 0.8525\n",
      "Epoch 60/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0508 - dice_loss: 0.0507 - accuracy: 0.9974 - recall: 0.9495 - precision: 0.9510 - F1_score: 0.9493 - IoU: 0.9054\n",
      "Epoch 60: val_loss did not improve from 0.08277\n",
      "1088/1088 [==============================] - 654s 601ms/step - loss: 0.0508 - dice_loss: 0.0507 - accuracy: 0.9974 - recall: 0.9495 - precision: 0.9510 - F1_score: 0.9493 - IoU: 0.9054 - val_loss: 0.0845 - val_dice_loss: 0.0844 - val_accuracy: 0.9951 - val_recall: 0.9224 - val_precision: 0.9181 - val_F1_score: 0.9156 - val_IoU: 0.8525\n",
      "Epoch 61/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0513 - dice_loss: 0.0512 - accuracy: 0.9974 - recall: 0.9467 - precision: 0.9528 - F1_score: 0.9488 - IoU: 0.9045\n",
      "Epoch 61: val_loss did not improve from 0.08277\n",
      "1088/1088 [==============================] - 657s 604ms/step - loss: 0.0513 - dice_loss: 0.0512 - accuracy: 0.9974 - recall: 0.9467 - precision: 0.9528 - F1_score: 0.9488 - IoU: 0.9045 - val_loss: 0.1082 - val_dice_loss: 0.1082 - val_accuracy: 0.9944 - val_recall: 0.9051 - val_precision: 0.8982 - val_F1_score: 0.8918 - val_IoU: 0.8199\n",
      "Epoch 62/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0492 - dice_loss: 0.0491 - accuracy: 0.9974 - recall: 0.9507 - precision: 0.9528 - F1_score: 0.9509 - IoU: 0.9081\n",
      "Epoch 62: val_loss did not improve from 0.08277\n",
      "1088/1088 [==============================] - 658s 604ms/step - loss: 0.0492 - dice_loss: 0.0491 - accuracy: 0.9974 - recall: 0.9507 - precision: 0.9528 - F1_score: 0.9509 - IoU: 0.9081 - val_loss: 0.0896 - val_dice_loss: 0.0896 - val_accuracy: 0.9949 - val_recall: 0.9127 - val_precision: 0.9203 - val_F1_score: 0.9104 - val_IoU: 0.8463\n",
      "Epoch 63/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0519 - dice_loss: 0.0519 - accuracy: 0.9974 - recall: 0.9481 - precision: 0.9502 - F1_score: 0.9481 - IoU: 0.9034\n",
      "Epoch 63: val_loss did not improve from 0.08277\n",
      "1088/1088 [==============================] - 661s 608ms/step - loss: 0.0519 - dice_loss: 0.0519 - accuracy: 0.9974 - recall: 0.9481 - precision: 0.9502 - F1_score: 0.9481 - IoU: 0.9034 - val_loss: 0.0866 - val_dice_loss: 0.0866 - val_accuracy: 0.9952 - val_recall: 0.8911 - val_precision: 0.9462 - val_F1_score: 0.9134 - val_IoU: 0.8489\n",
      "Epoch 64/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0499 - dice_loss: 0.0498 - accuracy: 0.9974 - recall: 0.9492 - precision: 0.9530 - F1_score: 0.9502 - IoU: 0.9071\n",
      "Epoch 64: val_loss improved from 0.08277 to 0.07818, saving model to G:\\lakemapping\\5_saved_models\\lakes_20240112-1629_AdaDelta_dice_loss_012345_572.h5\n",
      "1088/1088 [==============================] - 667s 612ms/step - loss: 0.0499 - dice_loss: 0.0498 - accuracy: 0.9974 - recall: 0.9492 - precision: 0.9530 - F1_score: 0.9502 - IoU: 0.9071 - val_loss: 0.0782 - val_dice_loss: 0.0781 - val_accuracy: 0.9955 - val_recall: 0.9101 - val_precision: 0.9412 - val_F1_score: 0.9219 - val_IoU: 0.8609\n",
      "Epoch 65/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0485 - dice_loss: 0.0485 - accuracy: 0.9975 - recall: 0.9508 - precision: 0.9538 - F1_score: 0.9516 - IoU: 0.9092\n",
      "Epoch 65: val_loss did not improve from 0.07818\n",
      "1088/1088 [==============================] - 665s 611ms/step - loss: 0.0485 - dice_loss: 0.0485 - accuracy: 0.9975 - recall: 0.9508 - precision: 0.9538 - F1_score: 0.9516 - IoU: 0.9092 - val_loss: 0.0950 - val_dice_loss: 0.0950 - val_accuracy: 0.9946 - val_recall: 0.8993 - val_precision: 0.9238 - val_F1_score: 0.9051 - val_IoU: 0.8367\n",
      "Epoch 66/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0497 - dice_loss: 0.0497 - accuracy: 0.9975 - recall: 0.9497 - precision: 0.9528 - F1_score: 0.9504 - IoU: 0.9073\n",
      "Epoch 66: val_loss did not improve from 0.07818\n",
      "1088/1088 [==============================] - 668s 614ms/step - loss: 0.0497 - dice_loss: 0.0497 - accuracy: 0.9975 - recall: 0.9497 - precision: 0.9528 - F1_score: 0.9504 - IoU: 0.9073 - val_loss: 0.0820 - val_dice_loss: 0.0820 - val_accuracy: 0.9954 - val_recall: 0.9184 - val_precision: 0.9264 - val_F1_score: 0.9180 - val_IoU: 0.8555\n",
      "Epoch 67/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0479 - dice_loss: 0.0479 - accuracy: 0.9975 - recall: 0.9513 - precision: 0.9547 - F1_score: 0.9522 - IoU: 0.9104\n",
      "Epoch 67: val_loss did not improve from 0.07818\n",
      "1088/1088 [==============================] - 662s 608ms/step - loss: 0.0479 - dice_loss: 0.0479 - accuracy: 0.9975 - recall: 0.9513 - precision: 0.9547 - F1_score: 0.9522 - IoU: 0.9104 - val_loss: 0.0978 - val_dice_loss: 0.0977 - val_accuracy: 0.9948 - val_recall: 0.8896 - val_precision: 0.9276 - val_F1_score: 0.9023 - val_IoU: 0.8334\n",
      "Epoch 68/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0472 - dice_loss: 0.0471 - accuracy: 0.9976 - recall: 0.9533 - precision: 0.9542 - F1_score: 0.9529 - IoU: 0.9117\n",
      "Epoch 68: val_loss did not improve from 0.07818\n",
      "1088/1088 [==============================] - 667s 613ms/step - loss: 0.0472 - dice_loss: 0.0471 - accuracy: 0.9976 - recall: 0.9533 - precision: 0.9542 - F1_score: 0.9529 - IoU: 0.9117 - val_loss: 0.0925 - val_dice_loss: 0.0925 - val_accuracy: 0.9950 - val_recall: 0.9001 - val_precision: 0.9302 - val_F1_score: 0.9076 - val_IoU: 0.8428\n",
      "Epoch 69/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0493 - dice_loss: 0.0492 - accuracy: 0.9976 - recall: 0.9499 - precision: 0.9533 - F1_score: 0.9508 - IoU: 0.9080\n",
      "Epoch 69: val_loss did not improve from 0.07818\n",
      "1088/1088 [==============================] - 667s 613ms/step - loss: 0.0493 - dice_loss: 0.0492 - accuracy: 0.9976 - recall: 0.9499 - precision: 0.9533 - F1_score: 0.9508 - IoU: 0.9080 - val_loss: 0.0878 - val_dice_loss: 0.0877 - val_accuracy: 0.9952 - val_recall: 0.9182 - val_precision: 0.9166 - val_F1_score: 0.9123 - val_IoU: 0.8477\n",
      "Epoch 70/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0488 - dice_loss: 0.0488 - accuracy: 0.9975 - recall: 0.9508 - precision: 0.9536 - F1_score: 0.9512 - IoU: 0.9089\n",
      "Epoch 70: val_loss did not improve from 0.07818\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0488 - dice_loss: 0.0488 - accuracy: 0.9975 - recall: 0.9508 - precision: 0.9536 - F1_score: 0.9512 - IoU: 0.9089 - val_loss: 0.0973 - val_dice_loss: 0.0973 - val_accuracy: 0.9951 - val_recall: 0.8942 - val_precision: 0.9261 - val_F1_score: 0.9027 - val_IoU: 0.8348\n",
      "Epoch 71/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0503 - dice_loss: 0.0502 - accuracy: 0.9975 - recall: 0.9495 - precision: 0.9524 - F1_score: 0.9498 - IoU: 0.9067\n",
      "Epoch 71: val_loss did not improve from 0.07818\n",
      "1088/1088 [==============================] - 666s 611ms/step - loss: 0.0503 - dice_loss: 0.0502 - accuracy: 0.9975 - recall: 0.9495 - precision: 0.9524 - F1_score: 0.9498 - IoU: 0.9067 - val_loss: 0.0937 - val_dice_loss: 0.0936 - val_accuracy: 0.9948 - val_recall: 0.9098 - val_precision: 0.9161 - val_F1_score: 0.9064 - val_IoU: 0.8392\n",
      "Epoch 72/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0476 - dice_loss: 0.0476 - accuracy: 0.9976 - recall: 0.9510 - precision: 0.9555 - F1_score: 0.9524 - IoU: 0.9109\n",
      "Epoch 72: val_loss improved from 0.07818 to 0.07659, saving model to G:\\lakemapping\\5_saved_models\\lakes_20240112-1629_AdaDelta_dice_loss_012345_572.h5\n",
      "1088/1088 [==============================] - 667s 613ms/step - loss: 0.0476 - dice_loss: 0.0476 - accuracy: 0.9976 - recall: 0.9510 - precision: 0.9555 - F1_score: 0.9524 - IoU: 0.9109 - val_loss: 0.0766 - val_dice_loss: 0.0765 - val_accuracy: 0.9956 - val_recall: 0.9239 - val_precision: 0.9303 - val_F1_score: 0.9235 - val_IoU: 0.8645\n",
      "Epoch 73/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0458 - dice_loss: 0.0457 - accuracy: 0.9976 - recall: 0.9529 - precision: 0.9569 - F1_score: 0.9543 - IoU: 0.9141\n",
      "Epoch 73: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 663s 609ms/step - loss: 0.0458 - dice_loss: 0.0457 - accuracy: 0.9976 - recall: 0.9529 - precision: 0.9569 - F1_score: 0.9543 - IoU: 0.9141 - val_loss: 0.0859 - val_dice_loss: 0.0858 - val_accuracy: 0.9953 - val_recall: 0.9010 - val_precision: 0.9392 - val_F1_score: 0.9142 - val_IoU: 0.8513\n",
      "Epoch 74/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0458 - dice_loss: 0.0457 - accuracy: 0.9977 - recall: 0.9529 - precision: 0.9571 - F1_score: 0.9543 - IoU: 0.9142\n",
      "Epoch 74: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 663s 609ms/step - loss: 0.0458 - dice_loss: 0.0457 - accuracy: 0.9977 - recall: 0.9529 - precision: 0.9571 - F1_score: 0.9543 - IoU: 0.9142 - val_loss: 0.0811 - val_dice_loss: 0.0810 - val_accuracy: 0.9958 - val_recall: 0.9035 - val_precision: 0.9433 - val_F1_score: 0.9190 - val_IoU: 0.8565\n",
      "Epoch 75/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0471 - dice_loss: 0.0470 - accuracy: 0.9976 - recall: 0.9517 - precision: 0.9560 - F1_score: 0.9530 - IoU: 0.9118\n",
      "Epoch 75: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0471 - dice_loss: 0.0470 - accuracy: 0.9976 - recall: 0.9517 - precision: 0.9560 - F1_score: 0.9530 - IoU: 0.9118 - val_loss: 0.0848 - val_dice_loss: 0.0848 - val_accuracy: 0.9951 - val_recall: 0.9039 - val_precision: 0.9386 - val_F1_score: 0.9152 - val_IoU: 0.8531\n",
      "Epoch 76/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0438 - dice_loss: 0.0438 - accuracy: 0.9976 - recall: 0.9562 - precision: 0.9575 - F1_score: 0.9563 - IoU: 0.9175\n",
      "Epoch 76: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 665s 611ms/step - loss: 0.0438 - dice_loss: 0.0438 - accuracy: 0.9976 - recall: 0.9562 - precision: 0.9575 - F1_score: 0.9563 - IoU: 0.9175 - val_loss: 0.0803 - val_dice_loss: 0.0803 - val_accuracy: 0.9953 - val_recall: 0.9234 - val_precision: 0.9241 - val_F1_score: 0.9198 - val_IoU: 0.8583\n",
      "Epoch 77/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0472 - dice_loss: 0.0472 - accuracy: 0.9976 - recall: 0.9521 - precision: 0.9553 - F1_score: 0.9528 - IoU: 0.9117\n",
      "Epoch 77: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 662s 609ms/step - loss: 0.0472 - dice_loss: 0.0472 - accuracy: 0.9976 - recall: 0.9521 - precision: 0.9553 - F1_score: 0.9528 - IoU: 0.9117 - val_loss: 0.0953 - val_dice_loss: 0.0953 - val_accuracy: 0.9947 - val_recall: 0.9018 - val_precision: 0.9188 - val_F1_score: 0.9047 - val_IoU: 0.8368\n",
      "Epoch 78/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0471 - dice_loss: 0.0470 - accuracy: 0.9976 - recall: 0.9527 - precision: 0.9549 - F1_score: 0.9530 - IoU: 0.9120\n",
      "Epoch 78: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 661s 607ms/step - loss: 0.0471 - dice_loss: 0.0470 - accuracy: 0.9976 - recall: 0.9527 - precision: 0.9549 - F1_score: 0.9530 - IoU: 0.9120 - val_loss: 0.0852 - val_dice_loss: 0.0852 - val_accuracy: 0.9952 - val_recall: 0.9241 - val_precision: 0.9136 - val_F1_score: 0.9148 - val_IoU: 0.8510\n",
      "Epoch 79/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0455 - dice_loss: 0.0455 - accuracy: 0.9976 - recall: 0.9542 - precision: 0.9563 - F1_score: 0.9546 - IoU: 0.9145\n",
      "Epoch 79: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 665s 611ms/step - loss: 0.0455 - dice_loss: 0.0455 - accuracy: 0.9976 - recall: 0.9542 - precision: 0.9563 - F1_score: 0.9546 - IoU: 0.9145 - val_loss: 0.0903 - val_dice_loss: 0.0903 - val_accuracy: 0.9949 - val_recall: 0.8945 - val_precision: 0.9362 - val_F1_score: 0.9098 - val_IoU: 0.8436\n",
      "Epoch 80/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0445 - dice_loss: 0.0445 - accuracy: 0.9978 - recall: 0.9550 - precision: 0.9575 - F1_score: 0.9556 - IoU: 0.9164\n",
      "Epoch 80: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 667s 613ms/step - loss: 0.0445 - dice_loss: 0.0445 - accuracy: 0.9978 - recall: 0.9550 - precision: 0.9575 - F1_score: 0.9556 - IoU: 0.9164 - val_loss: 0.0832 - val_dice_loss: 0.0832 - val_accuracy: 0.9954 - val_recall: 0.9037 - val_precision: 0.9411 - val_F1_score: 0.9168 - val_IoU: 0.8558\n",
      "Epoch 81/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0463 - dice_loss: 0.0463 - accuracy: 0.9977 - recall: 0.9535 - precision: 0.9555 - F1_score: 0.9537 - IoU: 0.9131\n",
      "Epoch 81: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 665s 611ms/step - loss: 0.0463 - dice_loss: 0.0463 - accuracy: 0.9977 - recall: 0.9535 - precision: 0.9555 - F1_score: 0.9537 - IoU: 0.9131 - val_loss: 0.0884 - val_dice_loss: 0.0883 - val_accuracy: 0.9953 - val_recall: 0.9004 - val_precision: 0.9358 - val_F1_score: 0.9117 - val_IoU: 0.8491\n",
      "Epoch 82/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0440 - dice_loss: 0.0439 - accuracy: 0.9978 - recall: 0.9555 - precision: 0.9579 - F1_score: 0.9561 - IoU: 0.9172\n",
      "Epoch 82: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 667s 613ms/step - loss: 0.0440 - dice_loss: 0.0439 - accuracy: 0.9978 - recall: 0.9555 - precision: 0.9579 - F1_score: 0.9561 - IoU: 0.9172 - val_loss: 0.0832 - val_dice_loss: 0.0832 - val_accuracy: 0.9952 - val_recall: 0.9030 - val_precision: 0.9443 - val_F1_score: 0.9168 - val_IoU: 0.8573\n",
      "Epoch 83/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0444 - dice_loss: 0.0443 - accuracy: 0.9977 - recall: 0.9547 - precision: 0.9582 - F1_score: 0.9557 - IoU: 0.9168\n",
      "Epoch 83: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 663s 609ms/step - loss: 0.0444 - dice_loss: 0.0443 - accuracy: 0.9977 - recall: 0.9547 - precision: 0.9582 - F1_score: 0.9557 - IoU: 0.9168 - val_loss: 0.0923 - val_dice_loss: 0.0922 - val_accuracy: 0.9949 - val_recall: 0.9050 - val_precision: 0.9247 - val_F1_score: 0.9078 - val_IoU: 0.8428\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0435 - dice_loss: 0.0435 - accuracy: 0.9978 - recall: 0.9564 - precision: 0.9584 - F1_score: 0.9565 - IoU: 0.9185\n",
      "Epoch 84: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 661s 607ms/step - loss: 0.0435 - dice_loss: 0.0435 - accuracy: 0.9978 - recall: 0.9564 - precision: 0.9584 - F1_score: 0.9565 - IoU: 0.9185 - val_loss: 0.0940 - val_dice_loss: 0.0939 - val_accuracy: 0.9952 - val_recall: 0.8967 - val_precision: 0.9314 - val_F1_score: 0.9061 - val_IoU: 0.8410\n",
      "Epoch 85/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0456 - dice_loss: 0.0456 - accuracy: 0.9977 - recall: 0.9540 - precision: 0.9562 - F1_score: 0.9545 - IoU: 0.9145\n",
      "Epoch 85: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 659s 605ms/step - loss: 0.0456 - dice_loss: 0.0456 - accuracy: 0.9977 - recall: 0.9540 - precision: 0.9562 - F1_score: 0.9545 - IoU: 0.9145 - val_loss: 0.0875 - val_dice_loss: 0.0875 - val_accuracy: 0.9949 - val_recall: 0.9048 - val_precision: 0.9322 - val_F1_score: 0.9125 - val_IoU: 0.8480\n",
      "Epoch 86/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0449 - dice_loss: 0.0448 - accuracy: 0.9978 - recall: 0.9546 - precision: 0.9571 - F1_score: 0.9552 - IoU: 0.9157\n",
      "Epoch 86: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 665s 611ms/step - loss: 0.0449 - dice_loss: 0.0448 - accuracy: 0.9978 - recall: 0.9546 - precision: 0.9571 - F1_score: 0.9552 - IoU: 0.9157 - val_loss: 0.0925 - val_dice_loss: 0.0925 - val_accuracy: 0.9950 - val_recall: 0.8802 - val_precision: 0.9476 - val_F1_score: 0.9075 - val_IoU: 0.8418\n",
      "Epoch 87/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0448 - dice_loss: 0.0447 - accuracy: 0.9977 - recall: 0.9545 - precision: 0.9574 - F1_score: 0.9553 - IoU: 0.9159\n",
      "Epoch 87: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 662s 608ms/step - loss: 0.0448 - dice_loss: 0.0447 - accuracy: 0.9977 - recall: 0.9545 - precision: 0.9574 - F1_score: 0.9553 - IoU: 0.9159 - val_loss: 0.0962 - val_dice_loss: 0.0961 - val_accuracy: 0.9947 - val_recall: 0.8884 - val_precision: 0.9335 - val_F1_score: 0.9039 - val_IoU: 0.8376\n",
      "Epoch 88/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0430 - dice_loss: 0.0430 - accuracy: 0.9978 - recall: 0.9568 - precision: 0.9586 - F1_score: 0.9570 - IoU: 0.9191\n",
      "Epoch 88: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 658s 604ms/step - loss: 0.0430 - dice_loss: 0.0430 - accuracy: 0.9978 - recall: 0.9568 - precision: 0.9586 - F1_score: 0.9570 - IoU: 0.9191 - val_loss: 0.0928 - val_dice_loss: 0.0927 - val_accuracy: 0.9951 - val_recall: 0.9028 - val_precision: 0.9242 - val_F1_score: 0.9073 - val_IoU: 0.8416\n",
      "Epoch 89/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0439 - dice_loss: 0.0438 - accuracy: 0.9978 - recall: 0.9558 - precision: 0.9578 - F1_score: 0.9562 - IoU: 0.9174\n",
      "Epoch 89: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0439 - dice_loss: 0.0438 - accuracy: 0.9978 - recall: 0.9558 - precision: 0.9578 - F1_score: 0.9562 - IoU: 0.9174 - val_loss: 0.0983 - val_dice_loss: 0.0982 - val_accuracy: 0.9946 - val_recall: 0.8746 - val_precision: 0.9466 - val_F1_score: 0.9018 - val_IoU: 0.8351\n",
      "Epoch 90/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0434 - dice_loss: 0.0434 - accuracy: 0.9977 - recall: 0.9563 - precision: 0.9583 - F1_score: 0.9566 - IoU: 0.9184\n",
      "Epoch 90: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 667s 612ms/step - loss: 0.0434 - dice_loss: 0.0434 - accuracy: 0.9977 - recall: 0.9563 - precision: 0.9583 - F1_score: 0.9566 - IoU: 0.9184 - val_loss: 0.0806 - val_dice_loss: 0.0805 - val_accuracy: 0.9955 - val_recall: 0.9089 - val_precision: 0.9404 - val_F1_score: 0.9195 - val_IoU: 0.8591\n",
      "Epoch 91/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0430 - dice_loss: 0.0430 - accuracy: 0.9978 - recall: 0.9557 - precision: 0.9594 - F1_score: 0.9570 - IoU: 0.9189\n",
      "Epoch 91: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 663s 609ms/step - loss: 0.0430 - dice_loss: 0.0430 - accuracy: 0.9978 - recall: 0.9557 - precision: 0.9594 - F1_score: 0.9570 - IoU: 0.9189 - val_loss: 0.0858 - val_dice_loss: 0.0857 - val_accuracy: 0.9953 - val_recall: 0.9290 - val_precision: 0.9100 - val_F1_score: 0.9143 - val_IoU: 0.8517\n",
      "Epoch 92/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0421 - dice_loss: 0.0421 - accuracy: 0.9978 - recall: 0.9576 - precision: 0.9594 - F1_score: 0.9580 - IoU: 0.9206\n",
      "Epoch 92: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0421 - dice_loss: 0.0421 - accuracy: 0.9978 - recall: 0.9576 - precision: 0.9594 - F1_score: 0.9580 - IoU: 0.9206 - val_loss: 0.0871 - val_dice_loss: 0.0870 - val_accuracy: 0.9953 - val_recall: 0.9124 - val_precision: 0.9234 - val_F1_score: 0.9130 - val_IoU: 0.8494\n",
      "Epoch 93/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0425 - dice_loss: 0.0425 - accuracy: 0.9978 - recall: 0.9568 - precision: 0.9594 - F1_score: 0.9575 - IoU: 0.9198\n",
      "Epoch 93: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 661s 607ms/step - loss: 0.0425 - dice_loss: 0.0425 - accuracy: 0.9978 - recall: 0.9568 - precision: 0.9594 - F1_score: 0.9575 - IoU: 0.9198 - val_loss: 0.0845 - val_dice_loss: 0.0845 - val_accuracy: 0.9953 - val_recall: 0.8935 - val_precision: 0.9490 - val_F1_score: 0.9156 - val_IoU: 0.8529\n",
      "Epoch 94/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0423 - dice_loss: 0.0422 - accuracy: 0.9979 - recall: 0.9572 - precision: 0.9596 - F1_score: 0.9578 - IoU: 0.9203\n",
      "Epoch 94: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 665s 611ms/step - loss: 0.0423 - dice_loss: 0.0422 - accuracy: 0.9979 - recall: 0.9572 - precision: 0.9596 - F1_score: 0.9578 - IoU: 0.9203 - val_loss: 0.0835 - val_dice_loss: 0.0834 - val_accuracy: 0.9954 - val_recall: 0.9098 - val_precision: 0.9353 - val_F1_score: 0.9166 - val_IoU: 0.8549\n",
      "Epoch 95/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0434 - dice_loss: 0.0434 - accuracy: 0.9978 - recall: 0.9557 - precision: 0.9588 - F1_score: 0.9566 - IoU: 0.9182\n",
      "Epoch 95: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0434 - dice_loss: 0.0434 - accuracy: 0.9978 - recall: 0.9557 - precision: 0.9588 - F1_score: 0.9566 - IoU: 0.9182 - val_loss: 0.0848 - val_dice_loss: 0.0848 - val_accuracy: 0.9954 - val_recall: 0.8892 - val_precision: 0.9512 - val_F1_score: 0.9152 - val_IoU: 0.8513\n",
      "Epoch 96/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0425 - dice_loss: 0.0424 - accuracy: 0.9978 - recall: 0.9569 - precision: 0.9595 - F1_score: 0.9576 - IoU: 0.9199\n",
      "Epoch 96: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0425 - dice_loss: 0.0424 - accuracy: 0.9978 - recall: 0.9569 - precision: 0.9595 - F1_score: 0.9576 - IoU: 0.9199 - val_loss: 0.0819 - val_dice_loss: 0.0818 - val_accuracy: 0.9953 - val_recall: 0.9016 - val_precision: 0.9434 - val_F1_score: 0.9182 - val_IoU: 0.8557\n",
      "Epoch 97/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0425 - dice_loss: 0.0425 - accuracy: 0.9979 - recall: 0.9580 - precision: 0.9583 - F1_score: 0.9575 - IoU: 0.9201\n",
      "Epoch 97: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 663s 609ms/step - loss: 0.0425 - dice_loss: 0.0425 - accuracy: 0.9979 - recall: 0.9580 - precision: 0.9583 - F1_score: 0.9575 - IoU: 0.9201 - val_loss: 0.0935 - val_dice_loss: 0.0934 - val_accuracy: 0.9946 - val_recall: 0.9077 - val_precision: 0.9176 - val_F1_score: 0.9066 - val_IoU: 0.8392\n",
      "Epoch 98/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0428 - dice_loss: 0.0427 - accuracy: 0.9979 - recall: 0.9562 - precision: 0.9597 - F1_score: 0.9573 - IoU: 0.9194\n",
      "Epoch 98: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 656s 603ms/step - loss: 0.0428 - dice_loss: 0.0427 - accuracy: 0.9979 - recall: 0.9562 - precision: 0.9597 - F1_score: 0.9573 - IoU: 0.9194 - val_loss: 0.0863 - val_dice_loss: 0.0863 - val_accuracy: 0.9952 - val_recall: 0.9116 - val_precision: 0.9251 - val_F1_score: 0.9137 - val_IoU: 0.8510\n",
      "Epoch 99/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0431 - dice_loss: 0.0431 - accuracy: 0.9978 - recall: 0.9565 - precision: 0.9590 - F1_score: 0.9570 - IoU: 0.9191\n",
      "Epoch 99: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 651s 599ms/step - loss: 0.0431 - dice_loss: 0.0431 - accuracy: 0.9978 - recall: 0.9565 - precision: 0.9590 - F1_score: 0.9570 - IoU: 0.9191 - val_loss: 0.0893 - val_dice_loss: 0.0892 - val_accuracy: 0.9949 - val_recall: 0.9060 - val_precision: 0.9283 - val_F1_score: 0.9108 - val_IoU: 0.8459\n",
      "Epoch 100/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0433 - dice_loss: 0.0433 - accuracy: 0.9979 - recall: 0.9560 - precision: 0.9589 - F1_score: 0.9568 - IoU: 0.9186\n",
      "Epoch 100: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 647s 595ms/step - loss: 0.0433 - dice_loss: 0.0433 - accuracy: 0.9979 - recall: 0.9560 - precision: 0.9589 - F1_score: 0.9568 - IoU: 0.9186 - val_loss: 0.0837 - val_dice_loss: 0.0836 - val_accuracy: 0.9949 - val_recall: 0.9144 - val_precision: 0.9299 - val_F1_score: 0.9164 - val_IoU: 0.8548\n",
      "Epoch 101/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0400 - dice_loss: 0.0400 - accuracy: 0.9979 - recall: 0.9600 - precision: 0.9610 - F1_score: 0.9601 - IoU: 0.9242\n",
      "Epoch 101: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 643s 591ms/step - loss: 0.0400 - dice_loss: 0.0400 - accuracy: 0.9979 - recall: 0.9600 - precision: 0.9610 - F1_score: 0.9601 - IoU: 0.9242 - val_loss: 0.0835 - val_dice_loss: 0.0834 - val_accuracy: 0.9952 - val_recall: 0.8955 - val_precision: 0.9514 - val_F1_score: 0.9166 - val_IoU: 0.8566\n",
      "Epoch 102/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0402 - dice_loss: 0.0402 - accuracy: 0.9980 - recall: 0.9598 - precision: 0.9611 - F1_score: 0.9599 - IoU: 0.9241\n",
      "Epoch 102: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 644s 592ms/step - loss: 0.0402 - dice_loss: 0.0402 - accuracy: 0.9980 - recall: 0.9598 - precision: 0.9611 - F1_score: 0.9599 - IoU: 0.9241 - val_loss: 0.1074 - val_dice_loss: 0.1074 - val_accuracy: 0.9934 - val_recall: 0.9232 - val_precision: 0.8780 - val_F1_score: 0.8927 - val_IoU: 0.8195\n",
      "Epoch 103/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0407 - dice_loss: 0.0407 - accuracy: 0.9979 - recall: 0.9585 - precision: 0.9611 - F1_score: 0.9593 - IoU: 0.9228\n",
      "Epoch 103: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 670s 616ms/step - loss: 0.0407 - dice_loss: 0.0407 - accuracy: 0.9979 - recall: 0.9585 - precision: 0.9611 - F1_score: 0.9593 - IoU: 0.9228 - val_loss: 0.0855 - val_dice_loss: 0.0854 - val_accuracy: 0.9951 - val_recall: 0.9077 - val_precision: 0.9325 - val_F1_score: 0.9146 - val_IoU: 0.8507\n",
      "Epoch 104/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0389 - dice_loss: 0.0388 - accuracy: 0.9979 - recall: 0.9607 - precision: 0.9626 - F1_score: 0.9612 - IoU: 0.9262\n",
      "Epoch 104: val_loss did not improve from 0.07659\n",
      "1088/1088 [==============================] - 669s 615ms/step - loss: 0.0389 - dice_loss: 0.0388 - accuracy: 0.9979 - recall: 0.9607 - precision: 0.9626 - F1_score: 0.9612 - IoU: 0.9262 - val_loss: 0.0903 - val_dice_loss: 0.0902 - val_accuracy: 0.9950 - val_recall: 0.9010 - val_precision: 0.9287 - val_F1_score: 0.9098 - val_IoU: 0.8431\n",
      "Epoch 105/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0422 - dice_loss: 0.0422 - accuracy: 0.9979 - recall: 0.9573 - precision: 0.9597 - F1_score: 0.9579 - IoU: 0.9205\n",
      "Epoch 105: val_loss improved from 0.07659 to 0.07335, saving model to G:\\lakemapping\\5_saved_models\\lakes_20240112-1629_AdaDelta_dice_loss_012345_572.h5\n",
      "1088/1088 [==============================] - 668s 613ms/step - loss: 0.0422 - dice_loss: 0.0422 - accuracy: 0.9979 - recall: 0.9573 - precision: 0.9597 - F1_score: 0.9579 - IoU: 0.9205 - val_loss: 0.0733 - val_dice_loss: 0.0733 - val_accuracy: 0.9958 - val_recall: 0.9161 - val_precision: 0.9442 - val_F1_score: 0.9267 - val_IoU: 0.8706\n",
      "Epoch 106/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0413 - dice_loss: 0.0413 - accuracy: 0.9979 - recall: 0.9587 - precision: 0.9599 - F1_score: 0.9588 - IoU: 0.9222\n",
      "Epoch 106: val_loss did not improve from 0.07335\n",
      "1088/1088 [==============================] - 663s 609ms/step - loss: 0.0413 - dice_loss: 0.0413 - accuracy: 0.9979 - recall: 0.9587 - precision: 0.9599 - F1_score: 0.9588 - IoU: 0.9222 - val_loss: 0.0871 - val_dice_loss: 0.0871 - val_accuracy: 0.9951 - val_recall: 0.8979 - val_precision: 0.9400 - val_F1_score: 0.9129 - val_IoU: 0.8496\n",
      "Epoch 107/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0384 - dice_loss: 0.0383 - accuracy: 0.9980 - recall: 0.9612 - precision: 0.9631 - F1_score: 0.9617 - IoU: 0.9271\n",
      "Epoch 107: val_loss did not improve from 0.07335\n",
      "1088/1088 [==============================] - 663s 609ms/step - loss: 0.0384 - dice_loss: 0.0383 - accuracy: 0.9980 - recall: 0.9612 - precision: 0.9631 - F1_score: 0.9617 - IoU: 0.9271 - val_loss: 0.0891 - val_dice_loss: 0.0890 - val_accuracy: 0.9951 - val_recall: 0.9138 - val_precision: 0.9189 - val_F1_score: 0.9110 - val_IoU: 0.8458\n",
      "Epoch 108/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0403 - dice_loss: 0.0403 - accuracy: 0.9980 - recall: 0.9591 - precision: 0.9615 - F1_score: 0.9597 - IoU: 0.9239\n",
      "Epoch 108: val_loss did not improve from 0.07335\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0403 - dice_loss: 0.0403 - accuracy: 0.9980 - recall: 0.9591 - precision: 0.9615 - F1_score: 0.9597 - IoU: 0.9239 - val_loss: 0.0804 - val_dice_loss: 0.0804 - val_accuracy: 0.9957 - val_recall: 0.9177 - val_precision: 0.9292 - val_F1_score: 0.9196 - val_IoU: 0.8589\n",
      "Epoch 109/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0402 - dice_loss: 0.0402 - accuracy: 0.9979 - recall: 0.9592 - precision: 0.9616 - F1_score: 0.9599 - IoU: 0.9240\n",
      "Epoch 109: val_loss did not improve from 0.07335\n",
      "1088/1088 [==============================] - 663s 609ms/step - loss: 0.0402 - dice_loss: 0.0402 - accuracy: 0.9979 - recall: 0.9592 - precision: 0.9616 - F1_score: 0.9599 - IoU: 0.9240 - val_loss: 0.0874 - val_dice_loss: 0.0873 - val_accuracy: 0.9952 - val_recall: 0.9084 - val_precision: 0.9259 - val_F1_score: 0.9127 - val_IoU: 0.8487\n",
      "Epoch 110/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0397 - dice_loss: 0.0396 - accuracy: 0.9980 - recall: 0.9596 - precision: 0.9623 - F1_score: 0.9604 - IoU: 0.9248\n",
      "Epoch 110: val_loss did not improve from 0.07335\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0397 - dice_loss: 0.0396 - accuracy: 0.9980 - recall: 0.9596 - precision: 0.9623 - F1_score: 0.9604 - IoU: 0.9248 - val_loss: 0.0852 - val_dice_loss: 0.0852 - val_accuracy: 0.9953 - val_recall: 0.9036 - val_precision: 0.9365 - val_F1_score: 0.9148 - val_IoU: 0.8526\n",
      "Epoch 111/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0401 - dice_loss: 0.0401 - accuracy: 0.9980 - recall: 0.9583 - precision: 0.9627 - F1_score: 0.9600 - IoU: 0.9244\n",
      "Epoch 111: val_loss did not improve from 0.07335\n",
      "1088/1088 [==============================] - 663s 609ms/step - loss: 0.0401 - dice_loss: 0.0401 - accuracy: 0.9980 - recall: 0.9583 - precision: 0.9627 - F1_score: 0.9600 - IoU: 0.9244 - val_loss: 0.0889 - val_dice_loss: 0.0889 - val_accuracy: 0.9951 - val_recall: 0.9050 - val_precision: 0.9266 - val_F1_score: 0.9111 - val_IoU: 0.8470\n",
      "Epoch 112/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0392 - dice_loss: 0.0392 - accuracy: 0.9980 - recall: 0.9597 - precision: 0.9630 - F1_score: 0.9608 - IoU: 0.9257\n",
      "Epoch 112: val_loss did not improve from 0.07335\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0392 - dice_loss: 0.0392 - accuracy: 0.9980 - recall: 0.9597 - precision: 0.9630 - F1_score: 0.9608 - IoU: 0.9257 - val_loss: 0.0851 - val_dice_loss: 0.0851 - val_accuracy: 0.9952 - val_recall: 0.9024 - val_precision: 0.9387 - val_F1_score: 0.9150 - val_IoU: 0.8522\n",
      "Epoch 113/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0384 - dice_loss: 0.0383 - accuracy: 0.9980 - recall: 0.9609 - precision: 0.9633 - F1_score: 0.9617 - IoU: 0.9272\n",
      "Epoch 113: val_loss did not improve from 0.07335\n",
      "1088/1088 [==============================] - 662s 608ms/step - loss: 0.0384 - dice_loss: 0.0383 - accuracy: 0.9980 - recall: 0.9609 - precision: 0.9633 - F1_score: 0.9617 - IoU: 0.9272 - val_loss: 0.0856 - val_dice_loss: 0.0855 - val_accuracy: 0.9954 - val_recall: 0.9072 - val_precision: 0.9323 - val_F1_score: 0.9145 - val_IoU: 0.8523\n",
      "Epoch 114/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0387 - dice_loss: 0.0386 - accuracy: 0.9980 - recall: 0.9606 - precision: 0.9630 - F1_score: 0.9614 - IoU: 0.9266\n",
      "Epoch 114: val_loss did not improve from 0.07335\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0387 - dice_loss: 0.0386 - accuracy: 0.9980 - recall: 0.9606 - precision: 0.9630 - F1_score: 0.9614 - IoU: 0.9266 - val_loss: 0.0920 - val_dice_loss: 0.0919 - val_accuracy: 0.9947 - val_recall: 0.9203 - val_precision: 0.9064 - val_F1_score: 0.9081 - val_IoU: 0.8414\n",
      "Epoch 115/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0394 - dice_loss: 0.0394 - accuracy: 0.9981 - recall: 0.9600 - precision: 0.9622 - F1_score: 0.9607 - IoU: 0.9254\n",
      "Epoch 115: val_loss did not improve from 0.07335\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0394 - dice_loss: 0.0394 - accuracy: 0.9981 - recall: 0.9600 - precision: 0.9622 - F1_score: 0.9607 - IoU: 0.9254 - val_loss: 0.0835 - val_dice_loss: 0.0834 - val_accuracy: 0.9956 - val_recall: 0.9107 - val_precision: 0.9325 - val_F1_score: 0.9166 - val_IoU: 0.8550\n",
      "Epoch 116/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0374 - dice_loss: 0.0374 - accuracy: 0.9981 - recall: 0.9618 - precision: 0.9644 - F1_score: 0.9627 - IoU: 0.9291\n",
      "Epoch 116: val_loss did not improve from 0.07335\n",
      "1088/1088 [==============================] - 665s 611ms/step - loss: 0.0374 - dice_loss: 0.0374 - accuracy: 0.9981 - recall: 0.9618 - precision: 0.9644 - F1_score: 0.9627 - IoU: 0.9291 - val_loss: 0.0875 - val_dice_loss: 0.0875 - val_accuracy: 0.9954 - val_recall: 0.9054 - val_precision: 0.9297 - val_F1_score: 0.9125 - val_IoU: 0.8496\n",
      "Epoch 117/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0380 - dice_loss: 0.0379 - accuracy: 0.9980 - recall: 0.9608 - precision: 0.9642 - F1_score: 0.9621 - IoU: 0.9279\n",
      "Epoch 117: val_loss did not improve from 0.07335\n",
      "1088/1088 [==============================] - 663s 609ms/step - loss: 0.0380 - dice_loss: 0.0379 - accuracy: 0.9980 - recall: 0.9608 - precision: 0.9642 - F1_score: 0.9621 - IoU: 0.9279 - val_loss: 0.0825 - val_dice_loss: 0.0825 - val_accuracy: 0.9957 - val_recall: 0.9144 - val_precision: 0.9296 - val_F1_score: 0.9175 - val_IoU: 0.8568\n",
      "Epoch 118/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0378 - dice_loss: 0.0378 - accuracy: 0.9981 - recall: 0.9618 - precision: 0.9635 - F1_score: 0.9623 - IoU: 0.9282\n",
      "Epoch 118: val_loss did not improve from 0.07335\n",
      "1088/1088 [==============================] - 662s 608ms/step - loss: 0.0378 - dice_loss: 0.0378 - accuracy: 0.9981 - recall: 0.9618 - precision: 0.9635 - F1_score: 0.9623 - IoU: 0.9282 - val_loss: 0.0777 - val_dice_loss: 0.0777 - val_accuracy: 0.9960 - val_recall: 0.9091 - val_precision: 0.9446 - val_F1_score: 0.9223 - val_IoU: 0.8628\n",
      "Epoch 119/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0395 - dice_loss: 0.0395 - accuracy: 0.9980 - recall: 0.9604 - precision: 0.9616 - F1_score: 0.9605 - IoU: 0.9253\n",
      "Epoch 119: val_loss improved from 0.07335 to 0.07294, saving model to G:\\lakemapping\\5_saved_models\\lakes_20240112-1629_AdaDelta_dice_loss_012345_572.h5\n",
      "1088/1088 [==============================] - 669s 614ms/step - loss: 0.0395 - dice_loss: 0.0395 - accuracy: 0.9980 - recall: 0.9604 - precision: 0.9616 - F1_score: 0.9605 - IoU: 0.9253 - val_loss: 0.0729 - val_dice_loss: 0.0729 - val_accuracy: 0.9961 - val_recall: 0.9152 - val_precision: 0.9498 - val_F1_score: 0.9271 - val_IoU: 0.8729\n",
      "Epoch 120/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0401 - dice_loss: 0.0401 - accuracy: 0.9980 - recall: 0.9597 - precision: 0.9616 - F1_score: 0.9600 - IoU: 0.9244\n",
      "Epoch 120: val_loss did not improve from 0.07294\n",
      "1088/1088 [==============================] - 660s 606ms/step - loss: 0.0401 - dice_loss: 0.0401 - accuracy: 0.9980 - recall: 0.9597 - precision: 0.9616 - F1_score: 0.9600 - IoU: 0.9244 - val_loss: 0.0971 - val_dice_loss: 0.0970 - val_accuracy: 0.9943 - val_recall: 0.9000 - val_precision: 0.9198 - val_F1_score: 0.9030 - val_IoU: 0.8356\n",
      "Epoch 121/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0385 - dice_loss: 0.0385 - accuracy: 0.9981 - recall: 0.9600 - precision: 0.9639 - F1_score: 0.9616 - IoU: 0.9269\n",
      "Epoch 121: val_loss did not improve from 0.07294\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0385 - dice_loss: 0.0385 - accuracy: 0.9981 - recall: 0.9600 - precision: 0.9639 - F1_score: 0.9616 - IoU: 0.9269 - val_loss: 0.0903 - val_dice_loss: 0.0903 - val_accuracy: 0.9950 - val_recall: 0.9097 - val_precision: 0.9211 - val_F1_score: 0.9097 - val_IoU: 0.8458\n",
      "Epoch 122/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0372 - dice_loss: 0.0372 - accuracy: 0.9981 - recall: 0.9618 - precision: 0.9646 - F1_score: 0.9628 - IoU: 0.9292\n",
      "Epoch 122: val_loss did not improve from 0.07294\n",
      "1088/1088 [==============================] - 665s 611ms/step - loss: 0.0372 - dice_loss: 0.0372 - accuracy: 0.9981 - recall: 0.9618 - precision: 0.9646 - F1_score: 0.9628 - IoU: 0.9292 - val_loss: 0.0890 - val_dice_loss: 0.0890 - val_accuracy: 0.9950 - val_recall: 0.9060 - val_precision: 0.9262 - val_F1_score: 0.9110 - val_IoU: 0.8455\n",
      "Epoch 123/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0380 - dice_loss: 0.0379 - accuracy: 0.9980 - recall: 0.9620 - precision: 0.9631 - F1_score: 0.9621 - IoU: 0.9280\n",
      "Epoch 123: val_loss did not improve from 0.07294\n",
      "1088/1088 [==============================] - 663s 609ms/step - loss: 0.0380 - dice_loss: 0.0379 - accuracy: 0.9980 - recall: 0.9620 - precision: 0.9631 - F1_score: 0.9621 - IoU: 0.9280 - val_loss: 0.0799 - val_dice_loss: 0.0799 - val_accuracy: 0.9956 - val_recall: 0.9131 - val_precision: 0.9385 - val_F1_score: 0.9201 - val_IoU: 0.8605\n",
      "Epoch 124/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0368 - dice_loss: 0.0367 - accuracy: 0.9980 - recall: 0.9626 - precision: 0.9647 - F1_score: 0.9633 - IoU: 0.9301\n",
      "Epoch 124: val_loss did not improve from 0.07294\n",
      "1088/1088 [==============================] - 663s 609ms/step - loss: 0.0368 - dice_loss: 0.0367 - accuracy: 0.9980 - recall: 0.9626 - precision: 0.9647 - F1_score: 0.9633 - IoU: 0.9301 - val_loss: 0.0891 - val_dice_loss: 0.0891 - val_accuracy: 0.9948 - val_recall: 0.9092 - val_precision: 0.9250 - val_F1_score: 0.9109 - val_IoU: 0.8457\n",
      "Epoch 125/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0367 - dice_loss: 0.0367 - accuracy: 0.9980 - recall: 0.9626 - precision: 0.9648 - F1_score: 0.9633 - IoU: 0.9300\n",
      "Epoch 125: val_loss did not improve from 0.07294\n",
      "1088/1088 [==============================] - 665s 611ms/step - loss: 0.0367 - dice_loss: 0.0367 - accuracy: 0.9980 - recall: 0.9626 - precision: 0.9648 - F1_score: 0.9633 - IoU: 0.9300 - val_loss: 0.0789 - val_dice_loss: 0.0789 - val_accuracy: 0.9957 - val_recall: 0.9125 - val_precision: 0.9385 - val_F1_score: 0.9211 - val_IoU: 0.8619\n",
      "Epoch 126/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0371 - dice_loss: 0.0371 - accuracy: 0.9981 - recall: 0.9629 - precision: 0.9638 - F1_score: 0.9629 - IoU: 0.9294\n",
      "Epoch 126: val_loss did not improve from 0.07294\n",
      "1088/1088 [==============================] - 663s 609ms/step - loss: 0.0371 - dice_loss: 0.0371 - accuracy: 0.9981 - recall: 0.9629 - precision: 0.9638 - F1_score: 0.9629 - IoU: 0.9294 - val_loss: 0.0924 - val_dice_loss: 0.0924 - val_accuracy: 0.9954 - val_recall: 0.8891 - val_precision: 0.9428 - val_F1_score: 0.9077 - val_IoU: 0.8432\n",
      "Epoch 127/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0373 - dice_loss: 0.0373 - accuracy: 0.9981 - recall: 0.9626 - precision: 0.9636 - F1_score: 0.9627 - IoU: 0.9290\n",
      "Epoch 127: val_loss did not improve from 0.07294\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0373 - dice_loss: 0.0373 - accuracy: 0.9981 - recall: 0.9626 - precision: 0.9636 - F1_score: 0.9627 - IoU: 0.9290 - val_loss: 0.0848 - val_dice_loss: 0.0848 - val_accuracy: 0.9956 - val_recall: 0.9055 - val_precision: 0.9372 - val_F1_score: 0.9152 - val_IoU: 0.8544\n",
      "Epoch 128/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0376 - dice_loss: 0.0375 - accuracy: 0.9981 - recall: 0.9628 - precision: 0.9632 - F1_score: 0.9625 - IoU: 0.9288\n",
      "Epoch 128: val_loss did not improve from 0.07294\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0376 - dice_loss: 0.0375 - accuracy: 0.9981 - recall: 0.9628 - precision: 0.9632 - F1_score: 0.9625 - IoU: 0.9288 - val_loss: 0.0863 - val_dice_loss: 0.0863 - val_accuracy: 0.9952 - val_recall: 0.9068 - val_precision: 0.9325 - val_F1_score: 0.9137 - val_IoU: 0.8512\n",
      "Epoch 129/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0364 - dice_loss: 0.0364 - accuracy: 0.9981 - recall: 0.9637 - precision: 0.9644 - F1_score: 0.9637 - IoU: 0.9307\n",
      "Epoch 129: val_loss improved from 0.07294 to 0.07022, saving model to G:\\lakemapping\\5_saved_models\\lakes_20240112-1629_AdaDelta_dice_loss_012345_572.h5\n",
      "1088/1088 [==============================] - 676s 621ms/step - loss: 0.0364 - dice_loss: 0.0364 - accuracy: 0.9981 - recall: 0.9637 - precision: 0.9644 - F1_score: 0.9637 - IoU: 0.9307 - val_loss: 0.0702 - val_dice_loss: 0.0702 - val_accuracy: 0.9961 - val_recall: 0.9244 - val_precision: 0.9426 - val_F1_score: 0.9298 - val_IoU: 0.8754\n",
      "Epoch 130/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0366 - dice_loss: 0.0365 - accuracy: 0.9981 - recall: 0.9629 - precision: 0.9648 - F1_score: 0.9635 - IoU: 0.9305\n",
      "Epoch 130: val_loss did not improve from 0.07022\n",
      "1088/1088 [==============================] - 667s 613ms/step - loss: 0.0366 - dice_loss: 0.0365 - accuracy: 0.9981 - recall: 0.9629 - precision: 0.9648 - F1_score: 0.9635 - IoU: 0.9305 - val_loss: 0.0813 - val_dice_loss: 0.0813 - val_accuracy: 0.9954 - val_recall: 0.9103 - val_precision: 0.9387 - val_F1_score: 0.9188 - val_IoU: 0.8592\n",
      "Epoch 131/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0362 - dice_loss: 0.0362 - accuracy: 0.9982 - recall: 0.9633 - precision: 0.9650 - F1_score: 0.9638 - IoU: 0.9309\n",
      "Epoch 131: val_loss did not improve from 0.07022\n",
      "1088/1088 [==============================] - 666s 612ms/step - loss: 0.0362 - dice_loss: 0.0362 - accuracy: 0.9982 - recall: 0.9633 - precision: 0.9650 - F1_score: 0.9638 - IoU: 0.9309 - val_loss: 0.0930 - val_dice_loss: 0.0930 - val_accuracy: 0.9946 - val_recall: 0.9093 - val_precision: 0.9157 - val_F1_score: 0.9071 - val_IoU: 0.8403\n",
      "Epoch 132/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0368 - dice_loss: 0.0368 - accuracy: 0.9981 - recall: 0.9628 - precision: 0.9646 - F1_score: 0.9633 - IoU: 0.9301\n",
      "Epoch 132: val_loss did not improve from 0.07022\n",
      "1088/1088 [==============================] - 665s 611ms/step - loss: 0.0368 - dice_loss: 0.0368 - accuracy: 0.9981 - recall: 0.9628 - precision: 0.9646 - F1_score: 0.9633 - IoU: 0.9301 - val_loss: 0.0765 - val_dice_loss: 0.0765 - val_accuracy: 0.9955 - val_recall: 0.9285 - val_precision: 0.9260 - val_F1_score: 0.9235 - val_IoU: 0.8654\n",
      "Epoch 133/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0348 - dice_loss: 0.0347 - accuracy: 0.9982 - recall: 0.9649 - precision: 0.9664 - F1_score: 0.9653 - IoU: 0.9337\n",
      "Epoch 133: val_loss did not improve from 0.07022\n",
      "1088/1088 [==============================] - 663s 609ms/step - loss: 0.0348 - dice_loss: 0.0347 - accuracy: 0.9982 - recall: 0.9649 - precision: 0.9664 - F1_score: 0.9653 - IoU: 0.9337 - val_loss: 0.0731 - val_dice_loss: 0.0730 - val_accuracy: 0.9960 - val_recall: 0.9076 - val_precision: 0.9555 - val_F1_score: 0.9270 - val_IoU: 0.8711\n",
      "Epoch 134/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0368 - dice_loss: 0.0368 - accuracy: 0.9982 - recall: 0.9623 - precision: 0.9651 - F1_score: 0.9633 - IoU: 0.9301\n",
      "Epoch 134: val_loss did not improve from 0.07022\n",
      "1088/1088 [==============================] - 663s 610ms/step - loss: 0.0368 - dice_loss: 0.0368 - accuracy: 0.9982 - recall: 0.9623 - precision: 0.9651 - F1_score: 0.9633 - IoU: 0.9301 - val_loss: 0.0867 - val_dice_loss: 0.0866 - val_accuracy: 0.9948 - val_recall: 0.9181 - val_precision: 0.9193 - val_F1_score: 0.9134 - val_IoU: 0.8497\n",
      "Epoch 135/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0368 - dice_loss: 0.0368 - accuracy: 0.9981 - recall: 0.9627 - precision: 0.9645 - F1_score: 0.9632 - IoU: 0.9299\n",
      "Epoch 135: val_loss did not improve from 0.07022\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0368 - dice_loss: 0.0368 - accuracy: 0.9981 - recall: 0.9627 - precision: 0.9645 - F1_score: 0.9632 - IoU: 0.9299 - val_loss: 0.0995 - val_dice_loss: 0.0995 - val_accuracy: 0.9941 - val_recall: 0.9240 - val_precision: 0.8933 - val_F1_score: 0.9005 - val_IoU: 0.8334\n",
      "Epoch 136/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0373 - dice_loss: 0.0372 - accuracy: 0.9982 - recall: 0.9620 - precision: 0.9643 - F1_score: 0.9628 - IoU: 0.9292\n",
      "Epoch 136: val_loss did not improve from 0.07022\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0373 - dice_loss: 0.0372 - accuracy: 0.9982 - recall: 0.9620 - precision: 0.9643 - F1_score: 0.9628 - IoU: 0.9292 - val_loss: 0.0955 - val_dice_loss: 0.0955 - val_accuracy: 0.9945 - val_recall: 0.9103 - val_precision: 0.9122 - val_F1_score: 0.9045 - val_IoU: 0.8375\n",
      "Epoch 137/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0367 - dice_loss: 0.0366 - accuracy: 0.9982 - recall: 0.9629 - precision: 0.9646 - F1_score: 0.9634 - IoU: 0.9302\n",
      "Epoch 137: val_loss did not improve from 0.07022\n",
      "1088/1088 [==============================] - 663s 609ms/step - loss: 0.0367 - dice_loss: 0.0366 - accuracy: 0.9982 - recall: 0.9629 - precision: 0.9646 - F1_score: 0.9634 - IoU: 0.9302 - val_loss: 0.0729 - val_dice_loss: 0.0728 - val_accuracy: 0.9958 - val_recall: 0.9095 - val_precision: 0.9522 - val_F1_score: 0.9272 - val_IoU: 0.8704\n",
      "Epoch 138/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0361 - dice_loss: 0.0361 - accuracy: 0.9982 - recall: 0.9632 - precision: 0.9656 - F1_score: 0.9640 - IoU: 0.9315\n",
      "Epoch 138: val_loss did not improve from 0.07022\n",
      "1088/1088 [==============================] - 666s 612ms/step - loss: 0.0361 - dice_loss: 0.0361 - accuracy: 0.9982 - recall: 0.9632 - precision: 0.9656 - F1_score: 0.9640 - IoU: 0.9315 - val_loss: 0.0950 - val_dice_loss: 0.0950 - val_accuracy: 0.9944 - val_recall: 0.9056 - val_precision: 0.9172 - val_F1_score: 0.9050 - val_IoU: 0.8365\n",
      "Epoch 139/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0359 - dice_loss: 0.0359 - accuracy: 0.9982 - recall: 0.9636 - precision: 0.9654 - F1_score: 0.9641 - IoU: 0.9316\n",
      "Epoch 139: val_loss did not improve from 0.07022\n",
      "1088/1088 [==============================] - 667s 613ms/step - loss: 0.0359 - dice_loss: 0.0359 - accuracy: 0.9982 - recall: 0.9636 - precision: 0.9654 - F1_score: 0.9641 - IoU: 0.9316 - val_loss: 0.0905 - val_dice_loss: 0.0905 - val_accuracy: 0.9951 - val_recall: 0.9076 - val_precision: 0.9223 - val_F1_score: 0.9096 - val_IoU: 0.8433\n",
      "Epoch 140/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0340 - dice_loss: 0.0340 - accuracy: 0.9983 - recall: 0.9648 - precision: 0.9680 - F1_score: 0.9661 - IoU: 0.9352\n",
      "Epoch 140: val_loss did not improve from 0.07022\n",
      "1088/1088 [==============================] - 647s 595ms/step - loss: 0.0340 - dice_loss: 0.0340 - accuracy: 0.9983 - recall: 0.9648 - precision: 0.9680 - F1_score: 0.9661 - IoU: 0.9352 - val_loss: 0.0822 - val_dice_loss: 0.0821 - val_accuracy: 0.9952 - val_recall: 0.9135 - val_precision: 0.9336 - val_F1_score: 0.9179 - val_IoU: 0.8578\n",
      "Epoch 141/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0351 - dice_loss: 0.0351 - accuracy: 0.9982 - recall: 0.9645 - precision: 0.9662 - F1_score: 0.9649 - IoU: 0.9332\n",
      "Epoch 141: val_loss did not improve from 0.07022\n",
      "1088/1088 [==============================] - 655s 602ms/step - loss: 0.0351 - dice_loss: 0.0351 - accuracy: 0.9982 - recall: 0.9645 - precision: 0.9662 - F1_score: 0.9649 - IoU: 0.9332 - val_loss: 0.0899 - val_dice_loss: 0.0899 - val_accuracy: 0.9952 - val_recall: 0.9073 - val_precision: 0.9274 - val_F1_score: 0.9101 - val_IoU: 0.8466\n",
      "Epoch 142/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0337 - dice_loss: 0.0337 - accuracy: 0.9982 - recall: 0.9662 - precision: 0.9671 - F1_score: 0.9663 - IoU: 0.9356\n",
      "Epoch 142: val_loss did not improve from 0.07022\n",
      "1088/1088 [==============================] - 655s 602ms/step - loss: 0.0337 - dice_loss: 0.0337 - accuracy: 0.9982 - recall: 0.9662 - precision: 0.9671 - F1_score: 0.9663 - IoU: 0.9356 - val_loss: 0.0803 - val_dice_loss: 0.0803 - val_accuracy: 0.9957 - val_recall: 0.9160 - val_precision: 0.9333 - val_F1_score: 0.9198 - val_IoU: 0.8610\n",
      "Epoch 143/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0335 - dice_loss: 0.0335 - accuracy: 0.9983 - recall: 0.9658 - precision: 0.9679 - F1_score: 0.9666 - IoU: 0.9359\n",
      "Epoch 143: val_loss did not improve from 0.07022\n",
      "1088/1088 [==============================] - 654s 601ms/step - loss: 0.0335 - dice_loss: 0.0335 - accuracy: 0.9983 - recall: 0.9658 - precision: 0.9679 - F1_score: 0.9666 - IoU: 0.9359 - val_loss: 0.0850 - val_dice_loss: 0.0850 - val_accuracy: 0.9954 - val_recall: 0.9116 - val_precision: 0.9305 - val_F1_score: 0.9151 - val_IoU: 0.8530\n",
      "Epoch 144/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0352 - dice_loss: 0.0352 - accuracy: 0.9983 - recall: 0.9636 - precision: 0.9669 - F1_score: 0.9649 - IoU: 0.9330\n",
      "Epoch 144: val_loss did not improve from 0.07022\n",
      "1088/1088 [==============================] - 655s 602ms/step - loss: 0.0352 - dice_loss: 0.0352 - accuracy: 0.9983 - recall: 0.9636 - precision: 0.9669 - F1_score: 0.9649 - IoU: 0.9330 - val_loss: 0.0890 - val_dice_loss: 0.0890 - val_accuracy: 0.9951 - val_recall: 0.9203 - val_precision: 0.9144 - val_F1_score: 0.9111 - val_IoU: 0.8467\n",
      "Epoch 145/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0347 - dice_loss: 0.0347 - accuracy: 0.9982 - recall: 0.9646 - precision: 0.9668 - F1_score: 0.9654 - IoU: 0.9339\n",
      "Epoch 145: val_loss did not improve from 0.07022\n",
      "1088/1088 [==============================] - 654s 601ms/step - loss: 0.0347 - dice_loss: 0.0347 - accuracy: 0.9982 - recall: 0.9646 - precision: 0.9668 - F1_score: 0.9654 - IoU: 0.9339 - val_loss: 0.0838 - val_dice_loss: 0.0838 - val_accuracy: 0.9950 - val_recall: 0.8975 - val_precision: 0.9451 - val_F1_score: 0.9163 - val_IoU: 0.8536\n",
      "Epoch 146/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0336 - dice_loss: 0.0336 - accuracy: 0.9983 - recall: 0.9663 - precision: 0.9673 - F1_score: 0.9665 - IoU: 0.9359\n",
      "Epoch 146: val_loss did not improve from 0.07022\n",
      "1088/1088 [==============================] - 651s 598ms/step - loss: 0.0336 - dice_loss: 0.0336 - accuracy: 0.9983 - recall: 0.9663 - precision: 0.9673 - F1_score: 0.9665 - IoU: 0.9359 - val_loss: 0.0816 - val_dice_loss: 0.0816 - val_accuracy: 0.9958 - val_recall: 0.9093 - val_precision: 0.9371 - val_F1_score: 0.9184 - val_IoU: 0.8574\n",
      "Epoch 147/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0338 - dice_loss: 0.0338 - accuracy: 0.9983 - recall: 0.9657 - precision: 0.9674 - F1_score: 0.9662 - IoU: 0.9355\n",
      "Epoch 147: val_loss did not improve from 0.07022\n",
      "1088/1088 [==============================] - 646s 594ms/step - loss: 0.0338 - dice_loss: 0.0338 - accuracy: 0.9983 - recall: 0.9657 - precision: 0.9674 - F1_score: 0.9662 - IoU: 0.9355 - val_loss: 0.0803 - val_dice_loss: 0.0802 - val_accuracy: 0.9958 - val_recall: 0.9106 - val_precision: 0.9378 - val_F1_score: 0.9198 - val_IoU: 0.8590\n",
      "Epoch 148/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0347 - dice_loss: 0.0347 - accuracy: 0.9982 - recall: 0.9654 - precision: 0.9660 - F1_score: 0.9653 - IoU: 0.9339\n",
      "Epoch 148: val_loss did not improve from 0.07022\n",
      "1088/1088 [==============================] - 671s 617ms/step - loss: 0.0347 - dice_loss: 0.0347 - accuracy: 0.9982 - recall: 0.9654 - precision: 0.9660 - F1_score: 0.9653 - IoU: 0.9339 - val_loss: 0.0790 - val_dice_loss: 0.0790 - val_accuracy: 0.9957 - val_recall: 0.9052 - val_precision: 0.9458 - val_F1_score: 0.9210 - val_IoU: 0.8609\n",
      "Epoch 149/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0338 - dice_loss: 0.0338 - accuracy: 0.9983 - recall: 0.9661 - precision: 0.9670 - F1_score: 0.9663 - IoU: 0.9354\n",
      "Epoch 149: val_loss did not improve from 0.07022\n",
      "1088/1088 [==============================] - 668s 614ms/step - loss: 0.0338 - dice_loss: 0.0338 - accuracy: 0.9983 - recall: 0.9661 - precision: 0.9670 - F1_score: 0.9663 - IoU: 0.9354 - val_loss: 0.0839 - val_dice_loss: 0.0839 - val_accuracy: 0.9951 - val_recall: 0.9167 - val_precision: 0.9250 - val_F1_score: 0.9161 - val_IoU: 0.8534\n",
      "Epoch 150/150\n",
      "1088/1088 [==============================] - ETA: 0s - loss: 0.0344 - dice_loss: 0.0344 - accuracy: 0.9982 - recall: 0.9660 - precision: 0.9660 - F1_score: 0.9657 - IoU: 0.9344\n",
      "Epoch 150: val_loss did not improve from 0.07022\n",
      "1088/1088 [==============================] - 664s 610ms/step - loss: 0.0344 - dice_loss: 0.0344 - accuracy: 0.9982 - recall: 0.9660 - precision: 0.9660 - F1_score: 0.9657 - IoU: 0.9344 - val_loss: 0.0795 - val_dice_loss: 0.0794 - val_accuracy: 0.9954 - val_recall: 0.9153 - val_precision: 0.9350 - val_F1_score: 0.9206 - val_IoU: 0.8608\n"
     ]
    }
   ],
   "source": [
    "loss_history = model.fit(train_generator, \n",
    "                         steps_per_epoch=train_sum//config.BATCH_SIZE,#config.MAX_TRAIN_STEPS,\n",
    "                         epochs=config.NB_EPOCHS, \n",
    "                         validation_data=val_generator,\n",
    "                         validation_steps=val_sum//config.BATCH_SIZE,#config.VALID_IMG_COUNT,\n",
    "                         callbacks=callbacks_list,\n",
    "                         workers=1,\n",
    "                         # shuffle=True,\n",
    "#                          use_multiprocessing=True # the generator is not very thread safe \n",
    "                         #max_queue_size = 60,\n",
    "                        )\n",
    "h=loss_history.history\n",
    "with open('history_{}_{}_{}_{}_{}.txt'.format(timestr,OPTIMIZER_NAME,LOSS_NAME, chs,config.input_shape[0]), 'wb') as file_pi:\n",
    "    pickle.dump(h, file_pi)\n",
    "plot(h,timestr, OPTIMIZER_NAME,LOSS_NAME, config.input_size[0], config.NB_EPOCHS, config.BATCH_SIZE,chs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### 读取现有history文件\n",
    "with open('.txt','rb')as file_pi: \n",
    "    h=pickle.load(file_pi)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(h, OPTIMIZER_NAME,LOSS_NAME, config.patch_size[0], config.NB_EPOCHS, config.BATCH_SIZE,chs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型精度评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model after training \n",
    "model_path=os.path.join(config.model_path,'lakes_20240112-1629_AdaDelta_dice_loss_012345_572.h5')\n",
    "model = load_model(model_path, custom_objects={'dice loss': LOSS, 'accuracy':accuracy ,'recall':recall, 'F1_score':F1_score,'precision':precision,'IoU': IoU}, compile=False) \n",
    "model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=[dice_loss, accuracy,recall,F1_score, precision, IoU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Print one batch on the training/test data! \n",
    "# for i in range(1):\n",
    "#     test_images, real_label = next(test_generator)\n",
    "#     #3 images per row: GSW, label, prediction\n",
    "#     prediction = model.predict(test_images, steps=1)\n",
    "#     prediction[prediction>0.5]=1\n",
    "#     prediction[prediction<=0.5]=0\n",
    "#     display_images(np.concatenate((test_images, real_label, prediction), axis = -1))# test_images( NDWI), real_label(label), prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=1\n",
    "frames=[]\n",
    "path_to_write=os.path.join(config.dataset_dir,'test/type'+str(j))\n",
    "all_files = os.listdir(path_to_write)\n",
    "all_image_files = [fn for fn in all_files if fn.startswith(config.image_fn) and fn.endswith(config.image_type)]#ndwi.png\n",
    "for i, fn in enumerate(all_image_files):\n",
    "    f,nums = readImgs(path_to_write,fn)\n",
    "    frames.append(f)\n",
    "test_DGT=DataGenerator(config.input_size, config.output_size,frames, augmenter = None)\n",
    "tp_img,tp_ann= test_DGT.all_sequential_patches(config.step_size)\n",
    "print(len(tp_ann))\n",
    "\n",
    "titles=['ndwi','rgb','swir','annotation','prediction']\n",
    "for i in range(len(tp_ann//config.BATCH_SIZE)+1):\n",
    "    prediction = model.predict(tp_img[i*config.BATCH_SIZE:(i+1)*config.BATCH_SIZE], steps=1)\n",
    "    prediction[prediction>0.5]=1\n",
    "    prediction[prediction<=0.5]=0\n",
    "    fn=os.path.join(config.base_dir,r'4_prediction\\sample746\\image\\type{}_{}_{}.png'.format(j,i,config.output_size[0]))\n",
    "    display_images(tp_img[i*config.BATCH_SIZE:(i+1)*config.BATCH_SIZE], tp_ann[i*config.BATCH_SIZE:(i+1)*config.BATCH_SIZE], prediction,92,config.output_size[0],fn.format(i),titles=titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总体精度评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "type0 image number:53\n",
      "type1 image number:48\n",
      "type2 image number:23\n",
      "type3 image number:18\n",
      "type4 image number:3\n",
      "type5 image number:6\n",
      "test patchs number: 5254\n"
     ]
    }
   ],
   "source": [
    "frames,numList=readFrames('test')\n",
    "test_patches = DataGenerator(config.input_size, config.output_size, frames, augmenter = None).all_sequential_patches(config.step_size)\n",
    "print('test patchs number:',len(test_patches[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ev\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_patches\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_patches\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m ev\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(test_patches[\u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "ev=model.evaluate(test_patches[0],test_patches[1],config.BATCH_SIZE)\n",
    "ev.append(len(test_patches[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11038431525230408, 0.11386916786432266, 0.9946683049201965, 0.9123051166534424, 0.8933606743812561, 0.8861443400382996, 0.8190804719924927]\n"
     ]
    }
   ],
   "source": [
    "print(ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类别精度评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 22s 166ms/step - loss: 0.1077 - dice_loss: 0.1079 - accuracy: 0.9938 - recall: 0.9154 - F1_score: 0.8922 - precision: 0.8900 - IoU: 0.8237\n",
      "50/50 [==============================] - 9s 156ms/step - loss: 0.1029 - dice_loss: 0.1046 - accuracy: 0.9981 - recall: 0.9172 - F1_score: 0.8954 - precision: 0.8983 - IoU: 0.8251\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/conv2d/Conv2D' defined at (most recent call last):\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\asus\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\traitlets\\config\\application.py\", line 1077, in launch_instance\n      app.start()\n    File \"C:\\Users\\asus\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"C:\\Users\\asus\\AppData\\Roaming\\Python\\Python38\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\asus\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\asus\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\asus\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"C:\\Users\\asus\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\asus\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\asus\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_11944\\2172035856.py\", line 13, in <module>\n      ev2=model.evaluate(test_patchs_type[0],test_patchs_type[1],config.BATCH_SIZE,verbose=1)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\engine\\training.py\", line 1756, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\engine\\training.py\", line 1557, in test_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\engine\\training.py\", line 1546, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\engine\\training.py\", line 1535, in run_step\n      outputs = model.test_step(data)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\engine\\training.py\", line 1499, in test_step\n      y_pred = self(x, training=False)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 250, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 225, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv2d/Conv2D'\nOOM when allocating tensor with shape[16,570,570,64] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv2d/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_test_function_2378]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m     test_patchs_type \u001b[38;5;241m=\u001b[39m DataGenerator(config\u001b[38;5;241m.\u001b[39minput_size, config\u001b[38;5;241m.\u001b[39moutput_size, frames, augmenter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;241m.\u001b[39mall_sequential_patches(config\u001b[38;5;241m.\u001b[39mstep_size)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#     print('type{} patches number:{}'.format(i,len(test_patchs_type[0])))\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     ev2\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_patchs_type\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_patchs_type\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     ev2\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(test_patchs_type[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m     15\u001b[0m     ev_list\u001b[38;5;241m.\u001b[39mappend(ev2)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/conv2d/Conv2D' defined at (most recent call last):\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\asus\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\traitlets\\config\\application.py\", line 1077, in launch_instance\n      app.start()\n    File \"C:\\Users\\asus\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"C:\\Users\\asus\\AppData\\Roaming\\Python\\Python38\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\asus\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\asus\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\asus\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"C:\\Users\\asus\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\asus\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\asus\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_11944\\2172035856.py\", line 13, in <module>\n      ev2=model.evaluate(test_patchs_type[0],test_patchs_type[1],config.BATCH_SIZE,verbose=1)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\engine\\training.py\", line 1756, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\engine\\training.py\", line 1557, in test_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\engine\\training.py\", line 1546, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\engine\\training.py\", line 1535, in run_step\n      outputs = model.test_step(data)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\engine\\training.py\", line 1499, in test_step\n      y_pred = self(x, training=False)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 250, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 225, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv2d/Conv2D'\nOOM when allocating tensor with shape[16,570,570,64] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv2d/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_test_function_2378]"
     ]
    }
   ],
   "source": [
    "ev_list=[]\n",
    "for i in range(1,config.type_num):\n",
    "    frames=[]\n",
    "    test_patchs_type=[]\n",
    "    path_to_write=os.path.join(config.dataset_dir,'test/type'+str(i))\n",
    "    all_files = os.listdir(path_to_write)\n",
    "    all_image_files = [fn for fn in all_files if fn.startswith(config.image_fn) and fn.endswith(config.image_type)]#ndwi.png\n",
    "    for j, fn in enumerate(all_image_files):\n",
    "        f ,num = readImgs(path_to_write,fn)\n",
    "        frames.append(f)\n",
    "    test_patchs_type = DataGenerator(config.input_size, config.output_size, frames, augmenter = None).all_sequential_patches(config.step_size)\n",
    "#     print('type{} patches number:{}'.format(i,len(test_patchs_type[0])))\n",
    "    ev2=model.evaluate(test_patchs_type[0],test_patchs_type[1],config.BATCH_SIZE,verbose=1)\n",
    "    ev2.append(len(test_patchs_type[0]))\n",
    "    ev_list.append(ev2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_list=[]\n",
    "ev_list.append(ev2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ev2\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_patchs_type\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_patchs_type\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m ev2\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(test_patchs_type[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m      3\u001b[0m ev_list\u001b[38;5;241m.\u001b[39mappend(ev2)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "ev2=model.evaluate(test_patchs_type[0],test_patchs_type[1],config.BATCH_SIZE,verbose=1)\n",
    "ev2.append(len(test_patchs_type[0]))\n",
    "ev_list.append(ev2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      patch_num   loss  dice_loss accuracy   recall  precision F1_score     IoU\n",
      "type0:  1928     0.061    0.061    0.998     0.929     0.939     0.959     0.891  \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# print('total: {:^9}{:^9.3f}{:^9.3f}{:^9.3f} {:^9.3f} {:^9.3f} {:^9.3f} {:^9.3f}'.format(ev[7],ev[0],ev[1],ev[2],ev[3],ev[4],ev[5],ev[6]))\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,config\u001b[38;5;241m.\u001b[39mtype_num):\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{:^9}\u001b[39;00m\u001b[38;5;132;01m{:^9.3f}\u001b[39;00m\u001b[38;5;132;01m{:^9.3f}\u001b[39;00m\u001b[38;5;132;01m{:^9.3f}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{:^9.3f}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{:^9.3f}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{:^9.3f}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{:^9.3f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i,\u001b[43mev_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m7\u001b[39m],ev_list[i][\u001b[38;5;241m0\u001b[39m],ev_list[i][\u001b[38;5;241m1\u001b[39m],ev_list[i][\u001b[38;5;241m2\u001b[39m],ev_list[i][\u001b[38;5;241m3\u001b[39m],ev_list[i][\u001b[38;5;241m4\u001b[39m],ev_list[i][\u001b[38;5;241m5\u001b[39m],ev_list[i][\u001b[38;5;241m6\u001b[39m]))\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print('      patch_num   loss  dice_loss accuracy   recall  precision F1_score     IoU')\n",
    "# print('total: {:^9}{:^9.3f}{:^9.3f}{:^9.3f} {:^9.3f} {:^9.3f} {:^9.3f} {:^9.3f}'.format(ev[7],ev[0],ev[1],ev[2],ev[3],ev[4],ev[5],ev[6]))\n",
    "for i in range(0,config.type_num):\n",
    "    print('type{}:{:^9}{:^9.3f}{:^9.3f}{:^9.3f} {:^9.3f} {:^9.3f} {:^9.3f} {:^9.3f}'.format(i,ev_list[i][7],ev_list[i][0],ev_list[i][1],ev_list[i][2],ev_list[i][3],ev_list[i][4],ev_list[i][5],ev_list[i][6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOeYCBzQRMr8FXNUC8za+ng",
   "collapsed_sections": [],
   "name": "step3-Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf_gpu_38",
   "language": "python",
   "name": "tf_gpu_38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Author: Ankit Kariryaa, University of Bremen\n",
    "  \n",
    "  Modified by Xuehui Pi and Qiuqi Luo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started\n",
    "Define the paths for the dataset and trained models in the `notebooks/config/UNetTraining.py` file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = '16'\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = '16'\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '16'\n",
    "print(os.environ.get('OMP_NUM_THREADS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import mixed_precision \n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "import time\n",
    "import rasterio.warp             # Reproject raster samples\n",
    "from functools import reduce\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from core.UNet import UNet  #\n",
    "from core.losses import tversky, focalTversky, bce_dice_loss, accuracy, dice_loss, IoU, recall, precision\n",
    "from tensorflow.keras.losses import BinaryCrossentropy as bce\n",
    "from core.optimizers import adaDelta, adagrad, adam, nadam\n",
    "from core.frame_info import FrameInfo\n",
    "from core.dataset_generator import DataGenerator\n",
    "from core.visualize import display_images,plot\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import shutil\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # plotting tools\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Polygon\n",
    "#matplotlib.use(\"Agg\")\n",
    "\n",
    "import warnings                  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "#Mixed precision is the use of both 16-bit and 32-bit floating-point types in a model during training to make it run faster and use less memory.\n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "# tf.device('/gpu:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto(\n",
    "    #device_count={\"CPU\": 64},\n",
    "    allow_soft_placement=True, \n",
    "    log_device_placement=False)\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required configurations (including the input and output paths) are stored in a separate file (such as config/UNetTraining.py)\n",
    "# Please provide required info in the file before continuing with this notebook. \n",
    "# hbh: in this scene,a new config named UNetTraining_sequential is created to distinguish from the original\n",
    "from config import UNetTraining_b3\n",
    "# In case you are using a different folder name such as configLargeCluster, then you should import from the respective folder \n",
    "# Eg. from configLargeCluster import UNetTraining\n",
    "config = UNetTraining_b3.Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readBands(path_to_write,fn):\n",
    "    img=rasterio.open(os.path.join(path_to_write,fn))\n",
    "#     im=img.read()\n",
    "#     axis=(0, 1)\n",
    "#     read_img=(im - im.mean(axis)) / (im.std(axis) + 1e-8)\n",
    "    read_img=img.read()/1000\n",
    "    return read_img\n",
    "\n",
    "def readImgs(path_to_write, fn):\n",
    "    NDWI_img = rasterio.open(os.path.join(path_to_write, fn))\n",
    "    read_NDWI_img = NDWI_img.read()/100\n",
    "    rowNum=read_NDWI_img.shape[1]/config.patch_size[0]\n",
    "    colNum=read_NDWI_img.shape[2]/config.patch_size[1]\n",
    "    read_green_img =readBands(path_to_write,fn.replace(config.NDWI_fn ,config.green_fn))\n",
    "    read_swir_img = readBands(path_to_write, fn.replace(config.NDWI_fn ,config.swir_fn))\n",
    "    comb_img = np.concatenate((read_NDWI_img,read_green_img, read_swir_img), axis=0)\n",
    "    comb_img = np.transpose(comb_img, axes=(1,2,0)) #Channel at the end  ( , ,1) \n",
    "    \n",
    "    annotation_im = Image.open(os.path.join(path_to_write, fn.replace(config.NDWI_fn,config.annotation_fn)))\n",
    "    annotation = np.array(annotation_im)\n",
    "    \n",
    "    f = FrameInfo(comb_img, annotation)\n",
    "    return f ,rowNum*colNum\n",
    "\n",
    "def readFrames(dataType):\n",
    "    frames=[]\n",
    "    numList=[]\n",
    "    print(dataType)\n",
    "    for i in range(0,config.type_num):\n",
    "        path_to_write=os.path.join(config.dataset_dir,'{}/type{}'.format(dataType,i))\n",
    "        all_files = os.listdir(path_to_write)\n",
    "        all_files_NDWI = [fn for fn in all_files if fn.startswith(config.NDWI_fn) and fn.endswith(config.image_type)]#ndwi.png\n",
    "        print('type{} image number:{}'.format(i,len(all_files_NDWI)))\n",
    "        for j, fn in enumerate(all_files_NDWI):\n",
    "            f,num = readImgs(path_to_write,fn)\n",
    "            frames.append(f)\n",
    "            numList.append(num)\n",
    "    return frames,numList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frames,numList=readFrames('train')\n",
    "percentages=np.array(numList)\n",
    "print(percentages.sum())\n",
    "percentages=percentages/percentages.sum()\n",
    "print('total training img count:'+str(len(frames)))\n",
    "train_generator = DataGenerator(config.input_image_channel, config.patch_size, frames, config.input_label_channel, augmenter = 'iaa').random_generator(config.BATCH_SIZE,percentages)#,normalize = config.normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# frames=readFrames('train')\n",
    "# train_patches = DataGenerator(config.input_image_channel, config.patch_size, frames, config.input_label_channel, augmenter = 'iaa').all_sequential_patches(config.step_size)\n",
    "# print('train patchs number:',len(train_patches[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frames,numList=readFrames('val')\n",
    "percentages=np.array(numList)\n",
    "print(percentages.sum())\n",
    "percentages=percentages/percentages.sum()\n",
    "print('total validation img count:'+str(len(frames)))\n",
    "val_generator = DataGenerator(config.input_image_channel, config.patch_size, frames, config.input_label_channel, augmenter = None).random_generator(config.BATCH_SIZE,percentages)#, normalize = config.normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del frames,percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(1):\n",
    "    val_images, val_label = next(val_generator) \n",
    "    print(val_images.shape)\n",
    "    display_images(np.concatenate((val_images,val_label), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(1):\n",
    "    train_images, real_label = next(train_generator) \n",
    "#     print(train_images.Length())\n",
    "    display_images(np.concatenate((train_images,real_label), axis = -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OPTIMIZER = adaDelta\n",
    "OPTIMIZER = mixed_precision.LossScaleOptimizer(OPTIMIZER)\n",
    "OPTIMIZER_NAME = 'AdaDelta'\n",
    "\n",
    "# OPTIMIZER = adam\n",
    "# OPTIMIZER = mixed_precision.LossScaleOptimizer(OPTIMIZER)\n",
    "# OPTIMIZER_NAME = 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSS = tversky \n",
    "# LOSS_NAME = 'tversky'\n",
    "\n",
    "# LOSS=focalTversky\n",
    "# LOSS_NAME = 'focalTversky'\n",
    "\n",
    "#LOSS=tf.keras.losses.BinaryCrossentropy()\n",
    "#LOSS_NAME = 'bce'\n",
    "\n",
    "# LOSS=bce_dice_loss\n",
    "# LOSS_NAME = 'bce_dice_loss'\n",
    "\n",
    "LOSS=dice_loss\n",
    "LOSS_NAME = 'dice_loss'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestr = time.strftime(\"%Y%m%d-%H%M\")\n",
    "chf = config.input_image_channel + config.input_label_channel\n",
    "chs = reduce(lambda a,b: a+str(b), chf, '') \n",
    "\n",
    "if not os.path.exists(config.model_path):\n",
    "    os.makedirs(config.model_path)\n",
    "model_name='_{}_{}_{}_{}_{}.h5'.format(timestr,OPTIMIZER_NAME,LOSS_NAME,chs,config.input_shape[0])\n",
    "model_path = os.path.join(config.model_path,'lakes'+model_name)\n",
    "\n",
    "chf = config.input_image_channel + config.input_label_channel\n",
    "chs = reduce(lambda a,b: a+str(b), chf, '') \n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the model and compile it  \n",
    "model = UNet([config.BATCH_SIZE, *config.input_shape],config.input_label_channel)\n",
    "model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=[dice_loss, accuracy, recall, precision, IoU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks      for the early stopping of training, LearningRateScheduler and model checkpointing \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = False)\n",
    "\n",
    "#reduceonplatea： It can be useful when using adam as optimizer\n",
    "#Reduce learning rate when a metric has stopped improving (after some patience 个epoch, reduce by a factor of 0.33, new_lr = lr * factor). \n",
    "#cooldown: number of epochs to wait before resuming normal operation after lr has been reduced. \n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.33,\n",
    "                                   patience=4, verbose=1, mode='min',\n",
    "                                   min_delta=0.0001, cooldown=4, min_lr=1e-16) \n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=2, patience=20)\n",
    "\n",
    "\n",
    "log_dir = os.path.join('./logs','UNet'+model_name)\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=0, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')\n",
    "\n",
    "callbacks_list = [checkpoint, tensorboard, early] #reduceLROnPlat is not required with adaDelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_history = model.fit(train_generator, \n",
    "                         steps_per_epoch=config.MAX_TRAIN_STEPS,\n",
    "                         epochs=config.NB_EPOCHS, \n",
    "                         validation_data=val_generator,\n",
    "                         validation_steps=config.VALID_IMG_COUNT,\n",
    "                         callbacks=callbacks_list,\n",
    "                         workers=1,\n",
    "#                          shuffle=True,\n",
    "#                          use_multiprocessing=True # the generator is not very thread safe \n",
    "                         #max_queue_size = 60,\n",
    "                        )\n",
    "h=loss_history.history\n",
    "with open('history_{}_{}_{}_{}_{}.txt'.format(timestr,OPTIMIZER_NAME,LOSS_NAME, chs,config.input_shape[0]), 'wb') as file_pi:\n",
    "    pickle.dump(h, file_pi)\n",
    "plot(h,timestr, OPTIMIZER_NAME,LOSS_NAME, config.patch_size[0], config.NB_EPOCHS, config.BATCH_SIZE,chs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 读取现有history文件\n",
    "# with open('.txt','rb')as file_pi:\n",
    "#     h=pickle.load(file_pi)\n",
    "# print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(h,timestr, OPTIMIZER_NAME,LOSS_NAME, config.patch_size[0], config.NB_EPOCHS, config.BATCH_SIZE,chs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames,numList=readFrames('test')\n",
    "percentages=np.array(numList)\n",
    "percentages=percentages/percentages.sum()\n",
    "print('total validation img count:'+str(len(frames)))\n",
    "test_generator = DataGenerator(config.input_image_channel, config.patch_size, frames, config.input_label_channel, augmenter = None).random_generator(config.BATCH_SIZE,percentages)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print one batch on the training/test data! \n",
    "for i in range(1):\n",
    "    test_images, real_label = next(test_generator)\n",
    "    #3 images per row: GSW, label, prediction\n",
    "    prediction = model.predict(test_images, steps=1)\n",
    "    prediction[prediction>0.5]=1\n",
    "    prediction[prediction<=0.5]=0\n",
    "    display_images(np.concatenate((test_images, real_label, prediction), axis = -1))# test_images( NDWI), real_label(label), prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型精度评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model after training \n",
    "model_path=r'D:\\lakemapping\\U_Net\\saved_models/UNet\\lakes_20231129-0018_AdaDelta_dice_loss_0123_512.h5'\n",
    "# model_path=r'D:\\lakemapping\\U_Net\\saved_models\\UNet\\lakes_20231109-1134_AdaDelta_dice_loss_0123_512.h5 '\n",
    "# model_path=r'D:\\lakemapping\\U_Net\\saved_models\\UNet\\lakes_area550_20231113-0337_AdaDelta_dice_loss_0123_512_percentages.h5'\n",
    "model = load_model(model_path, custom_objects={'dice loss': LOSS, 'accuracy':accuracy ,'recall':recall, 'precision':precision,'IoU': IoU}, compile=False) \n",
    "model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=[dice_loss, accuracy,recall, precision, IoU])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 总体精度评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frames,numList=readFrames('test')\n",
    "random.shuffle(frames)\n",
    "testDG=DataGenerator(config.input_image_channel, config.patch_size, frames, config.input_label_channel, augmenter = None)\n",
    "test_patches = testDG.all_sequential_patches(config.step_size)\n",
    "print('test patches number:',len(test_patches[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "print(test_patches[0][i*config.BATCH_SIZE:i*config.BATCH_SIZE+config.BATCH_SIZE].shape)\n",
    "display_images(np.concatenate((test_patches[0][i*config.BATCH_SIZE:i*config.BATCH_SIZE+config.BATCH_SIZE],test_patches[1][i*config.BATCH_SIZE:i*config.BATCH_SIZE+config.BATCH_SIZE]), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i=1\n",
    "prediction = model.predict(test_patches[0][i*config.BATCH_SIZE:i*config.BATCH_SIZE+config.BATCH_SIZE], steps=1)\n",
    "prediction[prediction>0.5]=1\n",
    "prediction[prediction<=0.5]=0\n",
    "display_images(np.concatenate((test_patches[0][i*config.BATCH_SIZE:i*config.BATCH_SIZE+config.BATCH_SIZE], test_patches[1][i*config.BATCH_SIZE:i*config.BATCH_SIZE+config.BATCH_SIZE], prediction), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_patches[0],test_patches[1],config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del frames,testDG,test_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "frames=[]\n",
    "path_to_write=os.path.join(config.dataset_dir,'test\\\\type'+str(j))\n",
    "all_files = os.listdir(path_to_write)\n",
    "all_files_NDWI = [fn for fn in all_files if fn.startswith(config.NDWI_fn) and fn.endswith(config.image_type)]#ndwi.png\n",
    "for j, fn in enumerate(all_files_NDWI):\n",
    "    f,nums = readImgs(path_to_write,fn)\n",
    "    frames.append(f)\n",
    "test_DGT=DataGenerator(config.input_image_channel, config.patch_size, frames, config.input_label_channel, augmenter = None)\n",
    "test_patches_type = test_DGT.all_sequential_patches(config.step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(test_patches_type[0][i*config.BATCH_SIZE:(i+1)*config.BATCH_SIZE], steps=1)\n",
    "prediction[prediction>0.5]=1\n",
    "prediction[prediction<=0.5]=0\n",
    "display_images(np.concatenate((test_patches_type[0][i*config.BATCH_SIZE:(i+1)*config.BATCH_SIZE ], test_patches_type[1][i*config.BATCH_SIZE:i*16+16], prediction), axis = -1),titles='i='+str(i))\n",
    "i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分类别精度评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,config.type_num):\n",
    "    frames=[]\n",
    "    path_to_write=os.path.join(config.dataset_dir,'test\\\\type'+str(i))\n",
    "    all_files = os.listdir(path_to_write)\n",
    "    all_files_NDWI = [fn for fn in all_files if fn.startswith(config.NDWI_fn) and fn.endswith(config.image_type)]#ndwi.png\n",
    "    for j, fn in enumerate(all_files_NDWI):\n",
    "        f,nums = readImgs(path_to_write,fn)\n",
    "        frames.append(f)\n",
    "    test_DGT=DataGenerator(config.input_image_channel, config.patch_size, frames, config.input_label_channel, augmenter = None)\n",
    "    test_patches_type = test_DGT.all_sequential_patches(config.step_size)\n",
    "    print('type{} patches number:{}'.format(i,len(test_patches_type[0])))\n",
    "    model.evaluate(test_patches_type[0],test_patches_type[1],config.BATCH_SIZE)\n",
    "    # del frames,test_DGT,test_patches_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12364), started 0:58:25 ago. (Use '!kill 12364' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2b2f7a9f0c5a0f13\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2b2f7a9f0c5a0f13\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=logs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOeYCBzQRMr8FXNUC8za+ng",
   "collapsed_sections": [],
   "name": "step3-Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "hbh_env",
   "language": "python",
   "name": "hbh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

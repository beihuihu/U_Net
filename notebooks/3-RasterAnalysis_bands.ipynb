{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import mixed_precision \n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "import geopandas as gps\n",
    "import rasterio                  # I/O raster data (netcdf, height, geotiff, ...)\n",
    "import rasterio.warp             # Reproject raster samples\n",
    "from rasterio import windows\n",
    "from rasterio import features\n",
    "import fiona                     # I/O vector data (shape, geojson, ...)\n",
    "import pyproj                    # Change coordinate reference system\n",
    "from osgeo import gdal, ogr, osr\n",
    "import pandas as pd\n",
    "import shapely\n",
    "from shapely.geometry import Point, Polygon,box\n",
    "from shapely.geometry import mapping, shape\n",
    "import cv2\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import numpy as np               # numerical array manipulation\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import PIL.ImageDraw\n",
    "import shutil\n",
    "from itertools import product\n",
    "\n",
    "import sys\n",
    "from core.UNet import UNet\n",
    "from core.losses import accuracy, dice_loss, IoU, recall, precision,F1_score\n",
    "from core.optimizers import adaDelta, adagrad, adam, nadam\n",
    "from core.visualize import display_images\n",
    "\n",
    "import matplotlib.pyplot as plt  # plotting tools\n",
    "%matplotlib inline\n",
    "import warnings                  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto(\n",
    "    #device_count={\"CPU\": 64},\n",
    "    allow_soft_placement=True, \n",
    "    log_device_placement=False)\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required configurations (including the input and output paths) are stored in a separate file (such as config/RasterAnalysis.py)\n",
    "# Please provide required info in the file before continuing with this notebook. \n",
    " \n",
    "from config import RasterAnalysis_bands\n",
    "# In case you are using a different folder name such as configLargeCluster, then you should import from the respective folder \n",
    "# Eg. from configLargeCluster import RasterAnalysis\n",
    "config = RasterAnalysis_bands.Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model \n",
    "OPTIMIZER = adaDelta\n",
    "OPTIMIZER=mixed_precision.LossScaleOptimizer(OPTIMIZER)\n",
    "model = load_model(config.trained_model_path, custom_objects={'dice loss': dice_loss, 'accuracy':accuracy ,'recall':recall, 'F1_score':F1_score,'precision':precision,'IoU': IoU}, compile=False)\n",
    "model.compile(optimizer=OPTIMIZER, loss=dice_loss, metrics=[dice_loss, accuracy,recall, precision, IoU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods to add results of a patch   to    the total results of a larger area. \n",
    "#The operator could be min (useful if there are too many false positives), max (useful for tackle false negatives)\n",
    "#res:mask [rows,cols] predition=np.squeeze(prediction[i], axis = -1) (col, row, wi, he) = batch_pos[i]\n",
    "def addTOResult(res, prediction, row, col, he, wi,operator,ie_width):\n",
    "    currValue = res[row+ie_width:row+he-ie_width, col+ie_width:col+wi-ie_width]\n",
    "    newPredictions = prediction[ie_width:he-ie_width, ie_width:wi-ie_width]\n",
    "    \n",
    "# IMPORTANT: MIN can't be used as long as the mask is initialed with 0!!!!! \n",
    "#If you want to use MIN initial the mask with -1 and handle the case of default value(-1) separately.\n",
    "    if operator == 'min': # Takes the min of current prediction and new prediction for each pixel  \n",
    "        currValue [currValue == -1] = 1 #Replace -1 with 1 in case of MIN  \n",
    "        res[row+ie_width:row+he-ie_width, col+ie_width:col+wi-ie_width] = np.minimum(currValue, newPredictions)\n",
    "    elif operator == 'max':\n",
    "        res[row+ie_width:row+he-ie_width, col+ie_width:col+wi-ie_width] = np.maximum(currValue, newPredictions)\n",
    "    else:\n",
    "        res[row+ie_width:row+he-ie_width, col+ie_width:col+wi-ie_width] = newPredictions  \n",
    "    return (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods that actually makes the predictions\n",
    "def predict_using_model(model, batch, batch_pos, mask,operator,ie_width):\n",
    "#     print(batch)\n",
    "    tm = np.stack(batch, axis = 0)\n",
    "#     print(tm)\n",
    "    prediction = model.predict(tm)\n",
    "    for i in range(len(batch_pos)): \n",
    "        (col, row, wi, he) = batch_pos[i]\n",
    "        p = np.squeeze(prediction[i], axis = -1)\n",
    "        # Instead of replacing the current values with new values, use the user specified operator (MIN,MAX,REPLACE)\n",
    "        mask = addTOResult(mask, p, row, col, he, wi,operator,ie_width)  \n",
    "    return mask\n",
    "\n",
    "def detect_lake(fullPath, NDWI_img, bands_img, operator ,width=512, height=512, stride = 256,ie_width=0,bandNum=1):\n",
    "    nols, nrows = NDWI_img.meta['width'], NDWI_img.meta['height']\n",
    "    meta = NDWI_img.meta.copy() \n",
    "    if 'float' not in meta['dtype']: #The prediction is a float so we keep it as float to be consistent with the prediction. \n",
    "        meta['dtype'] = np.float32\n",
    "    col_index=list(range(0, nols-width, stride))\n",
    "    col_index.append(nols-width)\n",
    "    row_index=list(range(0, nrows-height, stride))\n",
    "    row_index.append(nrows-height)\n",
    "    offsets = product(col_index,row_index)\n",
    "    big_window = windows.Window(col_off=0, row_off=0, width=nols, height=nrows)\n",
    "    print('the size of current NDWI_img',nrows, nols) \n",
    "\n",
    "    mask = np.zeros((nrows, nols), dtype=meta['dtype'])\n",
    "\n",
    "#     mask = mask -1   # Note: The initial mask is initialized with -1 instead of zero   to handle the MIN case (see addToResult)\n",
    "    batch = []\n",
    "    batch_pos = [ ]\n",
    "    for col_off, row_off in  tqdm(offsets):\n",
    "        window =windows.Window(col_off=col_off, row_off=row_off, width=width, height=height).intersection(big_window)\n",
    "        transform = windows.transform(window, NDWI_img.transform) \n",
    "#         hbh:notice datatype is float\n",
    "        patch = np.full((height, width, bandNum),-1.0)#Add -1 padding in case of corner images\n",
    "        read_ndwi_img=NDWI_img.read(window=window)/100\n",
    "        read_bands_img = bands_img.read(window=window)/1000\n",
    "#         hbh:change band sequence with the same as training data\n",
    "        read_bands_img[[0,2],:]=read_bands_img[[2,0],:]\n",
    "        temp_im = np.concatenate((read_ndwi_img,read_bands_img), axis=0)\n",
    "        temp_im =  np.transpose(temp_im, axes=(1,2,0))\n",
    "\n",
    "        patch[:window.height, :window.width] = temp_im   \n",
    "        batch.append(patch)\n",
    "        batch_pos.append((window.col_off, window.row_off, window.width, window.height))\n",
    "        \n",
    "        if (len(batch) == config.BATCH_SIZE):\n",
    "            mask = predict_using_model(model, batch, batch_pos, mask,operator,ie_width)\n",
    "            batch = []\n",
    "            batch_pos = []\n",
    "            \n",
    "    # To handle the edge of images as the image size may not be divisible by n complete batches and few frames on the edge may be left.\n",
    "    if batch:\n",
    "        mask = predict_using_model(model, batch, batch_pos, mask,operator,ie_width)\n",
    "        batch = []\n",
    "        batch_pos = []\n",
    "\n",
    "    return(mask, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeMaskToDisk(detected_mask, detected_meta, wp, write_as_type = 'uint8', th = 0.5, create_countors = False):\n",
    "    # Convert to correct required before writing\n",
    "    if 'float' in str(detected_meta['dtype']) and 'int' in write_as_type:\n",
    "        print(f'Converting prediction from {detected_meta[\"dtype\"]} to {write_as_type}, using threshold of {th}')#float32 to uint8\n",
    "#         initial code have problem of big lake\n",
    "        detected_mask[detected_mask<th]=0\n",
    "        detected_mask[detected_mask>=th]=1\n",
    "        detected_mask = detected_mask.astype(write_as_type)#'uint8'\n",
    "        detected_meta['dtype'] =  write_as_type\n",
    "    \n",
    "    # compress tif\n",
    "    detected_meta.update({\"compress\": 'lzw'})\n",
    "    \n",
    "    with rasterio.open(wp, 'w', **detected_meta) as outds:\n",
    "        outds.write(detected_mask, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_image_dir=r'F:/ndwi_int8_7000'\n",
    "# input_image_dir=r'/media/nkd/data18931/ndwi_int8_13001_18931'\n",
    "operator='max'\n",
    "suffix='_iew{}'.format(config.ignore_edge_width)\n",
    "for start in np.arange(1,7000,1000):\n",
    "    \n",
    "# start=11001\n",
    "    end=start+1000\n",
    "    for index in range(start,end):\n",
    "        out_dir=os.path.join(config.output_dir,f'{start}_{end-1}')\n",
    "        if not os.path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "        filename=f'{config.ndwi_fn_st}_{index}{config.input_image_type}'\n",
    "        fullPath=os.path.join(input_image_dir,filename)\n",
    "        outputFile = os.path.join(out_dir, f'{config.output_prefix}{index}{suffix}{config.input_image_type}')\n",
    "        if not os.path.isfile(outputFile) or config.overwrite_analysed_files: \n",
    "            with rasterio.open(fullPath) as NDWI:\n",
    "                with rasterio.open(fullPath.replace(config.ndwi_fn_st,config.bands_fn_st)) as bands:\n",
    "                    print(fullPath)\n",
    "                    detectedMask, detectedMeta = detect_lake(fullPath,NDWI,bands,operator,width = config.WIDTH, height = config.HEIGHT, stride = config.STRIDE,ie_width=config.ignore_edge_width,bandNum=config.band_num)\n",
    "                    writeMaskToDisk(detectedMask, detectedMeta, outputFile, write_as_type = config.output_dtype, th = 0.5, create_countors = False)            \n",
    "            print('File already analysed!', fullPath)\n",
    "        \n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_38",
   "language": "python",
   "name": "tf_gpu_38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

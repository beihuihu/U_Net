{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gps\n",
    "import rasterio                  # I/O raster data (netcdf, height, geotiff, ...)\n",
    "import rasterio.mask\n",
    "import rasterio.warp             # Reproject raster samples\n",
    "import rasterio.merge\n",
    "from rasterio.transform import rowcol\n",
    "from rasterio import features\n",
    "import fiona                     # I/O vector data (shape, geojson, ...)\n",
    "import pyproj                    # Change coordinate reference system\n",
    "from osgeo import gdal\n",
    "import pandas as pd\n",
    "import shapely\n",
    "from shapely.geometry import box, Point\n",
    "import json\n",
    "\n",
    "import numpy as np               # numerical array manipulation\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "import PIL.ImageDraw\n",
    "from core.visualize import display_images\n",
    "\n",
    "import matplotlib.pyplot as plt  # plotting tools\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import trange\n",
    "import warnings                  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_base_dir=r'D:\\lakemapping\\2_dataset\\output600'\n",
    "# raw_image_base_dir=r'G:\\5_lakemapping\\sample_img_3'\n",
    "output_dir=r'/media/nkd/backup/5_lakemapping/sample600/output'\n",
    "raw_image_base_dir=r'/media/nkd/backup/5_lakemapping/sample_img'\n",
    "raw_ndwi_image_prefix = 'ndwi_int8_'\n",
    "raw_bands_image_prefix = 'bands_int16_'\n",
    "raw_image_file_type = '.tif'\n",
    "extracted_file_type = '.png'\n",
    "extracted_ndwi_filename = 'ndwi'\n",
    "extracted_bands_filename = ['blue','green','red','swir']\n",
    "extracted_annotation_filename = 'annotation'\n",
    "type_num=6\n",
    "ndwi_band = [0]# If raster has multiple channels, then bands will be [0, 1, ...] otherwise simply [0]\n",
    "four_bands = [0,1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: path_to_write0 is not empty! The old files in the directory may not be overwritten!!\n",
      "Warning: path_to_write1 is not empty! The old files in the directory may not be overwritten!!\n",
      "Warning: path_to_write2 is not empty! The old files in the directory may not be overwritten!!\n",
      "Warning: path_to_write3 is not empty! The old files in the directory may not be overwritten!!\n",
      "Warning: path_to_write4 is not empty! The old files in the directory may not be overwritten!!\n",
      "Warning: path_to_write5 is not empty! The old files in the directory may not be overwritten!!\n"
     ]
    }
   ],
   "source": [
    "#hbh: check whether the output dir(must be present) of each type is empty\n",
    "for i in range(0,type_num):\n",
    "    path_to_write=os.path.join(output_dir,'output'+str(i))\n",
    "    assert os.path.exists(path_to_write)\n",
    "    if not len(os.listdir(path_to_write))==0:\n",
    "         print('Warning: path_to_write{} is not empty! The old files in the directory may not be overwritten!!'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84192, 2) (200, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS_NAME</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lake</td>\n",
       "      <td>POLYGON Z ((-87.75822 75.51463 0.00000, -87.75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lake</td>\n",
       "      <td>POLYGON Z ((-87.65832 75.50690 0.00000, -87.65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lake</td>\n",
       "      <td>POLYGON Z ((-87.73765 75.49621 0.00000, -87.73...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lake</td>\n",
       "      <td>POLYGON Z ((-87.68015 75.49181 0.00000, -87.68...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lake</td>\n",
       "      <td>POLYGON Z ((-87.75031 75.48534 0.00000, -87.75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84187</th>\n",
       "      <td>Lake</td>\n",
       "      <td>POLYGON Z ((112.29534 62.21211 0.00000, 112.29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84188</th>\n",
       "      <td>Lake</td>\n",
       "      <td>POLYGON Z ((112.30298 62.20591 0.00000, 112.30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84189</th>\n",
       "      <td>Lake</td>\n",
       "      <td>POLYGON Z ((112.17056 62.20896 0.00000, 112.17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84190</th>\n",
       "      <td>Lake</td>\n",
       "      <td>POLYGON Z ((112.30145 62.20339 0.00000, 112.30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84191</th>\n",
       "      <td>Lake</td>\n",
       "      <td>POLYGON Z ((112.02953 62.17114 0.00000, 112.02...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84192 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CLASS_NAME                                           geometry\n",
       "0           Lake  POLYGON Z ((-87.75822 75.51463 0.00000, -87.75...\n",
       "1           Lake  POLYGON Z ((-87.65832 75.50690 0.00000, -87.65...\n",
       "2           Lake  POLYGON Z ((-87.73765 75.49621 0.00000, -87.73...\n",
       "3           Lake  POLYGON Z ((-87.68015 75.49181 0.00000, -87.68...\n",
       "4           Lake  POLYGON Z ((-87.75031 75.48534 0.00000, -87.75...\n",
       "...          ...                                                ...\n",
       "84187       Lake  POLYGON Z ((112.29534 62.21211 0.00000, 112.29...\n",
       "84188       Lake  POLYGON Z ((112.30298 62.20591 0.00000, 112.30...\n",
       "84189       Lake  POLYGON Z ((112.17056 62.20896 0.00000, 112.17...\n",
       "84190       Lake  POLYGON Z ((112.30145 62.20339 0.00000, 112.30...\n",
       "84191       Lake  POLYGON Z ((112.02953 62.17114 0.00000, 112.02...\n",
       "\n",
       "[84192 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.266275</td>\n",
       "      <td>10198</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON Z ((-3.15840 51.46483 0.00000, -3.2822...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>156.689881</td>\n",
       "      <td>10203</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON Z ((-3.99269 56.16025 0.00000, -3.7520...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>417.358125</td>\n",
       "      <td>10228</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON Z ((-0.39148 52.69972 0.00000, -0.1020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>402.500829</td>\n",
       "      <td>10247</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON Z ((4.29607 51.33661 0.00000, 4.59752 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>352.732846</td>\n",
       "      <td>10277</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON Z ((8.09904 53.23757 0.00000, 8.33101 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15346</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON Z ((54.02269 72.97526 0.00000, 54.3949...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15355</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON Z ((56.16821 70.93170 0.00000, 56.3962...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15381</td>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON Z ((61.22978 75.61631 0.00000, 61.5317...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>242.767959</td>\n",
       "      <td>2796</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON Z ((-16.56337 12.58014 0.00000, -16.44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.564338</td>\n",
       "      <td>191.555829</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON Z ((-78.85202 1.19697 0.00000, -79.009...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Shape_Leng  Shape_Area     id  type  \\\n",
       "0      0.000000   84.266275  10198     2   \n",
       "1      0.000000  156.689881  10203     2   \n",
       "2      0.000000  417.358125  10228     2   \n",
       "3      0.000000  402.500829  10247     2   \n",
       "4      0.000000  352.732846  10277     2   \n",
       "..          ...         ...    ...   ...   \n",
       "195    0.000000    0.000000  15346     1   \n",
       "196    0.000000    0.000000  15355     1   \n",
       "197    0.000000    0.000000  15381     3   \n",
       "198    0.000000  242.767959   2796     1   \n",
       "199    0.564338  191.555829     43     1   \n",
       "\n",
       "                                              geometry  \n",
       "0    POLYGON Z ((-3.15840 51.46483 0.00000, -3.2822...  \n",
       "1    POLYGON Z ((-3.99269 56.16025 0.00000, -3.7520...  \n",
       "2    POLYGON Z ((-0.39148 52.69972 0.00000, -0.1020...  \n",
       "3    POLYGON Z ((4.29607 51.33661 0.00000, 4.59752 ...  \n",
       "4    POLYGON Z ((8.09904 53.23757 0.00000, 8.33101 ...  \n",
       "..                                                 ...  \n",
       "195  POLYGON Z ((54.02269 72.97526 0.00000, 54.3949...  \n",
       "196  POLYGON Z ((56.16821 70.93170 0.00000, 56.3962...  \n",
       "197  POLYGON Z ((61.22978 75.61631 0.00000, 61.5317...  \n",
       "198  POLYGON Z ((-16.56337 12.58014 0.00000, -16.44...  \n",
       "199  POLYGON Z ((-78.85202 1.19697 0.00000, -79.009...  \n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read a total of 84192 object polygons and 200 training areas.\n",
      "Polygons will be assigned to training areas in the next steps.\n"
     ]
    }
   ],
   "source": [
    "#Read the training area 、 training polygons\n",
    "# trainingArea = gps.read_file(r\"D:\\lakemapping\\2_dataset\\sampleAnnotations\\area\")\n",
    "# trainingPolygon = gps.read_file(r\"D:\\lakemapping\\2_dataset\\sampleAnnotations\\polygon\")\n",
    "trainingArea = gps.read_file(r\"/media/nkd/backup/5_lakemapping/sample600/sample/area\")\n",
    "trainingPolygon = gps.read_file(r\"/media/nkd/backup/5_lakemapping/sample600/sample/polygon\")\n",
    "\n",
    "print(trainingPolygon.shape,trainingArea.shape)# area:id, geomerry;   polygon:id, geometry \n",
    "trainingPolygon\n",
    "trainingArea\n",
    "print(f'Read a total of {trainingPolygon.shape[0]} object polygons and {trainingArea.shape[0]} training areas.')\n",
    "print(f'Polygons will be assigned to training areas in the next steps.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.0174532925199433],AXIS[\"Longitude\",EAST],AXIS[\"Latitude\",NORTH]]\n",
      "GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.0174532925199433],AXIS[\"Longitude\",EAST],AXIS[\"Latitude\",NORTH]]\n"
     ]
    }
   ],
   "source": [
    "# Check if the training areas and the training polygons have the same crs     \n",
    "if trainingArea.crs  != trainingPolygon.crs:\n",
    "    print('Training area CRS does not match training_polygon CRS')\n",
    "    targetCRS = trainingPolygon.crs #Areas are less in number so conversion should be faster\n",
    "    trainingArea = trainingArea.to_crs(targetCRS)\n",
    "print(trainingPolygon.crs)\n",
    "print(trainingArea.crs)\n",
    "assert trainingPolygon.crs == trainingArea.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb466d89530455a9e37b19a0c7de81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area's index: 0\n",
      "area's index: 1\n",
      "area's index: 2\n",
      "area's index: 3\n",
      "area's index: 4\n",
      "area's index: 5\n",
      "area's index: 6\n",
      "area's index: 7\n",
      "area's index: 8\n",
      "area's index: 9\n",
      "area's index: 10\n",
      "area's index: 11\n",
      "area's index: 12\n",
      "area's index: 13\n",
      "area's index: 14\n",
      "area's index: 15\n",
      "area's index: 16\n",
      "area's index: 17\n",
      "area's index: 18\n",
      "area's index: 19\n",
      "area's index: 20\n",
      "area's index: 21\n",
      "area's index: 22\n",
      "area's index: 23\n",
      "area's index: 24\n",
      "area's index: 25\n",
      "area's index: 26\n",
      "area's index: 27\n",
      "area's index: 28\n",
      "area's index: 29\n",
      "area's index: 30\n",
      "area's index: 31\n",
      "area's index: 32\n",
      "area's index: 33\n",
      "area's index: 34\n",
      "area's index: 35\n",
      "area's index: 36\n",
      "area's index: 37\n",
      "area's index: 38\n",
      "area's index: 39\n",
      "area's index: 40\n",
      "area's index: 41\n",
      "area's index: 42\n",
      "area's index: 43\n",
      "area's index: 44\n",
      "area's index: 45\n",
      "area's index: 46\n",
      "area's index: 47\n",
      "area's index: 48\n",
      "area's index: 49\n",
      "area's index: 50\n",
      "area's index: 51\n",
      "area's index: 52\n",
      "area's index: 53\n",
      "area's index: 54\n",
      "area's index: 55\n",
      "area's index: 56\n",
      "area's index: 57\n",
      "area's index: 58\n",
      "area's index: 59\n",
      "area's index: 60\n",
      "area's index: 61\n",
      "area's index: 62\n",
      "area's index: 63\n",
      "area's index: 64\n",
      "area's index: 65\n",
      "area's index: 66\n",
      "area's index: 67\n",
      "area's index: 68\n",
      "area's index: 69\n",
      "area's index: 70\n",
      "area's index: 71\n",
      "area's index: 72\n",
      "area's index: 73\n",
      "area's index: 74\n",
      "area's index: 75\n",
      "area's index: 76\n",
      "area's index: 77\n",
      "area's index: 78\n",
      "area's index: 79\n",
      "area's index: 80\n",
      "area's index: 81\n",
      "area's index: 82\n",
      "area's index: 83\n",
      "area's index: 84\n",
      "area's index: 85\n",
      "area's index: 86\n",
      "area's index: 87\n",
      "area's index: 88\n",
      "area's index: 89\n",
      "area's index: 90\n",
      "area's index: 91\n",
      "area's index: 92\n",
      "area's index: 93\n",
      "area's index: 94\n",
      "area's index: 95\n",
      "area's index: 96\n",
      "area's index: 97\n",
      "area's index: 98\n",
      "area's index: 99\n",
      "area's index: 100\n",
      "area's index: 101\n",
      "area's index: 102\n",
      "area's index: 103\n",
      "area's index: 104\n",
      "area's index: 105\n",
      "area's index: 106\n",
      "area's index: 107\n",
      "area's index: 108\n",
      "area's index: 109\n",
      "area's index: 110\n",
      "area's index: 111\n",
      "area's index: 112\n",
      "area's index: 113\n",
      "area's index: 114\n",
      "area's index: 115\n",
      "area's index: 116\n",
      "area's index: 117\n",
      "area's index: 118\n",
      "area's index: 119\n",
      "area's index: 120\n",
      "area's index: 121\n",
      "area's index: 122\n",
      "area's index: 123\n",
      "area's index: 124\n",
      "area's index: 125\n",
      "area's index: 126\n",
      "area's index: 127\n",
      "area's index: 128\n",
      "area's index: 129\n",
      "area's index: 130\n",
      "area's index: 131\n",
      "area's index: 132\n",
      "area's index: 133\n",
      "area's index: 134\n",
      "area's index: 135\n",
      "area's index: 136\n",
      "area's index: 137\n",
      "area's index: 138\n",
      "area's index: 139\n",
      "area's index: 140\n",
      "area's index: 141\n",
      "area's index: 142\n",
      "area's index: 143\n",
      "area's index: 144\n",
      "area's index: 145\n",
      "area's index: 146\n",
      "area's index: 147\n",
      "area's index: 148\n",
      "area's index: 149\n",
      "area's index: 150\n",
      "area's index: 151\n",
      "area's index: 152\n",
      "area's index: 153\n",
      "area's index: 154\n",
      "area's index: 155\n",
      "area's index: 156\n",
      "area's index: 157\n",
      "area's index: 158\n",
      "area's index: 159\n",
      "area's index: 160\n",
      "area's index: 161\n",
      "area's index: 162\n",
      "area's index: 163\n",
      "area's index: 164\n",
      "area's index: 165\n",
      "area's index: 166\n",
      "area's index: 167\n",
      "area's index: 168\n",
      "area's index: 169\n",
      "area's index: 170\n",
      "area's index: 171\n",
      "area's index: 172\n",
      "area's index: 173\n",
      "area's index: 174\n",
      "area's index: 175\n",
      "area's index: 176\n",
      "area's index: 177\n",
      "area's index: 178\n",
      "area's index: 179\n",
      "area's index: 180\n",
      "area's index: 181\n",
      "area's index: 182\n",
      "area's index: 183\n",
      "area's index: 184\n",
      "area's index: 185\n",
      "area's index: 186\n",
      "area's index: 187\n",
      "area's index: 188\n",
      "area's index: 189\n",
      "area's index: 190\n",
      "area's index: 191\n",
      "area's index: 192\n",
      "area's index: 193\n",
      "area's index: 194\n",
      "area's index: 195\n",
      "area's index: 196\n",
      "area's index: 197\n",
      "area's index: 198\n",
      "area's index: 199\n",
      "Assigned training polygons in 200 training areas\n"
     ]
    }
   ],
   "source": [
    "# As input we received two shapefile, first one contains the training areas/rectangles and other contains the polygon of lakes/objects in those training areas\n",
    "# The first task is to determine the parent training area for each polygon.\n",
    "\n",
    "def dividePolygonsInTrainingAreas(trainingPolygon, trainingArea):\n",
    "    '''Assign annotated ploygons in to the training areas.'''\n",
    "    # For efficiency, assigned polygons are removed from the list, we make a copy here. \n",
    "    cpTrainingPolygon = trainingPolygon.copy()\n",
    "    splitPolygons = {}\n",
    "    for i in tqdm(trainingArea.index):\n",
    "        spTemp = [] \n",
    "        allocated = []\n",
    "        print(\"area's index:\",i)\n",
    "        for j in cpTrainingPolygon.index:\n",
    "            if cpTrainingPolygon.loc[j]['geometry'].intersects(trainingArea.loc[i]['geometry']):\n",
    "                spTemp.append(cpTrainingPolygon.loc[j])\n",
    "                allocated.append(j)      \n",
    "        splitPolygons[i] = {'polygons':spTemp,'bounds':list(trainingArea.bounds.loc[i]),'id':trainingArea.loc[i]['id'] ,'type':trainingArea.loc[i]['type']}\n",
    "        cpTrainingPolygon = cpTrainingPolygon.drop(allocated)#assigned polygons are removed from the list\n",
    "    return splitPolygons\n",
    "\n",
    "# areasWithPolygons contains the object polygons for each area!\n",
    "areasWithPolygons = dividePolygonsInTrainingAreas(trainingPolygon, trainingArea)\n",
    "print(f'Assigned training polygons in {len(areasWithPolygons)} training areas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(areasWithPolygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAreasThatOverlapWithTrainingData(areaInfo, writePath):\n",
    "    \"\"\"Iterates over raw NDWI images and using findOverlap() extract areas that overlap with training data. \n",
    "    The overlapping areas in raw images are written in a separate file, and annotation file are created from polygons in the overlapping areas.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(writePath):\n",
    "        os.makedirs(writePath)\n",
    "        \n",
    "    polygonsInAreaDf = gps.GeoDataFrame(areaInfo['polygons'])\n",
    "    img_id=str(areaInfo['id'])\n",
    "    bboxArea = box(*areaInfo['bounds'])\n",
    "\n",
    "    #draw annotation png\n",
    "    # polygons = []\n",
    "    # for i in polygonsInAreaDf.index:\n",
    "    #     gm = polygonsInAreaDf.loc[i]['geometry']\n",
    "    #     polygons.append(gm)\n",
    "                \n",
    "    # with rasterio.open(os.path.join(writePath,extracted_annotation_filename+'_{}.png'.format(img_id)), 'w+', **profile) as out:\n",
    "    #     out_arr = out.read(1)\n",
    "    #     burned = features.rasterize(polygons, fill=0, default_value=1,out=out_arr, transform=out.transform)\n",
    "    #     out.write_band(1, burned)\n",
    "\n",
    "    #draw ndwi ong\n",
    "    ndwiImg = rasterio.open(os.path.join(raw_image_base_dir,raw_ndwi_image_prefix+img_id+raw_image_file_type))  \n",
    "    sm_ndwi = rasterio.mask.mask(ndwiImg, [bboxArea], all_touched=True, crop=True )\n",
    "    profile_ndwi = ndwiImg.profile  \n",
    "    profile_ndwi['height'] = sm_ndwi[0].shape[1]\n",
    "    profile_ndwi['width'] = sm_ndwi[0].shape[2]\n",
    "    profile_ndwi['transform'] = sm_ndwi[1]\n",
    "        # That's a problem with rasterio, if the height and the width are less then 256 it throws: ValueError: blockysize exceeds raster height \n",
    "        # So set the blockxsize and blockysize to prevent this problem\n",
    "    profile_ndwi['blockxsize'] = 32\n",
    "    profile_ndwi['blockysize'] = 32\n",
    "    profile_ndwi['count'] = 1\n",
    "    profile_ndwi['dtype'] = rasterio.float32\n",
    "    dt_ndwi = sm_ndwi[0][0].astype(profile_ndwi['dtype'])\n",
    "    with rasterio.open(os.path.join(writePath, extracted_ndwi_filename+'_{}.png'.format(img_id)), 'w', **profile_ndwi) as dst:\n",
    "        dst.write(dt_ndwi, 1) \n",
    "\n",
    "    #draw red green blue png\n",
    "    # bandsImg = rasterio.open(os.path.join(raw_image_base_dir,raw_bands_image_prefix+img_id+raw_image_file_type))\n",
    "    # sm_bands = rasterio.mask.mask(bandsImg, [bboxArea], all_touched=True, crop=True )\n",
    "    # profile_bands = bandsImg.profile  \n",
    "    # profile_bands['height'] = sm_bands[0].shape[1]\n",
    "    # profile_bands['width'] = sm_bands[0].shape[2]\n",
    "    # profile_bands['transform'] = sm_bands[1]\n",
    "    #     # That's a problem with rasterio, if the height and the width are less then 256 it throws: ValueError: blockysize exceeds raster height \n",
    "    #     # So set the blockxsize and blockysize to prevent this problem\n",
    "    # profile_bands['blockxsize'] = 32\n",
    "    # profile_bands['blockysize'] = 32\n",
    "    # profile_bands['count'] = len(four_bands)\n",
    "    # profile_bands['dtype'] = rasterio.float32\n",
    "    # for band, imFn in zip(four_bands, extracted_bands_filename):\n",
    "    #     dt_bands = sm_bands[0][band].astype(profile['dtype'])\n",
    "    #     with rasterio.open(os.path.join(writePath, imFn+'_{}.png'.format(img_id)), 'w', **profile_bands) as dst:\n",
    "    #         dst.write(dt_bands, 1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key,value in zip(areasWithPolygons.keys(),areasWithPolygons.values()):\n",
    "    path_to_write=os.path.join(output_dir,'output{}'.format(value['type']))\n",
    "    extractAreasThatOverlapWithTrainingData(value,path_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_base_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m sampleImage \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_55.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# path_to_write=os.path.join(training_base_dir,'output\\output4')\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m path_to_write\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mtraining_base_dir\u001b[49m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput588\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124moutput0\u001b[39m\u001b[38;5;124m'\u001b[39m )\n\u001b[1;32m      5\u001b[0m fn \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path_to_write, extracted_NDWI_filename \u001b[38;5;241m+\u001b[39m sampleImage)\n\u001b[1;32m      6\u001b[0m NDWI_img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(fn)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_base_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# Display extracted image \n",
    "sampleImage = '_55.png'\n",
    "# path_to_write=os.path.join(training_base_dir,'output\\output4')\n",
    "path_to_write=os.path.join(training_base_dir,'output588\\output0' )\n",
    "fn = os.path.join(path_to_write, extracted_NDWI_filename + sampleImage)\n",
    "NDWI_img = Image.open(fn)\n",
    "read_NDWI_img = np.array(NDWI_img)\n",
    "\n",
    "# redBands = os.path.join(path_to_write, 'red'+ sampleImage)\n",
    "# red_img = Image.open(redBands)\n",
    "# read_red_img = np.array(red_img)\n",
    "\n",
    "greenBands = os.path.join(path_to_write, 'green'+ sampleImage)\n",
    "green_img = Image.open(greenBands)\n",
    "read_green_img = np.array(green_img)\n",
    "\n",
    "# blueBands = os.path.join(path_to_write, 'blue'+ sampleImage)\n",
    "# blue_img = Image.open(blueBands)\n",
    "# read_blue_img = np.array(blue_img)\n",
    "\n",
    "swirBands = os.path.join(path_to_write, 'swir'+ sampleImage)\n",
    "swir_img = Image.open(swirBands)\n",
    "read_swir_img = np.array(swir_img)\n",
    "# print(read_NDWI_img.shape)\n",
    "# print(read_Bands_img.shape)\n",
    "annotation_im = Image.open(fn.replace(extracted_ndwi_filename ,config.extracted_annotation_filename))\n",
    "read_annotation = np.array(annotation_im)\n",
    "# print(read_annotation.shape)\n",
    "# print(read_annotation)\n",
    "\n",
    "all_images = np.array([read_NDWI_img,read_green_img,read_swir_img, read_annotation])#,read_red_img,read_blue_img\n",
    "# print(all_images.shape[1])\n",
    "display_images(np.expand_dims(np.transpose(all_images, axes=(1,2,0)), axis=0),['ndwi','green','swir','annotation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbh_env",
   "language": "python",
   "name": "hbh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

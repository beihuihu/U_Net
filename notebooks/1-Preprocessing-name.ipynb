{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gps\n",
    "import rasterio                  # I/O raster data (netcdf, height, geotiff, ...)\n",
    "import rasterio.mask\n",
    "import rasterio.warp             # Reproject raster samples\n",
    "import rasterio.merge\n",
    "from rasterio.transform import rowcol\n",
    "from rasterio import features\n",
    "import fiona                     # I/O vector data (shape, geojson, ...)\n",
    "import pyproj                    # Change coordinate reference system\n",
    "from osgeo import gdal\n",
    "import pandas as pd\n",
    "import shapely\n",
    "from shapely.geometry import box, Point\n",
    "import json\n",
    "\n",
    "import numpy as np               # numerical array manipulation\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "import PIL.ImageDraw\n",
    "from core.visualize import display_images\n",
    "\n",
    "import matplotlib.pyplot as plt  # plotting tools\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import trange\n",
    "import warnings                  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_base_dir=r'D:\\lakemapping\\2_dataset\\output600'\n",
    "raw_image_base_dir=r'G:\\5_lakemapping\\sample_img_3'\n",
    "raw_ndwi_image_prefix = 'ndwi_int8_'\n",
    "raw_bands_image_prefix = 'bands_int16_'\n",
    "raw_image_file_type = '.tif'\n",
    "extracted_file_type = '.png'\n",
    "extracted_ndwi_filename = 'ndwi'\n",
    "extracted_bands_filename = ['blue','green','red','swir']\n",
    "extracted_annotation_filename = 'annotation'\n",
    "type_num=4\n",
    "ndwi_band = [0]# If raster has multiple channels, then bands will be [0, 1, ...] otherwise simply [0]\n",
    "four_bands = [0,1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#hbh: check whether the output dir(must be present) of each type is empty\n",
    "for i in range(0,type_num):\n",
    "    path_to_write=os.path.join(training_base_dir,'output\\\\output'+str(i))\n",
    "    assert os.path.exists(path_to_write)\n",
    "    if not len(os.listdir(path_to_write))==0:\n",
    "         print('Warning: path_to_write{} is not empty! The old files in the directory may not be overwritten!!'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Read the training area „ÄÅ training polygons\n",
    "trainingArea = gps.read_file(r\"D:\\lakemapping\\2_dataset\\sampleAnnotations\\area\")\n",
    "trainingPolygon = gps.read_file(r\"D:\\lakemapping\\2_dataset\\sampleAnnotations\\polygon\")\n",
    "print(trainingPolygon.shape,trainingArea.shape)# area:id, geomerry;   polygon:id, geometry \n",
    "trainingPolygon\n",
    "trainingArea\n",
    "print(f'Read a total of {trainingPolygon.shape[0]} object polygons and {trainingArea.shape[0]} training areas.')\n",
    "print(f'Polygons will be assigned to training areas in the next steps.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the training areas and the training polygons have the same crs     \n",
    "if trainingArea.crs  != trainingPolygon.crs:\n",
    "    print('Training area CRS does not match training_polygon CRS')\n",
    "    targetCRS = trainingPolygon.crs #Areas are less in number so conversion should be faster\n",
    "    trainingArea = trainingArea.to_crs(targetCRS)\n",
    "print(trainingPolygon.crs)\n",
    "print(trainingArea.crs)\n",
    "assert trainingPolygon.crs == trainingArea.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# As input we received two shapefile, first one contains the training areas/rectangles and other contains the polygon of lakes/objects in those training areas\n",
    "# The first task is to determine the parent training area for each polygon.\n",
    "\n",
    "def dividePolygonsInTrainingAreas(trainingPolygon, trainingArea):\n",
    "    '''Assign annotated ploygons in to the training areas.'''\n",
    "    # For efficiency, assigned polygons are removed from the list, we make a copy here. \n",
    "    cpTrainingPolygon = trainingPolygon.copy()\n",
    "    splitPolygons = {}\n",
    "    for i in tqdm(trainingArea.index):\n",
    "        spTemp = [] \n",
    "        allocated = []\n",
    "        print(\"area's index:\",i)\n",
    "        for j in cpTrainingPolygon.index:\n",
    "            if cpTrainingPolygon.loc[j]['geometry'].intersects(trainingArea.loc[i]['geometry']):\n",
    "                spTemp.append(cpTrainingPolygon.loc[j])\n",
    "                allocated.append(j)      \n",
    "        splitPolygons[i] = {'polygons':spTemp,'bounds':list(trainingArea.bounds.loc[i]),'id':trainingArea.loc[i]['id'] ,'type':trainingArea.loc[i]['type']}\n",
    "        cpTrainingPolygon = cpTrainingPolygon.drop(allocated)#assigned polygons are removed from the list\n",
    "    return splitPolygons\n",
    "\n",
    "# areasWithPolygons contains the object polygons for each area!\n",
    "areasWithPolygons = dividePolygonsInTrainingAreas(trainingPolygon, trainingArea)\n",
    "print(f'Assigned training polygons in {len(areasWithPolygons)} training areas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(areasWithPolygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAreasThatOverlapWithTrainingData(areaInfo, writePath):\n",
    "    \"\"\"Iterates over raw NDWI images and using findOverlap() extract areas that overlap with training data. \n",
    "    The overlapping areas in raw images are written in a separate file, and annotation file are created from polygons in the overlapping areas.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(writePath):\n",
    "        os.makedirs(writePath)\n",
    "        \n",
    "    polygonsInAreaDf = gps.GeoDataFrame(areaInfo['polygons'])\n",
    "    img_id=str(areaInfo['id'])\n",
    "    bboxArea = box(*areaInfo['bounds'])\n",
    "        \n",
    "    ndwiImg = rasterio.open(os.path.join(raw_image_base_dir,raw_ndwi_image_prefix+img_id+raw_image_file_type))\n",
    "    bandsImg = rasterio.open(os.path.join(raw_image_base_dir,raw_bands_image_prefix+img_id+raw_image_file_type))\n",
    "        \n",
    "    profile = bandsImg.profile  \n",
    "    sm = rasterio.mask.mask(bandsImg, [bboxArea], all_touched=True, crop=True )\n",
    "    profile['height'] = sm[0].shape[1]\n",
    "    profile['width'] = sm[0].shape[2]\n",
    "    profile['transform'] = sm[1]\n",
    "        # That's a problem with rasterio, if the height and the width are less then 256 it throws: ValueError: blockysize exceeds raster height \n",
    "        # So set the blockxsize and blockysize to prevent this problem\n",
    "    profile['blockxsize'] = 32\n",
    "    profile['blockysize'] = 32\n",
    "    profile['count'] = 1\n",
    "        #hbh:band[ndwi] is range from[-100,100]\n",
    "    profile['dtype'] = rasterio.float32\n",
    "        \n",
    "    dt = sm[0][0].astype(profile['dtype'])\n",
    "    with rasterio.open(os.path.join(writePath, extracted_ndwi_filename+'_{}.png'.format(img_id)), 'w', **profile) as dst:\n",
    "        dst.write(dt, 1) \n",
    "\n",
    "    for band, imFn in zip(four_bands, extracted_bands_filename):\n",
    "        dt = sm[0][band].astype(profile['dtype'])\n",
    "        with rasterio.open(os.path.join(writePath, imFn+'_{}.png'.format(img_id)), 'w', **profile) as dst:\n",
    "            dst.write(dt, 1) \n",
    "\n",
    "    polygons = []\n",
    "    for i in polygonsInAreaDf.index:\n",
    "        gm = polygonsInAreaDf.loc[i]['geometry']\n",
    "        polygons.append(gm)\n",
    "                \n",
    "    with rasterio.open(os.path.join(writePath,extracted_annotation_filename+'_{}.png'.format(img_id)), 'w+', **profile) as out:\n",
    "        out_arr = out.read(1)\n",
    "        burned = features.rasterize(polygons, fill=0, default_value=1,out=out_arr, transform=out.transform)\n",
    "        out.write_band(1, burned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key,value in zip(areasWithPolygons.keys(),areasWithPolygons.values()):\n",
    "    path_to_write=r'D:\\lakemapping\\2_dataset\\output600\\output{}'.format(value['type'])\n",
    "    extractAreasThatOverlapWithTrainingData(value,path_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display extracted image \n",
    "sampleImage = '_55.png'\n",
    "# path_to_write=os.path.join(training_base_dir,'output\\output4')\n",
    "path_to_write=os.path.join(training_base_dir,'output588\\output0' )\n",
    "fn = os.path.join(path_to_write, extracted_NDWI_filename + sampleImage)\n",
    "NDWI_img = Image.open(fn)\n",
    "read_NDWI_img = np.array(NDWI_img)\n",
    "\n",
    "# redBands = os.path.join(path_to_write, 'red'+ sampleImage)\n",
    "# red_img = Image.open(redBands)\n",
    "# read_red_img = np.array(red_img)\n",
    "\n",
    "greenBands = os.path.join(path_to_write, 'green'+ sampleImage)\n",
    "green_img = Image.open(greenBands)\n",
    "read_green_img = np.array(green_img)\n",
    "\n",
    "# blueBands = os.path.join(path_to_write, 'blue'+ sampleImage)\n",
    "# blue_img = Image.open(blueBands)\n",
    "# read_blue_img = np.array(blue_img)\n",
    "\n",
    "swirBands = os.path.join(path_to_write, 'swir'+ sampleImage)\n",
    "swir_img = Image.open(swirBands)\n",
    "read_swir_img = np.array(swir_img)\n",
    "# print(read_NDWI_img.shape)\n",
    "# print(read_Bands_img.shape)\n",
    "annotation_im = Image.open(fn.replace(extracted_ndwi_filename ,config.extracted_annotation_filename))\n",
    "read_annotation = np.array(annotation_im)\n",
    "# print(read_annotation.shape)\n",
    "# print(read_annotation)\n",
    "\n",
    "all_images = np.array([read_NDWI_img,read_green_img,read_swir_img, read_annotation])#,read_red_img,read_blue_img\n",
    "# print(all_images.shape[1])\n",
    "display_images(np.expand_dims(np.transpose(all_images, axes=(1,2,0)), axis=0),['ndwi','green','swir','annotation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lake_env",
   "language": "python",
   "name": "lake_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

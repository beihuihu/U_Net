{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Author: Ankit Kariryaa, University of Bremen\n",
    "  \n",
    "  Modified by Beihui Hu\n",
    "\n",
    "\n",
    "#*************************************************************************************************************\n",
    "\n",
    "Copyright (c) 2020, Ankit Kariryaa\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.s\n",
    "\n",
    "#*************************************************************************************************************\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview \n",
    "\n",
    "The code was written by Ankit Kariryaa (Kariryaa AT uni-bremen DOT de) in 2018 (see https://doi.org/10.5281/zenodo.3978185), and some modifications were made by Beihui Hu in 2023.\n",
    "\n",
    "Start by labeling a part of the satellite images with the lakes and storing the labels in shapefiles. The areas that are labeled are denoted by the 'training area' and actual lakes in that area are denoted by the 'training polygons'.\n",
    "\n",
    "- First, we read the training area and the training polygons from two separate shapefiles. Then we determine the training area for each training polygon. \n",
    "- Next, we read the raw satellite images (NDWI channel), and extract training image that overlap with a training area from each satellite image. The part of the NDWI image that overlap with the training area and the corresponding label are then written to separate files.\n",
    "- Then, we classify the areas and corresponding polygons into different types .\n",
    "\n",
    "Here, the term training area and training polygon represent all available input data, which can then be separated into training, validation, and test sets in the next notebook(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gps\n",
    "import rasterio                  # I/O raster data (netcdf, height, geotiff, ...)\n",
    "import rasterio.mask\n",
    "import rasterio.warp             # Reproject raster samples\n",
    "import rasterio.merge\n",
    "from rasterio.transform import rowcol\n",
    "from rasterio import features\n",
    "import fiona                     # I/O vector data (shape, geojson, ...)\n",
    "import pyproj                    # Change coordinate reference system\n",
    "from osgeo import gdal\n",
    "import pandas as pd\n",
    "import shapely\n",
    "from shapely.geometry import box, Point\n",
    "import json\n",
    "\n",
    "import numpy as np               # numerical array manipulation\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "import PIL.ImageDraw\n",
    "from core.visualize import display_images\n",
    "\n",
    "import matplotlib.pyplot as plt  # plotting tools\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import trange\n",
    "import warnings                  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required configurations (including the input and output paths) are stored in a separate file (such as config/Preprocessing.py)\n",
    "# Please provide required info in the file before continuing with this notebook. \n",
    "# hbh: in this scene,a new config named Preprocessing_within is created to distinguish from the original\n",
    "from config import Preprocessing   \n",
    "# In case you are using a different folder name such as configLargeCluster, then you should import from the respective folder \n",
    "# Eg. from configLargeCluster import Preprocessing\n",
    "config = Preprocessing.Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#hbh: check whether the output dir(must be present) of each type is empty\n",
    "for i in range(0,config.type_num):\n",
    "    path_to_write=os.path.join(config.training_base_dir,'output\\\\output'+str(i))\n",
    "    assert os.path.exists(path_to_write)\n",
    "    if not len(os.listdir(path_to_write))==0:\n",
    "         print('Warning: path_to_write{} is not empty! The old files in the directory may not be overwritten!!'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Read the training area „ÄÅ training polygons\n",
    "# trainingArea = gps.read_file(r\"D:\\lakemapping\\2_dataset\\sampleAnnotations\\area\")\n",
    "# trainingPolygon = gps.read_file(r\"D:\\lakemapping\\2_dataset\\sampleAnnotations\\polygon\")\n",
    "trainingArea = gps.read_file(os.path.join(config.training_base_dir, config.training_area_fn))\n",
    "trainingPolygon = gps.read_file(os.path.join(config.training_base_dir, config.training_polygon_fn))\n",
    "print(trainingPolygon.shape,trainingArea.shape)# area:id, geomerry;   polygon:id, geometry \n",
    "trainingPolygon\n",
    "trainingArea\n",
    "print(f'Read a total of {trainingPolygon.shape[0]} object polygons and {trainingArea.shape[0]} training areas.')\n",
    "print(f'Polygons will be assigned to training areas in the next steps.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the training areas and the training polygons have the same crs     \n",
    "if trainingArea.crs  != trainingPolygon.crs:\n",
    "    print('Training area CRS does not match training_polygon CRS')\n",
    "    targetCRS = trainingPolygon.crs #Areas are less in number so conversion should be faster\n",
    "    trainingArea = trainingArea.to_crs(targetCRS)\n",
    "print(trainingPolygon.crs)\n",
    "print(trainingArea.crs)\n",
    "assert trainingPolygon.crs == trainingArea.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assign serial IDs to training areas    \n",
    "# trainingArea['id'] = range(trainingArea.shape[0])\n",
    "trainingArea#print(trainingArea.shape)  #area:   id,Type,geometry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# As input we received two shapefile, first one contains the training areas/rectangles and other contains the polygon of lakes/objects in those training areas\n",
    "# The first task is to determine the parent training area for each polygon.\n",
    "\n",
    "def dividePolygonsInTrainingAreas(trainingPolygon, trainingArea):\n",
    "    '''Assign annotated ploygons in to the training areas.'''\n",
    "    # For efficiency, assigned polygons are removed from the list, we make a copy here. \n",
    "    cpTrainingPolygon = trainingPolygon.copy()\n",
    "    splitPolygons = {}\n",
    "    for i in tqdm(trainingArea.index):\n",
    "        spTemp = [] \n",
    "        allocated = []\n",
    "        print(\"area's index:\",i)\n",
    "        for j in cpTrainingPolygon.index:\n",
    "            if cpTrainingPolygon.loc[j]['geometry'].intersects(trainingArea.loc[i]['geometry']):\n",
    "                spTemp.append(cpTrainingPolygon.loc[j])\n",
    "                allocated.append(j)           \n",
    "            # Order of bounds: minx miny maxx maxy\n",
    "        #print(spTemp)\n",
    "#         print(trainingArea.loc[i]['id'])\n",
    "        splitPolygons[trainingArea.loc[i]['id']] = {'polygons':spTemp, 'bounds':list(trainingArea.bounds.loc[i]),'type':trainingArea.loc[i]['type'],'id':trainingArea.loc[i]['id']}\n",
    "        cpTrainingPolygon = cpTrainingPolygon.drop(allocated)#assigned polygons are removed from the list\n",
    "    return splitPolygons\n",
    "\n",
    "# areasWithPolygons contains the object polygons for each area!\n",
    "areasWithPolygons = dividePolygonsInTrainingAreas(trainingPolygon, trainingArea)\n",
    "print(f'Assigned training polygons in {len(areasWithPolygons)} training areas')\n",
    "# print(areasWithPolygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read the raw input images\n",
    "def readInputImages(imageBaseDir, rawImageFileType, rawNdwiImagePrefix, rawBandsImagePrefix):\n",
    "    \"\"\"\n",
    "    Reads all images with prefix ndvi_image_prefix and image_file_type datatype in the image_base_dir directory.\n",
    "    \"\"\"  \n",
    "    ndwiImageFn = []\n",
    "    for root, dirs, files in os.walk(imageBaseDir):\n",
    "        for file in files:\n",
    "            if file.endswith(rawImageFileType) and file.startswith(rawNdwiImagePrefix):\n",
    "                ndwiImageFn.append(os.path.join(root, file))\n",
    "    bandsImageFn = [fn.replace(rawNdwiImagePrefix, rawBandsImagePrefix) for fn in ndwiImageFn]\n",
    "    inputImages = list(zip(ndwiImageFn,bandsImageFn))\n",
    "    return inputImages\n",
    "\n",
    "inputImages = readInputImages(config.raw_image_base_dir, config.raw_image_file_type, config.raw_NDWI_image_prefix, config.raw_bands_image_prefix)\n",
    "print(f'Found a total of {len(inputImages)} pair of raw image(s) to process!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each raw satellite image, determine if it overlaps with a training area. \n",
    "# If a overlap if found, then extract + write the overlapping part of the raw image, create + write an image from training polygons.\n",
    "\n",
    "def writeExtractedImageAndAnnotation(img, sm, profile, polygonsInAreaDf,  writePath, imagesFilename, annotationFilename, bands, writeCounter):\n",
    "    \"\"\"Write the part of raw image that overlaps with a training area into a separate image file. \n",
    "    Use rowColPolygons to create and write annotation image from polygons in the training area.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for band, imFn in zip(bands, imagesFilename):\n",
    "            # Rasterio reads file channel first, so the sm[0] has the shape [1 or ch_count, x,y]\n",
    "            # If raster has multiple channels, then bands will be [0, 1, ...] otherwise simply [0]\n",
    "            dt = sm[0][band].astype(profile['dtype'])\n",
    "            with rasterio.open(os.path.join(writePath, imFn+'_{}.png'.format(writeCounter)), 'w', **profile) as dst:\n",
    "                dst.write(dt, 1) \n",
    "#                 print('write '+ imFn+'_{}.png'.format(writeCounter) +' image\\n')\n",
    "\n",
    "        if annotationFilename:\n",
    "            annotation_filepath = os.path.join(writePath,annotationFilename+'_{}.png'.format(writeCounter))\n",
    "            polygons = []\n",
    "            for i in polygonsInAreaDf.index:\n",
    "                gm = polygonsInAreaDf.loc[i]['geometry']\n",
    "                polygons.append(gm)\n",
    "                \n",
    "            with rasterio.open(annotation_filepath, 'w+', **profile) as out:\n",
    "                out_arr = out.read(1)\n",
    "                burned = features.rasterize(polygons, fill=0, default_value=1,out=out_arr, transform=out.transform)\n",
    "                out.write_band(1, burned)\n",
    "        return(writeCounter+1)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Something nasty happened, could not write the annotation or the mask file!======\\n\\n\\n\")\n",
    "        return writeCounter\n",
    "        \n",
    "def findOverlap(img, areasWithPolygons, writePath, imageFilename, annotationFilename, bands, writeCounter):\n",
    "    \"\"\"Finds overlap of image with a training area.\n",
    "    Use writeExtractedImageAndAnnotation() to write the overlapping training area and corresponding polygons in separate image files.\n",
    "    \"\"\"\n",
    "    overlappedAreas = set()\n",
    "    \n",
    "    for areaID, areaInfo in areasWithPolygons.items():\n",
    "        #Convert the polygons in the area   in a dataframe and get the bounds of the area. \n",
    "        polygonsInAreaDf = gps.GeoDataFrame(areaInfo['polygons'])\n",
    "        bboxArea = box(*areaInfo['bounds'])#area bounds\n",
    "        bboxImg = box(*img.bounds)#image bounds\n",
    "        \n",
    "        #Extract the window if area is in the image\n",
    "        #hbh: if an area may overlap with multiple images, use intersect() rather than within()\n",
    "        #if(bboxArea.within(intersect)):\n",
    "        if(bboxArea.within(bboxImg)):\n",
    "            profile = img.profile  \n",
    "            sm = rasterio.mask.mask(img, [bboxArea], all_touched=True, crop=True )\n",
    "            profile['height'] = sm[0].shape[1]\n",
    "            profile['width'] = sm[0].shape[2]\n",
    "            profile['transform'] = sm[1]\n",
    "            # That's a problem with rasterio, if the height and the width are less then 256 it throws: ValueError: blockysize exceeds raster height \n",
    "            # So set the blockxsize and blockysize to prevent this problem\n",
    "            profile['blockxsize'] = 32\n",
    "            profile['blockysize'] = 32\n",
    "            profile['count'] = 1\n",
    "            #hbh:band[ndwi] is range from[-100,100]\n",
    "            profile['dtype'] = rasterio.float32\n",
    "            writeCounter = writeExtractedImageAndAnnotation(img, sm, profile, polygonsInAreaDf, writePath, imageFilename, annotationFilename,  bands, writeCounter)\n",
    "            overlappedAreas.add(areaID)\n",
    "    return(writeCounter, overlappedAreas)\n",
    "\n",
    "\n",
    "def extractAreasThatOverlapWithTrainingData(inputImages, areasWithPolygons, writePath, NdwiFilename,BandsFilename, annotationFilename, writeCounter):\n",
    "    \"\"\"Iterates over raw NDWI images and using findOverlap() extract areas that overlap with training data. \n",
    "    The overlapping areas in raw images are written in a separate file, and annotation file are created from polygons in the overlapping areas.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(writePath):\n",
    "        os.makedirs(writePath)\n",
    "        \n",
    "    overlappedAreas = set()\n",
    "    for imgs in tqdm(inputImages):\n",
    "        ndwiImg = rasterio.open(imgs[0])\n",
    "#         print(ndwiImg.shape)\n",
    "        bandsImg = rasterio.open(imgs[1])\n",
    "        ncNDWI,imOverlappedAreasNDWI = findOverlap(ndwiImg, areasWithPolygons, writePath=writePath, imageFilename=[NdwiFilename], annotationFilename=annotationFilename, bands=config.bands0, writeCounter=writeCounter)\n",
    "        ncBands,imOverlapppedAreasBands = findOverlap(bandsImg, areasWithPolygons, writePath=writePath, imageFilename=BandsFilename, annotationFilename='', bands=config.bands1, writeCounter=writeCounter )\n",
    "        if ncNDWI == ncBands:\n",
    "            writeCounter = ncNDWI\n",
    "        else: \n",
    "            print('Couldnt create mask!!!')\n",
    "            print(ncNDWI)\n",
    "            print(ncBands)\n",
    "            break;\n",
    "        overlappedAreas.update(imOverlappedAreasNDWI)\n",
    "    \n",
    "    allAreas = set(areasWithPolygons.keys())\n",
    "    if allAreas.difference(overlappedAreas):\n",
    "        print(f'Warning: Could not find a raw image correspoinding to {allAreas.difference(overlappedAreas)} areas. Make sure that you have provided the correct paths!')\n",
    "    return writeCounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "writeCounter=0\n",
    "for key,value in zip(areasWithPolygons.keys(),areasWithPolygons.values()):\n",
    "    newdict={}\n",
    "    path_to_write=r'D:\\lakemapping\\2_dataset\\output588\\output{}'.format(value['type'])\n",
    "#         path_to_write=os.path.join(output_dir,'output{}'.format(value['type']))\n",
    "        newdict[key] = {'polygons':value['polygons'], 'bounds':value['bounds']}\n",
    "        writeCounter=extractAreasThatOverlapWithTrainingData(inputImages,newdict, path_to_write, config.extracted_NDWI_filename,config.extracted_bands_filename, config.extracted_annotation_filename, writeCounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(writeCounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display extracted image \n",
    "sampleImage = '_55.png'\n",
    "# path_to_write=os.path.join(config.training_base_dir,'output\\output4')\n",
    "path_to_write=os.path.join(config.training_base_dir,'output588\\output0' )\n",
    "fn = os.path.join(path_to_write, config.extracted_NDWI_filename + sampleImage)\n",
    "NDWI_img = Image.open(fn)\n",
    "read_NDWI_img = np.array(NDWI_img)\n",
    "\n",
    "# redBands = os.path.join(path_to_write, 'red'+ sampleImage)\n",
    "# red_img = Image.open(redBands)\n",
    "# read_red_img = np.array(red_img)\n",
    "\n",
    "greenBands = os.path.join(path_to_write, 'green'+ sampleImage)\n",
    "green_img = Image.open(greenBands)\n",
    "read_green_img = np.array(green_img)\n",
    "\n",
    "# blueBands = os.path.join(path_to_write, 'blue'+ sampleImage)\n",
    "# blue_img = Image.open(blueBands)\n",
    "# read_blue_img = np.array(blue_img)\n",
    "\n",
    "swirBands = os.path.join(path_to_write, 'swir'+ sampleImage)\n",
    "swir_img = Image.open(swirBands)\n",
    "read_swir_img = np.array(swir_img)\n",
    "# print(read_NDWI_img.shape)\n",
    "# print(read_Bands_img.shape)\n",
    "annotation_im = Image.open(fn.replace(config.extracted_NDWI_filename ,config.extracted_annotation_filename))\n",
    "read_annotation = np.array(annotation_im)\n",
    "# print(read_annotation.shape)\n",
    "# print(read_annotation)\n",
    "\n",
    "all_images = np.array([read_NDWI_img,read_green_img,read_swir_img, read_annotation])#,read_red_img,read_blue_img\n",
    "# print(all_images.shape[1])\n",
    "display_images(np.expand_dims(np.transpose(all_images, axes=(1,2,0)), axis=0),['ndwi','green','swir','annotation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
